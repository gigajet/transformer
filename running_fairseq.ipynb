{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gigajet/transformer/blob/master/running_fairseq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OBkDDiNQPuD"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C-uhHC2jy04F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d21cfc-94b8-409c-a2b2-e79116d02d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Google Colab doesn't support `ln`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaNm6BzuuVW8",
        "outputId": "1f3d2bfb-599f-4ccd-d010-a8d04881bfaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31273, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 31273 (delta 18), reused 45 (delta 18), pack-reused 31225\u001b[K\n",
            "Receiving objects: 100% (31273/31273), 21.53 MiB | 15.61 MiB/s, done.\n",
            "Resolving deltas: 100% (23055/23055), done.\n",
            "/content/fairseq\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (1.15.0)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (1.21.6)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting bitarray\n",
            "  Downloading bitarray-2.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (4.64.0)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (0.11.0+cu113)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (2019.12.20)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+c8d6fb1) (0.29.28)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+c8d6fb1) (5.7.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+c8d6fb1) (4.2.0)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+c8d6fb1) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+c8d6fb1) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+c8d6fb1) (3.8.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=e76f532b39ec7272f3a65ceee14e364e009f55d442272272f8c85162c8a70b6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.5.0 colorama-0.4.4 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.4.0 sacrebleu-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# Install fairseq\n",
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "!pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMStVQCYu-nN",
        "outputId": "908122a2-4c85-403e-f5fd-4592a7d4b996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastBPE\n",
            "  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 18.0 MB/s \n",
            "\u001b[?25hCollecting subword_nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Building wheels for collected packages: fastBPE, sacremoses\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=483164 sha256=3d21ad62e7dbba248531515a9287ab9211022fd196aa700aee5e680eb56b808c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e685ad23ec88de4592b31633a5727df9b9374c0555dd25ba24de1e2fe1d18119\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built fastBPE sacremoses\n",
            "Installing collected packages: mock, subword-nmt, sacremoses, fastBPE\n",
            "Successfully installed fastBPE-0.1.0 mock-4.0.3 sacremoses-0.0.53 subword-nmt-0.3.8\n"
          ]
        }
      ],
      "source": [
        "# Dependencies for preprocessing\n",
        "!pip install fastBPE sacremoses subword_nmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CD6pa7A0CgRX"
      },
      "outputs": [],
      "source": [
        "# Run this if you get error \"importlib_metadata.PackageNotFoundError: No package metadata was found for fairseq\" in next cell\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/fairseq/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBYOOYRFbojI"
      },
      "source": [
        "## Verify that fairseq is now usable (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "cAecsqc7vGTE",
        "outputId": "3cdf48be-1ce8-482f-b696-0e0e9fcc1302"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-02 04:29:06 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "Downloading: \"https://github.com/pytorch/fairseq/archive/main.zip\" to /root/.cache/torch/hub/main.zip\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_main\n",
            "2022-05-02 04:29:10 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2 not found in cache, downloading to /tmp/tmpy9uuosu6\n",
            "  7%|▋         | 150277120/2193287384 [00:05<01:50, 18416384.24B/s]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-08ea59ea7e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Note: WMT'19 models use fastBPE instead of subword_nmt, see instructions below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt16.en-de',\n\u001b[0;32m---> 12\u001b[0;31m                        tokenizer='moses', bpe='subword_nmt')\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0men2de\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# disable dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mrepo_or_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_cache_or_reload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fairseq/fairseq/models/fairseq_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0marchive_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         )\n\u001b[1;32m    274\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fairseq/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mmodel_name_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_archive_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# convenience hack for loading data and BPE codes from model archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fairseq/fairseq/file_utils.py\u001b[0m in \u001b[0;36mload_archive_file\u001b[0;34m(archive_file)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# redirect to the cache, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         logger.info(\n",
            "\u001b[0;32m/content/fairseq/fairseq/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# File, and it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fairseq/fairseq/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0ms3_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# we are copying the file before closing it, so flush to avoid truncation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fairseq/fairseq/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontent_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Amount is not given (unbounded read) so we must check self.length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# This cell is for verifying the install\n",
        "# Interactive translation\n",
        "import torch\n",
        "import fairseq\n",
        "\n",
        "# List available models\n",
        "torch.hub.list('pytorch/fairseq')  # [..., 'transformer.wmt16.en-de', ... ]\n",
        "\n",
        "# Load a transformer trained on WMT'16 En-De\n",
        "# Note: WMT'19 models use fastBPE instead of subword_nmt, see instructions below\n",
        "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt16.en-de',\n",
        "                       tokenizer='moses', bpe='subword_nmt')\n",
        "en2de.eval()  # disable dropout\n",
        "\n",
        "# The underlying model is available under the *models* attribute\n",
        "assert isinstance(en2de.models[0], fairseq.models.transformer.TransformerModel)\n",
        "\n",
        "# Move model to GPU for faster translation\n",
        "# en2de.cuda()\n",
        "\n",
        "# Translate a sentence\n",
        "en2de.translate('Hello world!')\n",
        "# 'Hallo Welt!'\n",
        "\n",
        "# Batched translation\n",
        "en2de.translate(['Hello world!', 'The cat sat on the mat.'])\n",
        "# ['Hallo Welt!', 'Die Katze saß auf der Matte.']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuVoveca1ATX"
      },
      "source": [
        "## Prepare & Train IWSLT'14 German to English (Transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9uIZOA0-03u",
        "outputId": "2ccdda54-e869-4bca-a1b9-643a7abbc499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fairseq/examples/translation\n",
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 148090, done.\u001b[K\n",
            "remote: Counting objects: 100% (518/518), done.\u001b[K\n",
            "remote: Compressing objects: 100% (223/223), done.\u001b[K\n",
            "^C\n",
            "/content/fairseq\n"
          ]
        }
      ],
      "source": [
        "# Download and prepare the data\n",
        "%cd examples/translation/\n",
        "!bash prepare-iwslt14.sh\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01aLMot8vkby",
        "outputId": "9b37e8e5-642f-4acf-ade8-a003a8f293b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TEXT=examples/translation/iwslt14.tokenized.de-en\n",
            "/bin/bash: fairseq-preprocess: command not found\n"
          ]
        }
      ],
      "source": [
        "# Preprocess/binarize the data\n",
        "# Look below on how to set environment variable in GG Colab\n",
        "%env TEXT=examples/translation/iwslt14.tokenized.de-en\n",
        "!fairseq-preprocess --source-lang de --target-lang en \\\n",
        "    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
        "    --destdir /content/drive/MyDrive/translation/iwslt14.tokenized.de-en \\\n",
        "    --workers 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6m9cR6h1HPM",
        "outputId": "398179fe-af5e-41a9-bd05-7c4a8b8808ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "/bin/bash: fairseq-train: command not found\n"
          ]
        }
      ],
      "source": [
        "# Train the model, please change --max-epoch depends whether you use gpu/cpu\n",
        "%env CUDA_VISIBLE_DEVICES=0 \n",
        "!fairseq-train \\\n",
        "    /content/drive/MyDrive/translation/iwslt14.tokenized.de-en \\\n",
        "    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-epoch 15 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    --save-dir /content/drive/MyDrive/translation/iwslt14.tokenized.de-en/checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIVXq97t1JnF",
        "outputId": "ba78b363-c3a9-461d-de5d-a3f97d791a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: fairseq-generate: command not found\n"
          ]
        }
      ],
      "source": [
        "# Evaluate our model\n",
        "!fairseq-generate /content/drive/MyDrive/translation/iwslt14.tokenized.de-en \\\n",
        "    --path /content/drive/MyDrive/translation/iwslt14.tokenized.de-en/checkpoints/checkpoint_best.pt \\\n",
        "    --batch-size 128 --beam 5 --remove-bpe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYLNU2e0Ow0d"
      },
      "source": [
        "## Prepare IWSLT'15 English - Vietnamese data\n",
        "Data is already in Drive `/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset`, unnecessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RphxFkxj6wIW",
        "outputId": "1c696d33-667d-417c-811c-aaa87e050677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/translation/en-vi.zip\n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.dev2010.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.dev2010.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2010.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2010.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2011.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2011.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2012.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2012.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2013.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2013.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2015.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/IWSLT15.TED.tst2015.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.en-vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.tags.en-vi.clean.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.tags.en-vi.clean.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.tags.en-vi.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.tags.en-vi.tok.en  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.tags.en-vi.tok.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.tags.en-vi.vi  \n",
            "  inflating: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.vi  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/translation/en-vi.zip -d /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset\n",
        "# !cp /content/drive/MyDrive/translation/myprepare-iwslt15-en-vi.sh ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OdtKEvLYcpP1"
      },
      "outputs": [],
      "source": [
        "#!sh myprepare-iwslt15-en-vi.sh\n",
        "# After this, we have `train valid test` in iwslt15.tokenized.en-vi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "XLUymR6GeKvp"
      },
      "outputs": [],
      "source": [
        "# Preprocess/binarize the data\n",
        "# Look below on how to set environment variable in GG Colab\n",
        "# %env TEXT=iwslt15.tokenized.en-vi\n",
        "# !fairseq-preprocess --source-lang en --target-lang vi \\\n",
        "#     --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
        "#     --destdir /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset \\\n",
        "#     --workers 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsmOKipnchcY"
      },
      "source": [
        "## Train IWSLT'15 English-Vietnamese (Transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXd1Mv0Q7Cez",
        "outputId": "353dcaef-9d27-439a-c4d9-771c89682cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "/bin/bash: fairseq-train: command not found\n"
          ]
        }
      ],
      "source": [
        "# arch transformer, ở đây dùng transformer_iwslt_de_en là dùng lại architecture của nó\n",
        "# Train the model, please change --max-epoch depends whether you use gpu/cpu\n",
        "# see stop-time-hours\n",
        "%env CUDA_VISIBLE_DEVICES=0 \n",
        "!fairseq-train \\\n",
        "    /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset \\\n",
        "    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-epoch 36 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    --save-dir checkpoints\n",
        "    # --save-dir /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE1kX47f3YkB",
        "outputId": "41c13447-611d-4c80-9ca3-85c8fafdb389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-07 15:48:42 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-05-07 15:48:45 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/content/mymodel', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-05-07 15:48:46 | INFO | fairseq.tasks.translation | [en] dictionary: 7664 types\n",
            "2022-05-07 15:48:46 | INFO | fairseq.tasks.translation | [vi] dictionary: 6640 types\n",
            "2022-05-07 15:48:46 | INFO | fairseq_cli.generate | loading model(s) from /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint_best.pt\n",
            "model_type nntransformer_default\n",
            "cfg Namespace(_name='nntransformer_default', adam_betas='(0.9, 0.98)', adam_eps=1e-08, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='nntransformer_default', azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='/content/drive/MyDrive/Thesis/iwslt15.tokenized.en-vi', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', device_id=0, dim_feedforward=2048, dim_model=512, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=100, max_source_positions=1024, max_src_len=16378, max_target_positions=1024, max_tgt_len=16378, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_head=8, num_layer=6, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/drive/MyDrive/Thesis/customModel', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='/content/mymodel', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none')\n",
            "model <class 'mymodel.models.nnFairseqTransformer.NNTransformer'>\n",
            "hints dict_keys(['wav2vec', 'wav2vec2', 'wav2vec_ctc', 'wav2vec_seq2seq', 'hubert', 'hubert_ctc', 'transformer_lm', 'transformer_ulm'])\n",
            "WTF\n",
            "2022-05-07 15:48:51 | INFO | fairseq.data.data_utils | loaded 7,446 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/test.en-vi.en\n",
            "2022-05-07 15:48:52 | INFO | fairseq.data.data_utils | loaded 7,446 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/test.en-vi.vi\n",
            "2022-05-07 15:48:52 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset test en-vi 7446 examples\n",
            "  0% 0/60 [00:00<?, ?it/s]S-2053\tNo kidding .\n",
            "T-2053\tKhông đùa đâu .\n",
            "H-2053\t-0.15883876383304596\tKhông đùa đâu .\n",
            "D-2053\t-0.15883876383304596\tKhông đùa đâu .\n",
            "P-2053\t-0.2151 -0.0039 -0.1327 -0.3466 -0.0958\n",
            "S-49\tIt &apos;s interesting .\n",
            "T-49\tNó thật thú vị .\n",
            "H-49\t-0.3942326307296753\tThật thú vị .\n",
            "D-49\t-0.3942326307296753\tThật thú vị .\n",
            "P-49\t-1.5323 -0.1164 -0.0279 -0.1914 -0.1032\n",
            "S-6905\tIt was faster .\n",
            "T-6905\tNhanh hơn .\n",
            "H-6905\t-0.28961050510406494\tNó nhanh hơn .\n",
            "D-6905\t-0.28961050510406494\tNó nhanh hơn .\n",
            "P-6905\t-0.7786 -0.0850 -0.0507 -0.4326 -0.1012\n",
            "S-5460\tThere she is .\n",
            "T-5460\tBà ấy đây .\n",
            "H-5460\t-0.9421876072883606\tCô ấy đây .\n",
            "D-5460\t-0.9421876072883606\tCô ấy đây .\n",
            "P-5460\t-3.1883 -0.4919 -0.3633 -0.5815 -0.0859\n",
            "S-4411\tWooo !\n",
            "T-4411\tWooo !\n",
            "H-4411\t-0.0422537587583065\tWooo !\n",
            "D-4411\t-0.0422537587583065\tWooo !\n",
            "P-4411\t-0.0384 -0.0035 -0.0120 -0.0605 -0.0968\n",
            "S-4132\tIs that all ?\n",
            "T-4132\tđọc xong chứ ?\n",
            "H-4132\t-0.5081644654273987\tĐó có phải là tất cả ?\n",
            "D-4132\t-0.5081644654273987\tĐó có phải là tất cả ?\n",
            "P-4132\t-2.3221 -0.3246 -0.0188 -0.4925 -0.3664 -0.0535 -0.3840 -0.1035\n",
            "S-3256\tafter one week .\n",
            "T-3256\tsau một tuần .\n",
            "H-3256\t-0.3699674904346466\tSau một tuần .\n",
            "D-3256\t-0.3699674904346466\tSau một tuần .\n",
            "P-3256\t-0.9330 -0.5915 -0.0254 -0.2075 -0.0924\n",
            "S-3255\tFrom Seattle ...\n",
            "T-3255\tTừ Seattle ...\n",
            "H-3255\t-0.10573320090770721\tTừ Seattle ...\n",
            "D-3255\t-0.10573320090770721\tTừ Seattle ...\n",
            "P-3255\t-0.0543 -0.0045 -0.0554 -0.3459 -0.0684\n",
            "S-2822\tA few less .\n",
            "T-2822\tÍt hơn .\n",
            "H-2822\t-0.6940644979476929\tMột vài cái ít hơn .\n",
            "D-2822\t-0.6940644979476929\tMột vài cái ít hơn .\n",
            "P-2822\t-1.2337 -0.7113 -1.8717 -0.3414 -0.2992 -0.3039 -0.0972\n",
            "S-2814\tCreativity .\n",
            "T-2814\tSự sáng tạo .\n",
            "H-2814\t-0.5438964366912842\tSáng tạo .\n",
            "D-2814\t-0.5438964366912842\tSáng tạo .\n",
            "P-2814\t-2.1496 -0.0884 -0.0207 -0.3652 -0.0956\n",
            "S-2521\tWhich was awesome .\n",
            "T-2521\tThật là tuyệt .\n",
            "H-2521\t-0.3574691712856293\tThật kinh hãi .\n",
            "D-2521\t-0.3574691712856293\tThật kinh hãi .\n",
            "P-2521\t-0.6665 -0.6300 -0.1935 -0.1994 -0.0979\n",
            "S-2275\tExplore .\n",
            "T-2275\tVà khám phá .\n",
            "H-2275\t-1.2820268869400024\tĐược rồi .\n",
            "D-2275\t-1.2820268869400024\tĐược rồi .\n",
            "P-2275\t-4.1183 -0.6679 -0.2433 -0.0986\n",
            "S-6148\tGuess what ?\n",
            "T-6148\tNghĩ thử xem nhé ?\n",
            "H-6148\t-0.8136436939239502\tBạn có đoán được không ?\n",
            "D-6148\t-0.8136436939239502\tBạn có đoán được không ?\n",
            "P-6148\t-1.6213 -1.5618 -1.1012 -0.9553 -0.2581 -0.1044 -0.0933\n",
            "S-1921\tWhat a fish .\n",
            "T-1921\tÔi cá yêu .\n",
            "H-1921\t-0.3789100646972656\tMột con cá .\n",
            "D-1921\t-0.3789100646972656\tMột con cá .\n",
            "P-1921\t-1.4843 -0.0642 -0.0120 -0.2438 -0.0904\n",
            "S-1012\tSort of .\n",
            "T-1012\tĐại loại thế .\n",
            "H-1012\t-0.6052660346031189\tXin lỗi .\n",
            "D-1012\t-0.6052660346031189\tXin lỗi .\n",
            "P-1012\t-1.6980 -0.3842 -0.2393 -0.0996\n",
            "S-958\tTa-da !\n",
            "T-958\tTa-da !\n",
            "H-958\t-0.22346529364585876\tTa-da !\n",
            "D-958\t-0.22346529364585876\tTa-da !\n",
            "P-958\t-0.2143 -0.7271 -0.0221 -0.0650 -0.0888\n",
            "S-7018\tGenius .\n",
            "T-7018\tThiên tài .\n",
            "H-7018\t-0.24979360401630402\tGenius .\n",
            "D-7018\t-0.24979360401630402\tGenius .\n",
            "P-7018\t-0.8359 -0.0050 -0.0114 -0.3037 -0.0930\n",
            "S-5876\tAbsolutely .\n",
            "T-5876\tChính xác .\n",
            "H-5876\t-0.474170058965683\tChắc chắn rồi .\n",
            "D-5876\t-0.474170058965683\tChắc chắn rồi .\n",
            "P-5876\t-0.9974 -0.0129 -0.9360 -0.3259 -0.0987\n",
            "S-5217\tExtraordinary .\n",
            "T-5217\tPhi thường .\n",
            "H-5217\t-0.9927535653114319\tThật bình thường .\n",
            "D-5217\t-0.9927535653114319\tThật bình thường .\n",
            "P-5217\t-3.5435 -0.9519 -0.0233 -0.3539 -0.0911\n",
            "S-4399\tIt &apos;s true .\n",
            "T-4399\tThật đấy .\n",
            "H-4399\t-0.7148240208625793\tĐúng vậy .\n",
            "D-4399\t-0.7148240208625793\tĐúng vậy .\n",
            "P-4399\t-1.3108 -1.2309 -0.2162 -0.1014\n",
            "S-3821\tWe love entertainment .\n",
            "T-3821\tthích giải trí\n",
            "H-3821\t-0.3119141459465027\tChúng ta yêu thích giải trí .\n",
            "D-3821\t-0.3119141459465027\tChúng ta yêu thích giải trí .\n",
            "P-3821\t-0.1637 -0.5600 -0.4441 -0.7932 -0.0235 -0.0053 -0.4087 -0.0968\n",
            "S-2622\tAwesome .\n",
            "T-2622\tTuyệt vời .\n",
            "H-2622\t-0.6371151208877563\tTuyệt vời .\n",
            "D-2622\t-0.6371151208877563\tTuyệt vời .\n",
            "P-2622\t-1.9852 -0.2553 -0.2095 -0.0985\n",
            "S-1015\tYes , well ...\n",
            "T-1015\tVâng ,\n",
            "H-1015\t-0.42992040514945984\tVâng , vâng ...\n",
            "D-1015\t-0.42992040514945984\tVâng , vâng ...\n",
            "P-1015\t-0.2573 -0.2298 -0.6041 -0.9889 -0.0694\n",
            "S-966\tNice one .\n",
            "T-966\tTuyệt .\n",
            "H-966\t-0.7606930732727051\tKhông có gì cả .\n",
            "D-966\t-0.7606930732727051\tKhông có gì cả .\n",
            "P-966\t-0.2840 -1.6338 -1.4125 -0.8799 -0.2534 -0.1006\n",
            "S-1155\tAnd he says ...\n",
            "T-1155\tVà ông ấy nói ...\n",
            "H-1155\t-0.6829262375831604\tVà ông ấy nói ...\n",
            "D-1155\t-0.6829262375831604\tVà ông ấy nói ...\n",
            "P-1155\t-0.5613 -0.9355 -1.2372 -0.3414 -0.9570 -0.0652\n",
            "S-5878\tThanks , Tom .\n",
            "T-5878\tCảm ơn nhiều , Tom .\n",
            "H-5878\t-0.4122319221496582\tXin cảm ơn .\n",
            "D-5878\t-0.4122319221496582\tXin cảm ơn .\n",
            "P-5878\t-0.1420 -0.8949 -0.0523 -0.8822 -0.0896\n",
            "S-5442\tA real school .\n",
            "T-5442\tMột ngôi trường thật sự .\n",
            "H-5442\t-0.38006171584129333\tMột ngôi trường thật .\n",
            "D-5442\t-0.38006171584129333\tMột ngôi trường thật .\n",
            "P-5442\t-0.2911 -0.5674 -0.0244 -0.6931 -0.6049 -0.0994\n",
            "S-5294\tIt &apos;s everywhere .\n",
            "T-5294\tNó xảy ra mọi nơi .\n",
            "H-5294\t-0.3377896249294281\tNó ở mọi nơi .\n",
            "D-5294\t-0.3377896249294281\tNó ở mọi nơi .\n",
            "P-5294\t-0.4121 -0.3942 -0.8132 -0.0814 -0.2270 -0.0989\n",
            "S-4317\tAnd they did .\n",
            "T-4317\tVà tiếng đó dừng thật .\n",
            "H-4317\t-0.5496029853820801\tVà họ đã làm được .\n",
            "D-4317\t-0.5496029853820801\tVà họ đã làm được .\n",
            "P-4317\t-0.4980 -0.4020 -0.1791 -0.3441 -1.9573 -0.3714 -0.0952\n",
            "S-2434\tThey all matter .\n",
            "T-2434\tChúng đều quan trọng cả .\n",
            "H-2434\t-0.4986681044101715\tChúng đều quan trọng .\n",
            "D-2434\t-0.4986681044101715\tChúng đều quan trọng .\n",
            "P-2434\t-0.8664 -1.1768 -0.5866 -0.0326 -0.2299 -0.0997\n",
            "S-1936\tNot very sustainable .\n",
            "T-1936\tKhông bền vững lắm nhỉ .\n",
            "H-1936\t-0.25104469060897827\tKhông bền vững lắm .\n",
            "D-1936\t-0.25104469060897827\tKhông bền vững lắm .\n",
            "P-1936\t-0.4145 -0.1201 -0.0312 -0.5882 -0.2490 -0.1034\n",
            "S-1881\tWe know that .\n",
            "T-1881\tChúng ta biết điều đó .\n",
            "H-1881\t-0.26602107286453247\tChúng ta biết điều đó .\n",
            "D-1881\t-0.26602107286453247\tChúng ta biết điều đó .\n",
            "P-1881\t-0.3170 -0.1323 -0.2487 -0.4909 -0.2626 -0.3092 -0.1014\n",
            "S-616\tThey actually hurt .\n",
            "T-616\tMà còn gây tổn thương .\n",
            "H-616\t-0.6653836965560913\tHọ thật sự làm tổn thương .\n",
            "D-616\t-0.6653836965560913\tHọ thật sự làm tổn thương .\n",
            "P-616\t-1.3374 -1.3461 -0.1706 -1.8737 -0.2186 -0.0143 -0.2650 -0.0974\n",
            "S-399\tThis is hard .\n",
            "T-399\tĐiều này thật khó khăn .\n",
            "H-399\t-0.676545262336731\tĐiều này rất khó .\n",
            "D-399\t-0.676545262336731\tĐiều này rất khó .\n",
            "P-399\t-1.7211 -0.3391 -1.5818 -0.0320 -0.2945 -0.0908\n",
            "S-4811\tPretty simple .\n",
            "T-4811\tKhá đơn giản .\n",
            "H-4811\t-0.17462928593158722\tKhá đơn giản .\n",
            "D-4811\t-0.17462928593158722\tKhá đơn giản .\n",
            "P-4811\t-0.5237 -0.0091 -0.1182 -0.0532 -0.2438 -0.0997\n",
            "S-4480\tThis is not ...\n",
            "T-4480\tĐây không phải là ...\n",
            "H-4480\t-0.5507673621177673\tĐây không phải là ...\n",
            "D-4480\t-0.5507673621177673\tĐây không phải là ...\n",
            "P-4480\t-1.5826 -0.1249 -0.0940 -0.3626 -1.0759 -0.0646\n",
            "S-4735\tSo meet Al .\n",
            "T-4735\tHãy nói đến Al .\n",
            "H-4735\t-0.8255056142807007\tVậy là Al .\n",
            "D-4735\t-0.8255056142807007\tVậy là Al .\n",
            "P-4735\t-2.2878 -0.9400 -0.4342 -0.3613 -0.1042\n",
            "S-767\tThanks so much .\n",
            "T-767\tCảm ơn rất nhiều .\n",
            "H-767\t-0.4098471701145172\tXin cảm ơn .\n",
            "D-767\t-0.4098471701145172\tXin cảm ơn .\n",
            "P-767\t-0.2926 -0.6397 -0.0717 -0.9542 -0.0911\n",
            "S-2195\tThey called me .\n",
            "T-2195\tHọ gọi cho tôi .\n",
            "H-2195\t-0.3099289536476135\tHọ gọi tôi .\n",
            "D-2195\t-0.3099289536476135\tHọ gọi tôi .\n",
            "P-2195\t-0.3246 -0.2253 -0.5654 -0.3346 -0.0997\n",
            "S-2425\tI swear .\n",
            "T-2425\tTôi thề đấy .\n",
            "H-2425\t-0.6689275503158569\tTôi thề .\n",
            "D-2425\t-0.6689275503158569\tTôi thề .\n",
            "P-2425\t-0.1252 -1.8356 -0.2783 -1.0001 -0.1055\n",
            "S-2568\tThank you guys .\n",
            "T-2568\tCám ơn các bạn .\n",
            "H-2568\t-0.3227114975452423\tXin cảm ơn .\n",
            "D-2568\t-0.3227114975452423\tXin cảm ơn .\n",
            "P-2568\t-0.0616 -0.7523 -0.1001 -0.6086 -0.0911\n",
            "S-2857\tThat was us .\n",
            "T-2857\tĐó là chúng ta .\n",
            "H-2857\t-0.29696282744407654\tĐó là chúng tôi .\n",
            "D-2857\t-0.29696282744407654\tĐó là chúng tôi .\n",
            "P-2857\t-0.4977 -0.4357 -0.1270 -0.3796 -0.2447 -0.0972\n",
            "S-3164\tThat &apos;s scary .\n",
            "T-3164\tThật là đáng sợ .\n",
            "H-3164\t-0.30113404989242554\tThật đáng sợ .\n",
            "D-3164\t-0.30113404989242554\tThật đáng sợ .\n",
            "P-3164\t-0.9343 -0.2623 -0.0087 -0.1946 -0.1059\n",
            "S-3185\tYeah . Okay .\n",
            "T-3185\tĐược rồi . Okay .\n",
            "H-3185\t-0.3001646399497986\tVâng .\n",
            "D-3185\t-0.3001646399497986\tVâng .\n",
            "P-3185\t-0.6029 -0.1921 -0.1055\n",
            "S-3581\tWe were poor .\n",
            "T-3581\tChúng tôi rất nghèo .\n",
            "H-3581\t-0.25971344113349915\tChúng tôi nghèo .\n",
            "D-3581\t-0.25971344113349915\tChúng tôi nghèo .\n",
            "P-3581\t-0.2511 -0.2646 -0.5077 -0.1819 -0.0934\n",
            "S-3819\tWe love innovation .\n",
            "T-3819\tChúng ta thích cải tiến\n",
            "H-3819\t-0.5375323295593262\tChúng ta yêu sự cách tân .\n",
            "D-3819\t-0.5375323295593262\tChúng ta yêu sự cách tân .\n",
            "P-3819\t-0.1333 -0.3377 -0.2875 -1.7759 -0.9931 -0.2043 -0.4713 -0.0970\n",
            "S-4470\tThank you .\n",
            "T-4470\tCảm ơn các bạn .\n",
            "H-4470\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-4470\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-4470\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-4906\tThank you .\n",
            "T-4906\tCám ơn các bạn .\n",
            "H-4906\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-4906\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-4906\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5023\tThank you .\n",
            "T-5023\tCám ơn các bạn .\n",
            "H-5023\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5023\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5023\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5187\tThank you .\n",
            "T-5187\tCám ơn các bạn .\n",
            "H-5187\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5187\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5187\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5665\tThank you .\n",
            "T-5665\tVỗ tay Cám ơn\n",
            "H-5665\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5665\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5665\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5698\tThank you .\n",
            "T-5698\tCảm ơn quý vị .\n",
            "H-5698\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5698\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5698\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5778\tThank you .\n",
            "T-5778\tCảm ơn các bạn .\n",
            "H-5778\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5778\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5778\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5865\tThank you .\n",
            "T-5865\tCảm ơn các bạn .\n",
            "H-5865\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5865\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5865\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-6241\tThank you .\n",
            "T-6241\tCảm ơn các bạn .\n",
            "H-6241\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-6241\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-6241\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-7445\tThank you .\n",
            "T-7445\tCảm ơn các bạn .\n",
            "H-7445\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-7445\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-7445\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2442\tThank you .\n",
            "T-2442\tXin cảm ơn các bạn .\n",
            "H-2442\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2442\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2442\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2444\tThank you .\n",
            "T-2444\tXin cảm ơn các bạn .\n",
            "H-2444\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2444\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2444\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2611\t1.5 million .\n",
            "T-2611\t1,5 triệu USD .\n",
            "H-2611\t-0.15661971271038055\t1.5 triệu .\n",
            "D-2611\t-0.15661971271038055\t1.5 triệu .\n",
            "P-2611\t-0.0720 -0.0874 -0.3770 -0.0901\n",
            "S-4552\tThank you .\n",
            "T-4552\tXin cám ơn các bạn .\n",
            "H-4552\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-4552\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-4552\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2157\t... yet .\n",
            "T-2157\tlà 1 tài năng nghệ thuật ...\n",
            "H-2157\t-0.6786201596260071\tTuy nhiên ...\n",
            "D-2157\t-0.6786201596260071\tTuy nhiên ...\n",
            "P-2157\t-2.0721 -0.3159 -0.2281 -0.0983\n",
            "S-3339\tThank you .\n",
            "T-3339\tXin cám ơn các bạn đã lắng nghe\n",
            "H-3339\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-3339\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-3339\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-6726\tWill you ?\n",
            "T-6726\tCác bạn cũng như thế phải không ?\n",
            "H-6726\t-0.7439743876457214\tBạn sẽ mua chứ ?\n",
            "D-6726\t-0.7439743876457214\tBạn sẽ mua chứ ?\n",
            "P-6726\t-0.9003 -0.2675 -3.0115 -0.1286 -0.0557 -0.1004\n",
            "S-3369\tThank you .\n",
            "T-3369\tCảm ơn các bạn .\n",
            "H-3369\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-3369\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-3369\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-1677\tThank you .\n",
            "T-1677\tCảm ơn .\n",
            "H-1677\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-1677\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-1677\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-3079\tThank you .\n",
            "T-3079\tCảm ơn ,\n",
            "H-3079\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-3079\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-3079\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-3070\tThank you .\n",
            "T-3070\tCảm ơn .\n",
            "H-3070\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-3070\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-3070\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-3022\tThank you .\n",
            "T-3022\tCảm ơn .\n",
            "H-3022\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-3022\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-3022\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2990\tThank you .\n",
            "T-2990\tCảm ơn .\n",
            "H-2990\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2990\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2990\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2936\tThank you .\n",
            "T-2936\tCảm ơn .\n",
            "H-2936\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2936\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2936\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2534\tThank you .\n",
            "T-2534\tCám ơn .\n",
            "H-2534\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2534\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2534\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2482\tThank you .\n",
            "T-2482\tCảm ơn .\n",
            "H-2482\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2482\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2482\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2470\tThank you .\n",
            "T-2470\tCảm ơn .\n",
            "H-2470\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2470\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2470\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2409\tThank you .\n",
            "T-2409\tCảm ơn .\n",
            "H-2409\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2409\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2409\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-1895\t60,000 .\n",
            "T-1895\t60,000 .\n",
            "H-1895\t-0.29238641262054443\t60,000 .\n",
            "D-1895\t-0.29238641262054443\t60,000 .\n",
            "P-1895\t-0.2218 -0.4626 -0.3882 -0.0969\n",
            "S-1894\t60,000 .\n",
            "T-1894\t60,000 .\n",
            "H-1894\t-0.29238641262054443\t60,000 .\n",
            "D-1894\t-0.29238641262054443\t60,000 .\n",
            "P-1894\t-0.2218 -0.4626 -0.3882 -0.0969\n",
            "S-1884\tThank you .\n",
            "T-1884\tCảm ơn .\n",
            "H-1884\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-1884\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-1884\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-1743\tThank you .\n",
            "T-1743\tCám ơn .\n",
            "H-1743\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-1743\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-1743\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2327\tThank you .\n",
            "T-2327\tCảm ơn các bạn .\n",
            "H-2327\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2327\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2327\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-696\tThank you .\n",
            "T-696\tCám ơn .\n",
            "H-696\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-696\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-696\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-676\tHello !\n",
            "T-676\tXin chào !\n",
            "H-676\t-0.03597245365381241\tXin chào !\n",
            "D-676\t-0.03597245365381241\tXin chào !\n",
            "P-676\t-0.0106 -0.0091 -0.0234 -0.1008\n",
            "S-656\tThank you .\n",
            "T-656\tCám ơn .\n",
            "H-656\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-656\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-656\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-452\tThank you .\n",
            "T-452\tCảm ơn .\n",
            "H-452\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-452\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-452\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-417\tOlé !\n",
            "T-417\tOle !\n",
            "H-417\t-0.9993134140968323\tOlof the !\n",
            "D-417\t-0.9993134140968323\tOlof the !\n",
            "P-417\t-0.2098 -1.5799 -1.8156 -1.2934 -0.0979\n",
            "S-416\tThank you .\n",
            "T-416\tCám ơn .\n",
            "H-416\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-416\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-416\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-415\tThank you .\n",
            "T-415\tCám ơn .\n",
            "H-415\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-415\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-415\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-165\tWhoa !\n",
            "T-165\tWhoa !\n",
            "H-165\t-0.03775092586874962\tWhoa !\n",
            "D-165\t-0.03775092586874962\tWhoa !\n",
            "P-165\t-0.0121 -0.0033 -0.0433 -0.0923\n",
            "S-7030\tThank you .\n",
            "T-7030\tCảm ơn\n",
            "H-7030\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-7030\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-7030\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5819\tThank you .\n",
            "T-5819\tCảm ơn\n",
            "H-5819\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5819\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5819\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5383\tThank you .\n",
            "T-5383\tCảm ơn\n",
            "H-5383\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5383\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5383\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-4137\tAll right .\n",
            "T-4137\tĐược rồi\n",
            "H-4137\t-0.12827478349208832\tĐược rồi .\n",
            "D-4137\t-0.12827478349208832\tĐược rồi .\n",
            "P-4137\t-0.1121 -0.0670 -0.2384 -0.0956\n",
            "S-4967\tThank you .\n",
            "T-4967\tCảm ơn .\n",
            "H-4967\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-4967\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-4967\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2168\tThank you .\n",
            "T-2168\tCảm ơn các bạn .\n",
            "H-2168\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2168\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2168\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2109\tThank you .\n",
            "T-2109\tCảm ơn các bạn .\n",
            "H-2109\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-2109\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-2109\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-1676\tThank you .\n",
            "T-1676\tCảm ơn các bạn .\n",
            "H-1676\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-1676\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-1676\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-1239\tThank you .\n",
            "T-1239\tCảm ơn các bạn .\n",
            "H-1239\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-1239\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-1239\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-7226\tThank you .\n",
            "T-7226\tXin cảm ơn !\n",
            "H-7226\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-7226\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-7226\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-6956\tThank you .\n",
            "T-6956\tXin cảm ơn .\n",
            "H-6956\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-6956\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-6956\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-6575\tThank you .\n",
            "T-6575\tXin cảm ơn .\n",
            "H-6575\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-6575\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-6575\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5709\tAll right .\n",
            "T-5709\tXong rồi .\n",
            "H-5709\t-0.12827478349208832\tĐược rồi .\n",
            "D-5709\t-0.12827478349208832\tĐược rồi .\n",
            "P-5709\t-0.1121 -0.0670 -0.2384 -0.0956\n",
            "S-5227\tThank you .\n",
            "T-5227\tCảm ơn bạn .\n",
            "H-5227\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5227\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5227\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-4858\tThank you .\n",
            "T-4858\tXin cảm ơn .\n",
            "H-4858\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-4858\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-4858\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-3544\tThank you .\n",
            "T-3544\tXin cám ơn .\n",
            "H-3544\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-3544\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-3544\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-2700\tUnique .\n",
            "T-2700\tNét riêng biệt\n",
            "H-2700\t-0.827048122882843\tUnique .\n",
            "D-2700\t-0.827048122882843\tUnique .\n",
            "P-2700\t-2.5033 -0.2715 -0.4332 -0.1002\n",
            "S-802\tThank you .\n",
            "T-802\tXin cảm ơn .\n",
            "H-802\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-802\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-802\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-1889\tSure .\n",
            "T-1889\tChắc chắn rồi .\n",
            "H-1889\t-0.3988112509250641\tChắc chắn rồi .\n",
            "D-1889\t-0.3988112509250641\tChắc chắn rồi .\n",
            "P-1889\t-0.1963 -0.0073 -1.3983 -0.2924 -0.0998\n",
            "S-4068\tThank you .\n",
            "T-4068\tCảm ơn .\n",
            "H-4068\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-4068\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-4068\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5275\tThank you .\n",
            "T-5275\tXin cám ơn\n",
            "H-5275\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5275\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5275\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5296\tNot exactly .\n",
            "T-5296\tKhông đúng .\n",
            "H-5296\t-0.4668566584587097\tKhông hẳn chính xác .\n",
            "D-5296\t-0.4668566584587097\tKhông hẳn chính xác .\n",
            "P-5296\t-0.3018 -0.3542 -1.4473 -0.0126 -0.5851 -0.1000\n",
            "S-5497\tThank you .\n",
            "T-5497\tCám ơn .\n",
            "H-5497\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5497\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5497\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5587\tThank you .\n",
            "T-5587\tCảm ơn .\n",
            "H-5587\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5587\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5587\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5614\tThank you .\n",
            "T-5614\tCảm ơn .\n",
            "H-5614\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5614\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5614\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5818\tThank you .\n",
            "T-5818\tCảm ơn .\n",
            "H-5818\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5818\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5818\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-5978\tThank you .\n",
            "T-5978\tCảm ơn .\n",
            "H-5978\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-5978\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-5978\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-6164\tThank you .\n",
            "T-6164\tCám ơn .\n",
            "H-6164\t-0.31394824385643005\tXin cảm ơn .\n",
            "D-6164\t-0.31394824385643005\tXin cảm ơn .\n",
            "P-6164\t-0.0356 -0.8498 -0.0994 -0.4935 -0.0914\n",
            "S-325\tMaybe not .\n",
            "T-325\tCó thể không .\n",
            "H-325\t-0.4039933979511261\tCó lẽ không .\n",
            "D-325\t-0.4039933979511261\tCó lẽ không .\n",
            "P-325\t-0.1508 -1.0860 -0.3601 -0.3208 -0.1023\n",
            "S-2621\tOkay .\n",
            "T-2621\tTuyệt .\n",
            "H-2621\t-0.38454189896583557\tĐược rồi .\n",
            "D-2621\t-0.38454189896583557\tĐược rồi .\n",
            "P-2621\t-0.6754 -0.5165 -0.2545 -0.0918\n",
            "S-2971\tYeah .\n",
            "T-2971\tVâng .\n",
            "H-2971\t-0.43013471364974976\tVâng .\n",
            "D-2971\t-0.43013471364974976\tVâng .\n",
            "P-2971\t-0.8790 -0.3168 -0.0947\n",
            "S-4479\tNo .\n",
            "T-4479\tKhông .\n",
            "H-4479\t-0.1397802233695984\tKhông .\n",
            "D-4479\t-0.1397802233695984\tKhông .\n",
            "P-4479\t-0.0749 -0.2426 -0.1019\n",
            "S-6014\tThanks .\n",
            "T-6014\tCảm ơn\n",
            "H-6014\t-0.33725205063819885\tXin cám ơn .\n",
            "D-6014\t-0.33725205063819885\tXin cám ơn .\n",
            "P-6014\t-0.1254 -0.9920 -0.0570 -0.4202 -0.0915\n",
            "S-6874\tGo !\n",
            "T-6874\tĐi !\n",
            "H-6874\t-0.7567009329795837\tTiến lên !\n",
            "D-6874\t-0.7567009329795837\tTiến lên !\n",
            "P-6874\t-2.6196 -0.1804 -0.1505 -0.0763\n",
            "S-6879\tOh !\n",
            "T-6879\tOh !\n",
            "H-6879\t-0.4861622750759125\tỒ !\n",
            "D-6879\t-0.4861622750759125\tỒ !\n",
            "P-6879\t-1.1467 -0.2006 -0.1112\n",
            "S-2396\tReally .\n",
            "T-2396\tThật đấy .\n",
            "H-2396\t-0.7592474818229675\tThực sự .\n",
            "D-2396\t-0.7592474818229675\tThực sự .\n",
            "P-2396\t-1.7342 -0.5260 -0.6798 -0.0970\n",
            "S-2485\tThanks .\n",
            "T-2485\tcảm ơn .\n",
            "H-2485\t-0.33725205063819885\tXin cám ơn .\n",
            "D-2485\t-0.33725205063819885\tXin cám ơn .\n",
            "P-2485\t-0.1254 -0.9920 -0.0570 -0.4202 -0.0915\n",
            "S-4481\tOkay .\n",
            "T-4481\tĐược rồi .\n",
            "H-4481\t-0.38454189896583557\tĐược rồi .\n",
            "D-4481\t-0.38454189896583557\tĐược rồi .\n",
            "P-4481\t-0.6754 -0.5165 -0.2545 -0.0918\n",
            "S-2624\tYeah .\n",
            "T-2624\tTất nhiên rồi .\n",
            "H-2624\t-0.43013471364974976\tVâng .\n",
            "D-2624\t-0.43013471364974976\tVâng .\n",
            "P-2624\t-0.8790 -0.3168 -0.0947\n",
            "S-3180\tThanks .\n",
            "T-3180\tXin cảm ơn .\n",
            "H-3180\t-0.33725205063819885\tXin cám ơn .\n",
            "D-3180\t-0.33725205063819885\tXin cám ơn .\n",
            "P-3180\t-0.1254 -0.9920 -0.0570 -0.4202 -0.0915\n",
            "S-6870\tGo .\n",
            "T-6870\tĐi\n",
            "H-6870\t-0.9310383796691895\tHãy đi .\n",
            "D-6870\t-0.9310383796691895\tHãy đi .\n",
            "P-6870\t-2.0939 -0.9508 -0.6079 -0.0715\n",
            "  2% 1/60 [00:01<01:21,  1.39s/it, wps=466]S-6727\tThank you very much .\n",
            "T-6727\tChân thành cảm ơn .\n",
            "H-6727\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-6727\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-6727\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-2000\tThe farm &apos;s incredible .\n",
            "T-2000\tTrang trại này hay lắm .\n",
            "H-2000\t-0.8431110382080078\tnông trại tuyệt vời .\n",
            "D-2000\t-0.8431110382080078\tnông trại tuyệt vời .\n",
            "P-2000\t-1.7218 -0.0142 -2.7800 -0.1323 -0.3136 -0.0968\n",
            "S-1994\tWhat did they do ?\n",
            "T-1994\tHọ đã làm gì với nó ?\n",
            "H-1994\t-0.20118388533592224\tHọ đã làm gì ?\n",
            "D-1994\t-0.20118388533592224\tHọ đã làm gì ?\n",
            "P-1994\t-0.3186 -0.3177 -0.0867 -0.2155 -0.1686 -0.0999\n",
            "S-1598\tNext would be nuclear .\n",
            "T-1598\tTiếp theo sẽ là hạt nhân .\n",
            "H-1598\t-0.4312392771244049\tTiếp theo là hạt nhân .\n",
            "D-1598\t-0.4312392771244049\tTiếp theo là hạt nhân .\n",
            "P-1598\t-1.2149 -0.3693 -0.9455 -0.0155 -0.0145 -0.3662 -0.0928\n",
            "S-1475\tOh , that guy .\n",
            "T-1475\tÔ , người đàn ông đó .\n",
            "H-1475\t-0.44110140204429626\tỒ , anh chàng đó .\n",
            "D-1475\t-0.44110140204429626\tỒ , anh chàng đó .\n",
            "P-1475\t-0.5091 -0.1403 -0.6868 -0.5772 -0.6990 -0.3711 -0.1043\n",
            "S-1461\tThere &apos;s no normal .\n",
            "T-1461\tChẳng có gì là bình thường .\n",
            "H-1461\t-0.5637627243995667\tKhông có bình thường .\n",
            "D-1461\t-0.5637627243995667\tKhông có bình thường .\n",
            "P-1461\t-0.5345 -0.5784 -1.6816 -0.0605 -0.4292 -0.0984\n",
            "S-832\tIt &apos;s a crisis .\n",
            "T-832\tĐó là một cuộc khủng hoảng .\n",
            "H-832\t-0.3215055763721466\tĐó là một cuộc khủng hoảng .\n",
            "D-832\t-0.3215055763721466\tĐó là một cuộc khủng hoảng .\n",
            "P-832\t-0.4149 -0.1708 -0.9848 -0.6097 -0.0118 -0.0253 -0.2539 -0.1009\n",
            "S-757\tThank you so much .\n",
            "T-757\tCảm ơn các bạn rất nhiều .\n",
            "H-757\t-0.3835994303226471\tXin cảm ơn .\n",
            "D-757\t-0.3835994303226471\tXin cảm ơn .\n",
            "P-757\t-0.1131 -0.6411 -0.0964 -0.9756 -0.0918\n",
            "S-407\tJust do your job .\n",
            "T-407\tHãy làm công việc của mình .\n",
            "H-407\t-0.5060932040214539\tHãy làm công việc của bạn .\n",
            "D-407\t-0.5060932040214539\tHãy làm công việc của bạn .\n",
            "P-407\t-1.2375 -0.3118 -0.7380 -0.0199 -0.1401 -1.0302 -0.4659 -0.1053\n",
            "S-244\tThank you very much .\n",
            "T-244\tCảm ơn tất cả các bạn .\n",
            "H-244\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-244\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-244\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-7368\tAnd you love it .\n",
            "T-7368\tVà các bạn thích nó .\n",
            "H-7368\t-0.49543535709381104\tVà bạn yêu nó .\n",
            "D-7368\t-0.49543535709381104\tVà bạn yêu nó .\n",
            "P-7368\t-0.6350 -0.3913 -1.0369 -0.5846 -0.2289 -0.0959\n",
            "S-7361\tIt &apos;s about concrete .\n",
            "T-7361\tĐó là về bê tông .\n",
            "H-7361\t-0.287557989358902\tĐó là về bê tông .\n",
            "D-7361\t-0.287557989358902\tĐó là về bê tông .\n",
            "P-7361\t-1.0284 -0.1627 -0.4329 -0.1798 -0.0074 -0.0909 -0.1108\n",
            "S-7336\tThis is a trick .\n",
            "T-7336\tĐây là một mẹo .\n",
            "H-7336\t-0.3790091574192047\tĐây là một trò mẹo .\n",
            "D-7336\t-0.3790091574192047\tĐây là một trò mẹo .\n",
            "P-7336\t-0.3889 -0.1689 -0.8834 -0.2112 -0.9407 -0.0206 -0.3118 -0.1067\n",
            "S-7327\tAnd that &apos;s architecture .\n",
            "T-7327\tVà đó là kiến trúc .\n",
            "H-7327\t-0.1955065280199051\tVà đó là kiến trúc .\n",
            "D-7327\t-0.1955065280199051\tVà đó là kiến trúc .\n",
            "P-7327\t-0.3787 -0.1985 -0.3330 -0.1766 -0.0281 -0.1496 -0.1041\n",
            "S-6873\tAll right , ready ?\n",
            "T-6873\tĐược chứ , sẵn sàng ?\n",
            "H-6873\t-0.1449640542268753\tĐược rồi , sẵn sàng chưa ?\n",
            "D-6873\t-0.1449640542268753\tĐược rồi , sẵn sàng chưa ?\n",
            "P-6873\t-0.3894 -0.0893 -0.2443 -0.1342 -0.0115 -0.0613 -0.1330 -0.0967\n",
            "S-6852\tThank you very much .\n",
            "T-6852\tXin chân thành cảm ơn .\n",
            "H-6852\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-6852\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-6852\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-2118\tYou could see Manhattan .\n",
            "T-2118\tTôi vẫn nhìn thấy được Manhattan .\n",
            "H-2118\t-0.23995386064052582\tBạn có thể thấy Manhattan .\n",
            "D-2118\t-0.23995386064052582\tBạn có thể thấy Manhattan .\n",
            "P-2118\t-0.4033 -0.1742 -0.0897 -0.3547 -0.0497 -0.5091 -0.0990\n",
            "S-6587\tShe can have fun .\n",
            "T-6587\tNó có thể vui chơi .\n",
            "H-6587\t-0.5403679013252258\tCô ấy có thể vui .\n",
            "D-6587\t-0.5403679013252258\tCô ấy có thể vui .\n",
            "P-6587\t-0.4334 -0.6606 -0.2236 -0.0769 -0.9357 -1.3574 -0.0950\n",
            "S-5470\tToday I am 22 .\n",
            "T-5470\tHôm nay tôi 22 tuổi .\n",
            "H-5470\t-0.2402576357126236\tHôm nay tôi 22 tuổi .\n",
            "D-5470\t-0.2402576357126236\tHôm nay tôi 22 tuổi .\n",
            "P-5470\t-0.1422 -0.0553 -0.1575 -0.5739 -0.3169 -0.3412 -0.0948\n",
            "S-5345\tThe answer is easy .\n",
            "T-5345\tCâu trả lời rất dễ .\n",
            "H-5345\t-0.37633973360061646\tCâu trả lời rất dễ .\n",
            "D-5345\t-0.37633973360061646\tCâu trả lời rất dễ .\n",
            "P-5345\t-0.0433 -0.0351 -0.0310 -1.8478 -0.2014 -0.3743 -0.1014\n",
            "S-5223\tYou can be extraordinary .\n",
            "T-5223\tBạn có thể phi thường .\n",
            "H-5223\t-0.7136979699134827\tBạn có thể phi thường .\n",
            "D-5223\t-0.7136979699134827\tBạn có thể phi thường .\n",
            "P-5223\t-0.3878 -0.1568 -0.1021 -3.9378 -0.0055 -0.3080 -0.0980\n",
            "S-5172\tI lost all hope .\n",
            "T-5172\tTôi hoàn toàn tuyệt vọng .\n",
            "H-5172\t-0.572253942489624\tTôi mất tất cả hy vọng .\n",
            "D-5172\t-0.572253942489624\tTôi mất tất cả hy vọng .\n",
            "P-5172\t-0.0950 -1.4818 -1.4963 -0.0672 -1.0412 -0.0505 -0.2454 -0.1005\n",
            "S-4772\tAnd that &apos;s important .\n",
            "T-4772\tĐiều đó thật quan trọng .\n",
            "H-4772\t-0.5008870959281921\tVà điều đó rất quan trọng .\n",
            "D-4772\t-0.5008870959281921\tVà điều đó rất quan trọng .\n",
            "P-4772\t-1.1337 -0.3358 -0.8982 -1.2187 -0.0491 -0.0495 -0.2239 -0.0982\n",
            "S-4721\tWe &apos;re taking off .\n",
            "T-4721\tChúng ta đang cất cánh .\n",
            "H-4721\t-0.731768786907196\tChúng tôi cất cánh .\n",
            "D-4721\t-0.731768786907196\tChúng tôi cất cánh .\n",
            "P-4721\t-0.1455 -1.8728 -2.0058 -0.0240 -0.2441 -0.0985\n",
            "S-4464\tWhat does it mean ?\n",
            "T-4464\tĐiều này có nghĩa gì ?\n",
            "H-4464\t-0.3474108874797821\tNó có nghĩa là gì ?\n",
            "D-4464\t-0.3474108874797821\tNó có nghĩa là gì ?\n",
            "P-4464\t-1.3997 -0.2632 -0.2829 -0.2477 -0.0322 -0.1069 -0.0993\n",
            "S-4202\tHey , why not ?\n",
            "T-4202\tỒ , tại sao không ?\n",
            "H-4202\t-0.32304316759109497\tNày , tại sao không ?\n",
            "D-4202\t-0.32304316759109497\tNày , tại sao không ?\n",
            "P-4202\t-0.9605 -0.1290 -0.3191 -0.0415 -0.2555 -0.4601 -0.0955\n",
            "S-4197\tThank you very much .\n",
            "T-4197\tCảm ơn các bạn rất nhiều\n",
            "H-4197\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-4197\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-4197\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-3631\tMy hunches again .\n",
            "T-3631\tLại là linh cảm .\n",
            "H-3631\t-1.238802194595337\tMột lần nữa đi săn .\n",
            "D-3631\t-1.238802194595337\tMột lần nữa đi săn .\n",
            "P-3631\t-3.6587 -0.0067 -0.0167 -3.2399 -0.2147 -1.4310 -0.1039\n",
            "S-3630\tafter only one trip .\n",
            "T-3630\tsau có một chuyến đi .\n",
            "H-3630\t-0.3474244773387909\tChỉ sau một chuyến đi .\n",
            "D-3630\t-0.3474244773387909\tChỉ sau một chuyến đi .\n",
            "P-3630\t-1.3033 -0.1206 -0.2545 -0.1462 -0.1430 -0.3651 -0.0993\n",
            "S-3555\tHe is my grandfather .\n",
            "T-3555\tÔng là ông của tôi .\n",
            "H-3555\t-0.6196386814117432\tAnh ấy là ông tôi .\n",
            "D-3555\t-0.6196386814117432\tAnh ấy là ông tôi .\n",
            "P-3555\t-1.7702 -0.9056 -0.2722 -0.4164 -0.6194 -0.2561 -0.0977\n",
            "S-2986\tPlay &apos;s essential .\n",
            "T-2986\tchơi đùa là cần thiết .\n",
            "H-2986\t-0.8014001250267029\tChơi cần thiết .\n",
            "D-2986\t-0.8014001250267029\tChơi cần thiết .\n",
            "P-2986\t-0.9787 -0.5284 -2.9620 -0.0012 -0.2458 -0.0923\n",
            "S-2696\tI don &apos;t know .\n",
            "T-2696\tTôi cũng không biết nữa .\n",
            "H-2696\t-0.18499793112277985\tTôi không biết .\n",
            "D-2696\t-0.18499793112277985\tTôi không biết .\n",
            "P-2696\t-0.1711 -0.1267 -0.1812 -0.3432 -0.1028\n",
            "S-6751\tThis is the cord .\n",
            "T-6751\tMấu chốt nằm ở đây .\n",
            "H-6751\t-0.33705025911331177\tĐây là sợi dây .\n",
            "D-6751\t-0.33705025911331177\tĐây là sợi dây .\n",
            "P-6751\t-0.3825 -0.1471 -1.0856 -0.0809 -0.2232 -0.1031\n",
            "S-6162\tWe activate communities .\n",
            "T-6162\tChúng tôi kích hoạt những cộng đồng .\n",
            "H-6162\t-0.30597805976867676\tChúng tôi kích hoạt các cộng đồng .\n",
            "D-6162\t-0.30597805976867676\tChúng tôi kích hoạt các cộng đồng .\n",
            "P-6162\t-0.1363 -0.3912 -0.0725 -0.3194 -1.2357 -0.0845 -0.0376 -0.3803 -0.0963\n",
            "S-5088\tWhy should I worry ?\n",
            "T-5088\tVậy tại sao tôi phải lo lắng ?\n",
            "H-5088\t-0.25376468896865845\tTại sao tôi phải lo lắng ?\n",
            "D-5088\t-0.25376468896865845\tTại sao tôi phải lo lắng ?\n",
            "P-5088\t-0.1949 -0.0521 -0.6297 -0.8711 -0.0649 -0.0283 -0.0895 -0.0996\n",
            "S-4421\tSo what happened here ?\n",
            "T-4421\tVậy điều gì xảy ra ở đây ?\n",
            "H-4421\t-0.36606696248054504\tVậy điều gì đã xảy ra ở đây ?\n",
            "D-4421\t-0.36606696248054504\tVậy điều gì đã xảy ra ở đây ?\n",
            "P-4421\t-1.2264 -0.9093 -0.0466 -0.6184 -0.1486 -0.0919 -0.3505 -0.0804 -0.0901 -0.0984\n",
            "S-4236\tAnd so I did .\n",
            "T-4236\tVà thế là tôi cố hoàn hảo .\n",
            "H-4236\t-0.6613807678222656\tVà thế là tôi đã làm được .\n",
            "D-4236\t-0.6613807678222656\tVà thế là tôi đã làm được .\n",
            "P-4236\t-0.8187 -1.8273 -0.2868 -0.1144 -0.4353 -0.2429 -1.8036 -0.3272 -0.0961\n",
            "S-3165\tBut it gets worse .\n",
            "T-3165\tNhưng mọi sự còn tệ hơn nữa .\n",
            "H-3165\t-0.5424206852912903\tNhưng nó tệ hơn .\n",
            "D-3165\t-0.5424206852912903\tNhưng nó tệ hơn .\n",
            "P-3165\t-0.2638 -0.8512 -1.5943 -0.0636 -0.3742 -0.1073\n",
            "S-3137\tAn almost identical structure .\n",
            "T-3137\tMột cấu trúc hoàn toàn tương tự .\n",
            "H-3137\t-0.2976326048374176\tMột cấu trúc giống hệt nhau .\n",
            "D-3137\t-0.2976326048374176\tMột cấu trúc giống hệt nhau .\n",
            "P-3137\t-0.4437 -0.1450 -0.0285 -0.4411 -0.8095 -0.1429 -0.2726 -0.0978\n",
            "S-3044\tDoes that sound good ?\n",
            "T-3044\tNghe có vẻ thú vị phải không ?\n",
            "H-3044\t-0.673240065574646\tNghe hay phải không ?\n",
            "D-3044\t-0.673240065574646\tNghe hay phải không ?\n",
            "P-3044\t-0.8200 -1.2232 -1.4582 -0.0836 -0.3476 -0.1069\n",
            "S-2913\tThese changes are coming .\n",
            "T-2913\tNhững thay đổi này đang tới gần .\n",
            "H-2913\t-0.3712487518787384\tNhững thay đổi này đang đến .\n",
            "D-2913\t-0.3712487518787384\tNhững thay đổi này đang đến .\n",
            "P-2913\t-0.3212 -0.3070 -0.0219 -0.4499 -0.5798 -0.7328 -0.4637 -0.0937\n",
            "S-2844\tMaybe 10 times more .\n",
            "T-2844\tCó thể nhiều hơn đến 10 lần .\n",
            "H-2844\t-0.5814175605773926\tCó thể là 10 lần .\n",
            "D-2844\t-0.5814175605773926\tCó thể là 10 lần .\n",
            "P-2844\t-0.1409 -0.7211 -1.6068 -0.8798 -0.0300 -0.5902 -0.1011\n",
            "S-2025\tThere is no feed .\n",
            "T-2025\tKhông có thức ăn dành cho cá .\n",
            "H-2025\t-0.41167202591896057\tKhông có thức ăn .\n",
            "D-2025\t-0.41167202591896057\tKhông có thức ăn .\n",
            "P-2025\t-0.4420 -0.8947 -0.7259 -0.0081 -0.3024 -0.0969\n",
            "S-1344\tAnd this was fascinating .\n",
            "T-1344\tVà điều này thực sự hấp dẫn .\n",
            "H-1344\t-0.5463621020317078\tVà điều này thật thú vị .\n",
            "D-1344\t-0.5463621020317078\tVà điều này thật thú vị .\n",
            "P-1344\t-1.3305 -0.3305 -0.3516 -0.4151 -1.5817 -0.0241 -0.2378 -0.0996\n",
            "S-1180\tThis is really exciting .\n",
            "T-1180\tĐiều này thực sự gây hào hứng .\n",
            "H-1180\t-0.4796418845653534\tĐiều này thực sự rất thú vị .\n",
            "D-1180\t-0.4796418845653534\tĐiều này thực sự rất thú vị .\n",
            "P-1180\t-0.6883 -0.3009 -1.3470 -0.0610 -1.1366 -0.3830 -0.0236 -0.2823 -0.0941\n",
            "S-658\tThey really loved it .\n",
            "T-658\tBọn trẻ thật sự thích nó .\n",
            "H-658\t-0.5799670219421387\tHọ rất thích nó .\n",
            "D-658\t-0.5799670219421387\tHọ rất thích nó .\n",
            "P-658\t-0.4927 -1.5775 -0.3505 -0.7375 -0.2223 -0.0994\n",
            "S-7427\tEverything is different now .\n",
            "T-7427\tMọi thứ nay đều khác biệt .\n",
            "H-7427\t-0.46698978543281555\tMọi thứ đều khác nhau .\n",
            "D-7427\t-0.46698978543281555\tMọi thứ đều khác nhau .\n",
            "P-7427\t-0.4782 -0.1387 -1.2323 -0.1253 -0.8715 -0.3197 -0.1032\n",
            "S-7316\tLet &apos;s do this .\n",
            "T-7316\tHãy cùng nhau làm điều đó .\n",
            "H-7316\t-0.5109720826148987\tHãy làm điều này .\n",
            "D-7316\t-0.5109720826148987\tHãy làm điều này .\n",
            "P-7316\t-0.6378 -0.5954 -0.9165 -0.4061 -0.4066 -0.1034\n",
            "S-2681\tBan is blank .\n",
            "T-2681\tBan chưa là gì hết .\n",
            "H-2681\t-1.0098992586135864\tchiếc xe tăng .\n",
            "D-2681\t-1.0098992586135864\tchiếc xe tăng .\n",
            "P-2681\t-3.5921 -0.0338 -0.8630 -0.4622 -0.0985\n",
            "S-6569\tThese are huge questions .\n",
            "T-6569\tĐây là một câu hỏi lớn .\n",
            "H-6569\t-0.3320075571537018\tĐây là những câu hỏi lớn .\n",
            "D-6569\t-0.3320075571537018\tĐây là những câu hỏi lớn .\n",
            "P-6569\t-0.5007 -0.1309 -0.3752 -0.0853 -0.0241 -1.2064 -0.2348 -0.0988\n",
            "S-6424\tThank you very much .\n",
            "T-6424\tCảm ơn quý vị rất nhiều .\n",
            "H-6424\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-6424\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-6424\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-6230\tWe take photos constantly .\n",
            "T-6230\tChúng tôi chụp ảnh liên tục .\n",
            "H-6230\t-0.3670220971107483\tChúng tôi chụp ảnh liên tục .\n",
            "D-6230\t-0.3670220971107483\tChúng tôi chụp ảnh liên tục .\n",
            "P-6230\t-0.1860 -0.5304 -1.1573 -0.2917 -0.3012 -0.0070 -0.3640 -0.0986\n",
            "S-6204\tIt could take months .\n",
            "T-6204\tCó thể mất đến hàng tháng .\n",
            "H-6204\t-0.6528136730194092\tNó có thể mất hàng tháng .\n",
            "D-6204\t-0.6528136730194092\tNó có thể mất hàng tháng .\n",
            "P-6204\t-2.7838 -0.9438 -0.0775 -0.0509 -0.6832 -0.0928 -0.4956 -0.0950\n",
            "S-4927\tWhat creates the illusion ?\n",
            "T-4927\tĐiều gì tạo nên ảo giác ?\n",
            "H-4927\t-0.5632737874984741\tCái gì tạo ra ảo giác ?\n",
            "D-4927\t-0.5632737874984741\tCái gì tạo ra ảo giác ?\n",
            "P-4927\t-2.4652 -0.0205 -0.1098 -0.7523 -0.0129 -1.0075 -0.0326 -0.1054\n",
            "S-4322\tHe kept pointing here .\n",
            "T-4322\tAnh ta cứ chỉ vào đó .\n",
            "H-4322\t-0.9918436408042908\tAnh ấy giữ ở đây .\n",
            "D-4322\t-0.9918436408042908\tAnh ấy giữ ở đây .\n",
            "P-4322\t-1.2136 -1.6309 -1.5405 -2.0844 -0.1473 -0.2230 -0.1032\n",
            "S-4182\tHow engaged you are .\n",
            "T-4182\tBạn thật bận rộn đó .\n",
            "H-4182\t-0.9490969777107239\tLàm thế nào mà bạn có thể tham gia .\n",
            "D-4182\t-0.9490969777107239\tLàm thế nào mà bạn có thể tham gia .\n",
            "P-4182\t-1.6609 -0.6463 -0.0551 -2.3552 -0.4815 -0.9737 -0.3494 -3.0419 -0.0517 -0.7229 -0.1015\n",
            "S-4153\tBut you know what ?\n",
            "T-4153\tnhưng bạn biết điều gì không ?\n",
            "H-4153\t-0.41948631405830383\tNhưng bạn biết không ?\n",
            "D-4153\t-0.41948631405830383\tNhưng bạn biết không ?\n",
            "P-4153\t-0.1401 -0.8034 -0.3835 -0.9478 -0.1421 -0.1001\n",
            "S-3933\tThank you very much .\n",
            "T-3933\tCảm ơn các bạn rất nhiều .\n",
            "H-3933\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-3933\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-3933\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-3298\tHere is the video .\n",
            "T-3298\tSau đây là một đoạn video .\n",
            "H-3298\t-0.3064265847206116\tĐây là video .\n",
            "D-3298\t-0.3064265847206116\tĐây là video .\n",
            "P-3298\t-0.1852 -0.1316 -0.8755 -0.2364 -0.1035\n",
            "S-3191\tGood afternoon , everybody .\n",
            "T-3191\tXin chào quý vị khán giả .\n",
            "H-3191\t-0.19667761027812958\tXin chào mọi người .\n",
            "D-3191\t-0.19667761027812958\tXin chào mọi người .\n",
            "P-3191\t-0.2251 -0.0260 -0.3594 -0.0774 -0.3979 -0.0941\n",
            "S-3183\tIs that your opinion ?\n",
            "T-3183\tÝ kiến của anh thế nào ?\n",
            "H-3183\t-0.5989015698432922\tCó phải ý kiến của bạn không ?\n",
            "D-3183\t-0.5989015698432922\tCó phải ý kiến của bạn không ?\n",
            "P-3183\t-2.1428 -0.0500 -1.2295 -0.2322 -0.2263 -0.9878 -0.3291 -0.0886 -0.1037\n",
            "S-3110\tSo they know everything .\n",
            "T-3110\tVậy là họ biết mọi thứ .\n",
            "H-3110\t-0.5918905138969421\tHọ biết mọi thứ .\n",
            "D-3110\t-0.5918905138969421\tHọ biết mọi thứ .\n",
            "P-3110\t-2.2890 -0.4854 -0.3208 -0.1263 -0.2305 -0.0993\n",
            "S-3078\tThank you very much .\n",
            "T-3078\tCảm ơn mọi người rất nhiều .\n",
            "H-3078\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-3078\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-3078\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-2687\tIt keeps you fresh .\n",
            "T-2687\tNó làm chúng ta tỉnh táo .\n",
            "H-2687\t-0.5941513180732727\tNó giữ cho bạn tươi mới .\n",
            "D-2687\t-0.5941513180732727\tNó giữ cho bạn tươi mới .\n",
            "P-2687\t-0.3586 -2.4871 -0.4225 -0.1459 -0.6738 -0.2796 -0.2785 -0.1072\n",
            "S-5040\tThese guys make money .\n",
            "T-5040\tKiếm tiền !\n",
            "H-5040\t-0.2882043123245239\tNhững người này kiếm tiền .\n",
            "D-5040\t-0.2882043123245239\tNhững người này kiếm tiền .\n",
            "P-5040\t-0.5191 -0.6975 -0.1873 -0.0855 -0.0402 -0.3943 -0.0935\n",
            "S-3586\tGo home to where ?\n",
            "T-3586\tVề nhà ở đâu ?\n",
            "H-3586\t-0.8028724193572998\tVề nhà để đi đâu ?\n",
            "D-3586\t-0.8028724193572998\tVề nhà để đi đâu ?\n",
            "P-3586\t-1.4348 -0.1074 -1.5078 -1.3769 -1.0341 -0.0648 -0.0943\n",
            "S-2925\tWhy not live longer ?\n",
            "T-2925\tSống lâu hơn ?\n",
            "H-2925\t-0.20400072634220123\tTại sao không sống lâu hơn ?\n",
            "D-2925\t-0.20400072634220123\tTại sao không sống lâu hơn ?\n",
            "P-2925\t-0.1258 -0.0558 -0.2283 -0.1959 -0.0386 -0.7892 -0.1004 -0.0981\n",
            "S-2632\tI was amazed .\n",
            "T-2632\tTôi đã rất sốc .\n",
            "H-2632\t-0.40875697135925293\tTôi kinh ngạc .\n",
            "D-2632\t-0.40875697135925293\tTôi kinh ngạc .\n",
            "P-2632\t-0.1350 -1.3984 -0.0304 -0.3808 -0.0993\n",
            "S-2439\tBe a mentor .\n",
            "T-2439\tlàm người hướng dẫn .\n",
            "H-2439\t-0.5587897896766663\tHãy trở thành người thầy .\n",
            "D-2439\t-0.5587897896766663\tHãy trở thành người thầy .\n",
            "P-2439\t-0.2306 -1.7799 -0.0113 -1.0799 -0.3932 -0.3159 -0.1007\n",
            "S-2084\tCan I be honest ?\n",
            "T-2084\tTôi nói thật nhé ?\n",
            "H-2084\t-0.633945643901825\tTôi có thể thành thật không ?\n",
            "D-2084\t-0.633945643901825\tTôi có thể thành thật không ?\n",
            "P-2084\t-0.6629 -1.2211 -0.5576 -1.2772 -0.1285 -0.9998 -0.1179 -0.1066\n",
            "S-989\tBut the point is ...\n",
            "T-989\tNhưng cái chính là ...\n",
            "H-989\t-0.4667997658252716\tNhưng vấn đề là ...\n",
            "D-989\t-0.4667997658252716\tNhưng vấn đề là ...\n",
            "P-989\t-0.2071 -0.9920 -0.0642 -0.4670 -1.0011 -0.0694\n",
            "S-804\tRobert Gupta .\n",
            "T-804\tRobert Gupta .\n",
            "H-804\t-0.09898564219474792\tRobert Gupta .\n",
            "D-804\t-0.09898564219474792\tRobert Gupta .\n",
            "P-804\t-0.0128 -0.0029 -0.0079 -0.0137 -0.4613 -0.0953\n",
            "S-670\tThe sun is rising .\n",
            "T-670\tMặt trời đang mọc .\n",
            "H-670\t-0.3674602806568146\tMặt trời đang tăng lên .\n",
            "D-670\t-0.3674602806568146\tMặt trời đang tăng lên .\n",
            "P-670\t-0.0143 -0.0270 -0.1241 -1.5845 -0.1862 -0.5370 -0.0991\n",
            "S-441\tThis was the result .\n",
            "T-441\tĐây là hậu quả .\n",
            "H-441\t-0.3486165702342987\tĐây là kết quả .\n",
            "D-441\t-0.3486165702342987\tĐây là kết quả .\n",
            "P-441\t-1.4360 -0.2103 -0.0945 -0.0324 -0.2131 -0.1054\n",
            "S-245\tI am a writer .\n",
            "T-245\tTôi là một nhà văn\n",
            "H-245\t-0.2860567271709442\tTôi là một nhà văn .\n",
            "D-245\t-0.2860567271709442\tTôi là một nhà văn .\n",
            "P-245\t-0.1186 -0.1972 -1.1596 -0.0904 -0.0323 -0.3077 -0.0966\n",
            "S-6700\tI resisted it .\n",
            "T-6700\tTôi phản đối .\n",
            "H-6700\t-0.9715567231178284\tTôi từ chối nó .\n",
            "D-6700\t-0.9715567231178284\tTôi từ chối nó .\n",
            "P-6700\t-0.1368 -4.5277 -0.0142 -0.7498 -0.2966 -0.1043\n",
            "S-2620\tI can help you .\n",
            "T-2620\tTôi có thể giúp anh .\n",
            "H-2620\t-0.31772974133491516\tTôi có thể giúp bạn .\n",
            "D-2620\t-0.31772974133491516\tTôi có thể giúp bạn .\n",
            "P-2620\t-0.3737 -0.2146 -0.1101 -0.0247 -1.1467 -0.2530 -0.1013\n",
            "S-4410\tOh , my God !\n",
            "T-4410\tÔi chúa ơi !\n",
            "H-4410\t-0.31284183263778687\tÔi , Chúa ơi !\n",
            "D-4410\t-0.31284183263778687\tÔi , Chúa ơi !\n",
            "P-4410\t-1.0200 -0.4266 -0.2653 -0.0377 -0.0225 -0.1050\n",
            "S-4049\tThank you very much .\n",
            "T-4049\tCám ơn rất nhiều\n",
            "H-4049\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-4049\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-4049\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-3659\tI don &apos;t know .\n",
            "T-3659\tTôi không biết .\n",
            "H-3659\t-0.18499793112277985\tTôi không biết .\n",
            "D-3659\t-0.18499793112277985\tTôi không biết .\n",
            "P-3659\t-0.1711 -0.1267 -0.1812 -0.3432 -0.1028\n",
            "S-3360\tSo here it is .\n",
            "T-3360\tVà nó đây .\n",
            "H-3360\t-0.7170554995536804\tVà đây là nó .\n",
            "D-3360\t-0.7170554995536804\tVà đây là nó .\n",
            "P-3360\t-1.0755 -0.5224 -1.5389 -0.8111 -0.2625 -0.0919\n",
            "S-3170\tIt is generic .\n",
            "T-3170\tNó chung chung .\n",
            "H-3170\t-1.1053361892700195\tNó là một loại thuốc .\n",
            "D-3170\t-1.1053361892700195\tNó là một loại thuốc .\n",
            "P-3170\t-0.6781 -1.0318 -1.9665 -1.7536 -1.1345 -1.0730 -0.0998\n",
            "S-2869\tHe answers the door .\n",
            "T-2869\tÔng mở cửa .\n",
            "H-2869\t-0.6063754558563232\tÔng trả lời cánh cửa .\n",
            "D-2869\t-0.6063754558563232\tÔng trả lời cánh cửa .\n",
            "P-2869\t-0.8334 -1.0307 -0.0168 -1.9109 -0.0058 -0.3440 -0.1029\n",
            "S-2744\tYeah . All right .\n",
            "T-2744\tÔkê . .\n",
            "H-2744\t-0.5315018892288208\tVâng .\n",
            "D-2744\t-0.5315018892288208\tVâng .\n",
            "P-2744\t-0.8245 -0.1985 -0.5715\n",
            "S-1886\tThank you so much .\n",
            "T-1886\tCảm ơn nhiều .\n",
            "H-1886\t-0.3835994303226471\tXin cảm ơn .\n",
            "D-1886\t-0.3835994303226471\tXin cảm ơn .\n",
            "P-1886\t-0.1131 -0.6411 -0.0964 -0.9756 -0.0918\n",
            "S-1020\tYeah , I know .\n",
            "T-1020\tVâng , tôi biết\n",
            "H-1020\t-0.24121294915676117\tVâng , tôi biết .\n",
            "D-1020\t-0.24121294915676117\tVâng , tôi biết .\n",
            "P-1020\t-0.4306 -0.1954 -0.2171 -0.1103 -0.3952 -0.0987\n",
            "S-2818\tThat &apos;s very good .\n",
            "T-2818\tRất tuyệt .\n",
            "H-2818\t-0.4466782510280609\tĐiều đó rất tốt .\n",
            "D-2818\t-0.4466782510280609\tĐiều đó rất tốt .\n",
            "P-2818\t-1.2191 -0.4998 -0.3788 -0.2603 -0.2250 -0.0970\n",
            "S-631\tThank you very much .\n",
            "T-631\tCám ơn nhiều\n",
            "H-631\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-631\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-631\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-4229\t1,000 , very good .\n",
            "T-4229\t1000 , tuyệt vời .\n",
            "H-4229\t-0.2752281725406647\t1000 , rất tốt .\n",
            "D-4229\t-0.2752281725406647\t1000 , rất tốt .\n",
            "P-4229\t-0.8457 -0.1389 -0.0573 -0.2710 -0.2466 -0.0918\n",
            "S-2582\tIt &apos;s a lot .\n",
            "T-2582\tchắc chắn là vô số .\n",
            "H-2582\t-0.6527745723724365\tNó rất nhiều .\n",
            "D-2582\t-0.6527745723724365\tNó rất nhiều .\n",
            "P-2582\t-1.4533 -0.9123 -0.5583 -0.2442 -0.0959\n",
            "S-2362\tSo I made one .\n",
            "T-2362\tTôi làm được một cái .\n",
            "H-2362\t-0.8915343880653381\tVì vậy tôi đã làm một cái .\n",
            "D-2362\t-0.8915343880653381\tVì vậy tôi đã làm một cái .\n",
            "P-2362\t-2.3249 -1.1015 -0.3040 -0.8922 -1.3726 -0.7998 -0.9467 -0.1849 -0.0972\n",
            "S-1762\tBut it hadn &apos;t .\n",
            "T-1762\tNhưng thực tế là không .\n",
            "H-1762\t-0.8623557686805725\tNhưng nó đã không như vậy .\n",
            "D-1762\t-0.8623557686805725\tNhưng nó đã không như vậy .\n",
            "P-1762\t-0.1919 -0.8196 -1.9692 -0.1138 -2.6679 -0.8108 -0.2217 -0.1038\n",
            "S-881\tThank you very much .\n",
            "T-881\tXin chân thành cảm ơn .\n",
            "H-881\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-881\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-881\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-856\tWhat was the result ?\n",
            "T-856\tKết quả như thế nào ?\n",
            "H-856\t-0.13772858679294586\tKết quả là gì ?\n",
            "D-856\t-0.13772858679294586\tKết quả là gì ?\n",
            "P-856\t-0.3348 -0.0266 -0.2115 -0.0453 -0.1168 -0.0914\n",
            "S-803\tThank you . Thanks .\n",
            "T-803\tCám ơn , cám ơn .\n",
            "H-803\t-0.32887211441993713\tXin cám ơn .\n",
            "D-803\t-0.32887211441993713\tXin cám ơn .\n",
            "P-803\t-0.0520 -1.0444 -0.0718 -0.2725 -0.2037\n",
            "S-700\tThank you very much .\n",
            "T-700\tXin cám ơn rất nhiều .\n",
            "H-700\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-700\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-700\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-673\tGood job ! Yeah !\n",
            "T-673\tLàm tốt lắm ! Yeah !\n",
            "H-673\t-0.8300395011901855\tTốt lắm !\n",
            "D-673\t-0.8300395011901855\tTốt lắm !\n",
            "P-673\t-2.3858 -0.0875 -0.6545 -0.1923\n",
            "S-578\tBut I felt worse .\n",
            "T-578\tNhưng tôi thấy tệ hơn .\n",
            "H-578\t-0.33561232686042786\tNhưng tôi cảm thấy tệ hơn .\n",
            "D-578\t-0.33561232686042786\tNhưng tôi cảm thấy tệ hơn .\n",
            "P-578\t-0.3324 -0.1362 -0.3734 -0.1038 -1.3014 -0.0603 -0.2692 -0.1082\n",
            "S-561\tHere &apos;s another example .\n",
            "T-561\tĐây là ví dụ khác .\n",
            "H-561\t-0.17534029483795166\tĐây là một ví dụ khác .\n",
            "D-561\t-0.17534029483795166\tĐây là một ví dụ khác .\n",
            "P-561\t-0.3271 -0.1558 -0.3633 -0.0407 -0.0620 -0.1084 -0.2440 -0.1013\n",
            "S-151\tThank you very much .\n",
            "T-151\tXin cảm ơn rất nhiều .\n",
            "H-151\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-151\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-151\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-6778\tWhat would you say ?\n",
            "T-6778\tBạn sẽ nói gì ?\n",
            "H-6778\t-0.20361031591892242\tBạn sẽ nói gì ?\n",
            "D-6778\t-0.20361031591892242\tBạn sẽ nói gì ?\n",
            "P-6778\t-0.3635 -0.1904 -0.2502 -0.1455 -0.1689 -0.1031\n",
            "S-6781\tListen to understand .\n",
            "T-6781\tNghe để thấu hiểu .\n",
            "H-6781\t-0.48506176471710205\tHãy lắng nghe .\n",
            "D-6781\t-0.48506176471710205\tHãy lắng nghe .\n",
            "P-6781\t-0.2682 -1.5288 -0.0101 -0.5153 -0.1028\n",
            "S-4185\tWe &apos;re losing them .\n",
            "T-4185\tChúng tôi đang thua họ\n",
            "H-4185\t-0.48745185136795044\tChúng ta đang mất đi chúng .\n",
            "D-4185\t-0.48745185136795044\tChúng ta đang mất đi chúng .\n",
            "P-4185\t-0.1594 -0.1346 -0.5114 -0.1482 -1.0334 -1.5459 -0.2687 -0.0979\n",
            "S-5434\tThank you very much .\n",
            "T-5434\tCám ơn rất nhiều .\n",
            "H-5434\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-5434\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-5434\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-5509\tHold it up .\n",
            "T-5509\tHãy giơ nó lên .\n",
            "H-5509\t-0.44138792157173157\tGiữ nó lên .\n",
            "D-5509\t-0.44138792157173157\tGiữ nó lên .\n",
            "P-5509\t-0.3475 -0.5211 -0.8001 -0.6759 -0.2017 -0.1020\n",
            "S-5668\tAnd I was scared .\n",
            "T-5668\tTôi đã rất sợ .\n",
            "H-5668\t-0.6205670237541199\tVà tôi rất sợ .\n",
            "D-5668\t-0.6205670237541199\tVà tôi rất sợ .\n",
            "P-5668\t-0.9789 -0.1630 -2.0485 -0.1848 -0.2516 -0.0965\n",
            "S-5937\tWe are the soil .\n",
            "T-5937\tChúng ta là đất .\n",
            "H-5937\t-0.2549756169319153\tChúng ta là đất .\n",
            "D-5937\t-0.2549756169319153\tChúng ta là đất .\n",
            "P-5937\t-0.3564 -0.3084 -0.2662 -0.0986 -0.4050 -0.0953\n",
            "S-6150\tIt doesn &apos;t exist .\n",
            "T-6150\tĐiều đó không tồn tại\n",
            "H-6150\t-0.15729333460330963\tNó không tồn tại .\n",
            "D-6150\t-0.15729333460330963\tNó không tồn tại .\n",
            "P-6150\t-0.3509 -0.1273 -0.1193 -0.0177 -0.2249 -0.1036\n",
            "S-6365\tThank you very much .\n",
            "T-6365\tCảm ơn rất nhiều .\n",
            "H-6365\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-6365\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-6365\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-6455\tHard is hard .\n",
            "T-6455\tMà khó là khó .\n",
            "H-6455\t-0.37415942549705505\tHard rất khó .\n",
            "D-6455\t-0.37415942549705505\tHard rất khó .\n",
            "P-6455\t-0.1381 -0.0588 -1.3020 -0.0778 -0.5756 -0.0926\n",
            "S-6665\tThank you very much .\n",
            "T-6665\tCảm ơn rất nhiều .\n",
            "H-6665\t-0.3418520390987396\tXin cảm ơn .\n",
            "D-6665\t-0.3418520390987396\tXin cảm ơn .\n",
            "P-6665\t-0.1065 -0.6790 -0.0980 -0.7351 -0.0906\n",
            "S-7331\tThat &apos;s huge .\n",
            "T-7331\tThời gian đó rất nhiều .\n",
            "H-7331\t-0.9622113704681396\tĐó là một điều rất lớn .\n",
            "D-7331\t-0.9622113704681396\tĐó là một điều rất lớn .\n",
            "P-7331\t-1.9901 -0.2555 -0.3900 -2.3301 -2.1541 -0.2936 -0.1865 -0.0978\n",
            "S-7373\tIt was crazy .\n",
            "T-7373\tĐiều này thật điên rồ .\n",
            "H-7373\t-0.2767094373703003\tThật điên rồ .\n",
            "D-7373\t-0.2767094373703003\tThật điên rồ .\n",
            "P-7373\t-0.8537 -0.1512 -0.0277 -0.2442 -0.1068\n",
            "S-1853\tVery different notion .\n",
            "T-1853\tNhững ý niệm rất khác nhau .\n",
            "H-1853\t-0.27299976348876953\tKhái niệm rất khác biệt .\n",
            "D-1853\t-0.27299976348876953\tKhái niệm rất khác biệt .\n",
            "P-1853\t-1.1309 -0.2108 -0.0371 -0.1555 -0.0730 -0.2354 -0.2456 -0.0958\n",
            "S-1968\tI actually am .\n",
            "T-1968\tMà thật ra tôi thế thật .\n",
            "H-1968\t-0.8073322772979736\tThực ra tôi là thế .\n",
            "D-1968\t-0.8073322772979736\tThực ra tôi là thế .\n",
            "P-1968\t-1.4977 -0.8955 -0.3180 -1.2251 -1.1819 -0.4362 -0.0969\n",
            "S-2144\tIt feels great .\n",
            "T-2144\tVà cảm giác đó thật tuyệt .\n",
            "H-2144\t-0.5890325903892517\tThật tuyệt vời .\n",
            "D-2144\t-0.5890325903892517\tThật tuyệt vời .\n",
            "P-2144\t-1.7851 -0.1432 -0.7531 -0.1622 -0.1016\n",
            "S-5119\tBut many die .\n",
            "T-5119\tNhưng rất nhiều người đã chết .\n",
            "H-5119\t-0.3474629819393158\tNhưng nhiều người chết .\n",
            "D-5119\t-0.3474629819393158\tNhưng nhiều người chết .\n",
            "P-5119\t-0.1201 -1.1293 -0.0756 -0.1991 -0.4601 -0.1006\n",
            "S-5516\tRaw data .\n",
            "T-5516\tNhững thông tin thuần sơ cấp .\n",
            "H-5516\t-0.6829541325569153\tDữ liệu Raw .\n",
            "D-5516\t-0.6829541325569153\tDữ liệu Raw .\n",
            "P-5516\t-2.0202 -0.4228 -0.0388 -1.7546 -0.1943 -0.2522 -0.0978\n",
            "S-5934\tSo what happened ?\n",
            "T-5934\tVậy điều gì đã xảy ra ?\n",
            "H-5934\t-0.3107016086578369\tVậy điều gì đã xảy ra ?\n",
            "D-5934\t-0.3107016086578369\tVậy điều gì đã xảy ra ?\n",
            "P-5934\t-0.7965 -0.8612 -0.0418 -0.3335 -0.1682 -0.0832 -0.0967 -0.1045\n",
            "S-6832\tIt &apos;s personal .\n",
            "T-6832\tĐó còn là chuyện cá nhân .\n",
            "H-6832\t-0.44867968559265137\tĐó là một cá nhân .\n",
            "D-6832\t-0.44867968559265137\tĐó là một cá nhân .\n",
            "P-6832\t-0.6700 -0.1726 -1.6122 -0.2655 -0.0242 -0.2979 -0.0983\n",
            "S-1977\tLike twice over .\n",
            "T-1977\tGần như chín gấp hai lần ấy .\n",
            "H-1977\t-0.45638880133628845\tNhư là hai lần .\n",
            "D-1977\t-0.45638880133628845\tNhư là hai lần .\n",
            "P-1977\t-0.7212 -0.4515 -0.6210 -0.0293 -0.8194 -0.0959\n",
            "S-2113\tIt sounds scary .\n",
            "T-2113\tThật sự khiến người ta phát điên .\n",
            "H-2113\t-0.19602631032466888\tNghe thật đáng sợ .\n",
            "D-2113\t-0.19602631032466888\tNghe thật đáng sợ .\n",
            "P-2113\t-0.1615 -0.3293 -0.3330 -0.0094 -0.2378 -0.1052\n",
            "S-2472\tIt has sensors .\n",
            "T-2472\tNó có một số cảm biến--\n",
            "H-2472\t-0.23054231703281403\tNó có cảm biến .\n",
            "D-2472\t-0.23054231703281403\tNó có cảm biến .\n",
            "P-2472\t-0.1327 -0.1967 -0.4314 -0.1491 -0.3769 -0.0964\n",
            "S-6887\tOh ! Oh !\n",
            "T-6887\tNgười đàn ông : Oh ! Oh !\n",
            "H-6887\t-0.6483925580978394\tOh ! Oh ! Oh !\n",
            "D-6887\t-0.6483925580978394\tOh ! Oh ! Oh !\n",
            "P-6887\t-1.5131 -0.0748 -1.2120 -0.1056 -1.3890 -0.1504 -0.0938\n",
            "S-2715\tI &apos;m Tom .\n",
            "T-2715\tTôm : Tôi đơn giản là Tôm .\n",
            "H-2715\t-0.1929076462984085\tTôi là Tom .\n",
            "D-2715\t-0.1929076462984085\tTôi là Tom .\n",
            "P-2715\t-0.1944 -0.3138 -0.0517 -0.3056 -0.0990\n",
            "S-2713\tIs that something ?\n",
            "T-2713\tNhư vậy có coi là 1 câu trả lời chứ ?\n",
            "H-2713\t-0.6070165634155273\tĐó có phải là điều gì không ?\n",
            "D-2713\t-0.6070165634155273\tĐó có phải là điều gì không ?\n",
            "P-2713\t-1.9650 -0.2150 -0.0213 -0.2049 -1.7112 -0.0920 -1.0502 -0.1031 -0.1004\n",
            "S-3763\tI represent children .\n",
            "T-3763\tTôi muốn đại diện lên tiếng nói cho trẻ em .\n",
            "H-3763\t-0.11560536175966263\tTôi đại diện cho trẻ em .\n",
            "D-3763\t-0.11560536175966263\tTôi đại diện cho trẻ em .\n",
            "P-3763\t-0.1460 -0.1708 -0.0096 -0.0160 -0.0727 -0.1378 -0.2688 -0.1030\n",
            "S-7210\tIs she conscious ?\n",
            "T-7210\tcô ta có ý thức ?\n",
            "H-7210\t-0.6747763156890869\tCô ấy có nhận thức được không ?\n",
            "D-7210\t-0.6747763156890869\tCô ấy có nhận thức được không ?\n",
            "P-7210\t-3.1846 -0.5839 -0.1161 -1.3373 -0.0417 -0.2935 -0.3254 -0.0895 -0.1010\n",
            "  3% 2/60 [00:02<01:24,  1.46s/it, wps=514]S-2518\tSo that started the journey .\n",
            "T-2518\tThế là cuộc chiến bắt đầu .\n",
            "H-2518\t-0.6264906525611877\tVà điều đó bắt đầu hành trình .\n",
            "D-2518\t-0.6264906525611877\tVà điều đó bắt đầu hành trình .\n",
            "P-2518\t-1.7244 -1.3592 -0.4265 -1.1544 -0.1280 -0.4725 -0.0207 -0.2489 -0.1038\n",
            "S-5882\tThis is South Los Angeles .\n",
            "T-5882\tĐây là vùng Nam Los Angeles .\n",
            "H-5882\t-0.12839214503765106\tĐây là Nam Los Angeles .\n",
            "D-5882\t-0.12839214503765106\tĐây là Nam Los Angeles .\n",
            "P-5882\t-0.1054 -0.0968 -0.0484 -0.2933 -0.0238 -0.2365 -0.0945\n",
            "S-5879\tI live in South Central .\n",
            "T-5879\tTôi sống ở vùng Trung Nam .\n",
            "H-5879\t-0.3714486062526703\tTôi sống ở Nam Trung tâm .\n",
            "D-5879\t-0.3714486062526703\tTôi sống ở Nam Trung tâm .\n",
            "P-5879\t-0.1001 -0.0851 -0.2731 -0.1633 -0.3784 -1.5956 -0.2773 -0.0987\n",
            "S-5754\tAnd here &apos;s me today .\n",
            "T-5754\tVà đây là tôi bây giờ .\n",
            "H-5754\t-0.40431955456733704\tVà đây là tôi hôm nay .\n",
            "D-5754\t-0.40431955456733704\tVà đây là tôi hôm nay .\n",
            "P-5754\t-0.4166 -0.3333 -0.2292 -0.1385 -1.7619 -0.0564 -0.2026 -0.0962\n",
            "S-5700\tActually , for 10 years .\n",
            "T-5700\tThật ra , trong 10 năm .\n",
            "H-5700\t-0.45327016711235046\tThực ra , trong 10 năm .\n",
            "D-5700\t-0.45327016711235046\tThực ra , trong 10 năm .\n",
            "P-5700\t-0.7971 -0.8624 -1.0736 -0.1641 -0.1067 -0.0535 -0.4707 -0.0979\n",
            "S-5036\tWe have three main groups .\n",
            "T-5036\tCó ba nguồn tấn công chính .\n",
            "H-5036\t-0.3447536528110504\tChúng ta có ba nhóm chính .\n",
            "D-5036\t-0.3447536528110504\tChúng ta có ba nhóm chính .\n",
            "P-5036\t-0.5233 -0.8938 -0.1535 -0.7860 -0.0525 -0.1000 -0.1506 -0.0983\n",
            "S-4951\tSo here &apos;s another example .\n",
            "T-4951\tSau đây là một ví dụ .\n",
            "H-4951\t-0.2922455072402954\tĐây là một ví dụ khác .\n",
            "D-4951\t-0.2922455072402954\tĐây là một ví dụ khác .\n",
            "P-4951\t-1.2949 -0.1444 -0.3749 -0.0438 -0.0604 -0.0909 -0.2287 -0.0998\n",
            "S-4791\tSo Scott gets this call .\n",
            "T-4791\tScott nhận thức được điều này .\n",
            "H-4791\t-0.426653653383255\tVì vậy Scott nhận được cuộc gọi này .\n",
            "D-4791\t-0.426653653383255\tVì vậy Scott nhận được cuộc gọi này .\n",
            "P-4791\t-1.4700 -0.6534 -0.3430 -0.4367 -0.0640 -0.3599 -0.0242 -0.5573 -0.2555 -0.1026\n",
            "S-4319\tAnd then it happened again .\n",
            "T-4319\tVà điều đó lại xảy ra .\n",
            "H-4319\t-0.6088647246360779\tVà rồi nó lại xảy ra .\n",
            "D-4319\t-0.6088647246360779\tVà rồi nó lại xảy ra .\n",
            "P-4319\t-0.7439 -1.7634 -1.2584 -0.2905 -0.2269 -0.0923 -0.3975 -0.0981\n",
            "S-3729\tI was devastated .\n",
            "T-3729\tLúc đấy , tôi thấy thất vọng\n",
            "H-3729\t-0.8559651374816895\tTôi đã rất đau đớn .\n",
            "D-3729\t-0.8559651374816895\tTôi đã rất đau đớn .\n",
            "P-3729\t-0.1574 -0.7071 -2.8687 -1.1707 -0.7070 -0.2815 -0.0994\n",
            "S-3553\tHe retreated into silence .\n",
            "T-3553\tÔng rút lui vào yên lặng .\n",
            "H-3553\t-0.9784286618232727\tÔng ta được chữa trị trong im lặng .\n",
            "D-3553\t-0.9784286618232727\tÔng ta được chữa trị trong im lặng .\n",
            "P-3553\t-0.9664 -1.0887 -3.5264 -0.6426 -0.0727 -2.9608 -0.0792 -0.0049 -0.3336 -0.1088\n",
            "S-3244\tAnd then everybody moved down .\n",
            "T-3244\tVà rồi mọi người giải tán .\n",
            "H-3244\t-0.6516098976135254\tVà mọi người di chuyển xuống .\n",
            "D-3244\t-0.6516098976135254\tVà mọi người di chuyển xuống .\n",
            "P-3244\t-0.5888 -1.4877 -0.0934 -1.6261 -0.1072 -0.9504 -0.2591 -0.1001\n",
            "S-3033\tWill I like the color ?\n",
            "T-3033\tTôi có thích màu đó không ?\n",
            "H-3033\t-0.3613359034061432\tTôi sẽ thích màu sắc ?\n",
            "D-3033\t-0.3613359034061432\tTôi sẽ thích màu sắc ?\n",
            "P-3033\t-0.2515 -0.8460 -0.2196 -0.0437 -0.0742 -0.9871 -0.1072\n",
            "S-2682\tThat &apos;s a great question .\n",
            "T-2682\tĐó là 1 câu hỏi khó .\n",
            "H-2682\t-0.2837429940700531\tĐó là một câu hỏi tuyệt vời .\n",
            "D-2682\t-0.2837429940700531\tĐó là một câu hỏi tuyệt vời .\n",
            "P-2682\t-0.3016 -0.1933 -0.3064 -0.0401 -0.0376 -1.2735 -0.0914 -0.2099 -0.1000\n",
            "S-2627\tTurn the camera off .\n",
            "T-2627\tTắt ngay camera cho tôi .\n",
            "H-2627\t-0.5657048225402832\tHãy tắt máy ảnh đi .\n",
            "D-2627\t-0.5657048225402832\tHãy tắt máy ảnh đi .\n",
            "P-2627\t-0.3628 -1.7148 -0.0963 -1.2372 -0.1749 -0.2767 -0.0971\n",
            "S-2547\tIsn &apos;t that awesome ?\n",
            "T-2547\tThật là tuyệt vời phải không .\n",
            "H-2547\t-0.5836319923400879\tThật kinh hãi phải không ?\n",
            "D-2547\t-0.5836319923400879\tThật kinh hãi phải không ?\n",
            "P-2547\t-2.5636 -0.5202 -0.1091 -0.1899 -0.0669 -0.5342 -0.1015\n",
            "S-6008\tSo I set up everything .\n",
            "T-6008\tVà tôi lắp đặt mọi thứ .\n",
            "H-6008\t-0.9010750651359558\tVì vậy tôi đã thiết lập mọi thứ .\n",
            "D-6008\t-0.9010750651359558\tVì vậy tôi đã thiết lập mọi thứ .\n",
            "P-6008\t-2.3206 -0.8471 -0.3837 -2.2233 -2.4942 -0.0321 -0.3644 -0.0751 -0.1703 -0.0998\n",
            "S-2459\tSo this is for real .\n",
            "T-2459\tVì vậy nó là sự thật .\n",
            "H-2459\t-0.7798648476600647\tVà điều này là thật .\n",
            "D-2459\t-0.7798648476600647\tVà điều này là thật .\n",
            "P-2459\t-2.8631 -0.6924 -0.2490 -0.4591 -0.8357 -0.2612 -0.0984\n",
            "S-2252\tAnd it took 18 months .\n",
            "T-2252\tTôi đã mất tới 18 tháng .\n",
            "H-2252\t-0.47103995084762573\tVà mất 18 tháng .\n",
            "D-2252\t-0.47103995084762573\tVà mất 18 tháng .\n",
            "P-2252\t-0.6000 -1.0762 -0.6027 -0.0393 -0.4141 -0.0938\n",
            "S-2220\tThis picture &apos;s from there .\n",
            "T-2220\tBức hình này chụp ở đó .\n",
            "H-2220\t-0.43280908465385437\tBức ảnh này được chụp từ đó .\n",
            "D-2220\t-0.43280908465385437\tBức ảnh này được chụp từ đó .\n",
            "P-2220\t-0.0823 -0.5444 -0.1244 -1.8923 -0.0301 -0.2553 -0.5648 -0.2964 -0.1053\n",
            "S-2152\tBut it was very sad .\n",
            "T-2152\tNhưng nó thực sự đáng buồn .\n",
            "H-2152\t-0.5841922760009766\tNhưng nó rất buồn .\n",
            "D-2152\t-0.5841922760009766\tNhưng nó rất buồn .\n",
            "P-2152\t-0.1938 -1.7749 -1.0139 -0.0527 -0.3654 -0.1043\n",
            "S-1931\tThere &apos;s almost nothing left .\n",
            "T-1931\tHầu như chẳng còn gì nữa .\n",
            "H-1931\t-0.5864936709403992\tKhông còn gì để lại .\n",
            "D-1931\t-0.5864936709403992\tKhông còn gì để lại .\n",
            "P-1931\t-1.2782 -0.0328 -0.8285 -1.4717 -0.0638 -0.3294 -0.1010\n",
            "S-1787\tAnd here is a surprise .\n",
            "T-1787\tVà đây là một bất ngờ :\n",
            "H-1787\t-0.2610042989253998\tVà đây là một điều bất ngờ .\n",
            "D-1787\t-0.2610042989253998\tVà đây là một điều bất ngờ .\n",
            "P-1787\t-0.5087 -0.1529 -0.1705 -0.3391 -0.5379 -0.2383 -0.0032 -0.2916 -0.1068\n",
            "S-1651\tThat &apos;s super important .\n",
            "T-1651\tĐiều này cực kì quan trọng .\n",
            "H-1651\t-0.48354437947273254\tĐiều đó cực kỳ quan trọng .\n",
            "D-1651\t-0.48354437947273254\tĐiều đó cực kỳ quan trọng .\n",
            "P-1651\t-1.2919 -0.7011 -1.1754 -0.2742 -0.0165 -0.0380 -0.2744 -0.0969\n",
            "S-1369\tTremendously challenging .\n",
            "T-1369\tSự thách thức tột cùng .\n",
            "H-1369\t-0.9562232494354248\tThoả thuận một cách khó khăn\n",
            "D-1369\t-0.9562232494354248\tThoả thuận một cách khó khăn\n",
            "P-1369\t-1.0711 -1.9293 -0.2271 -0.3703 -1.8656 -0.0723 -0.7623 -0.0823 -2.2257\n",
            "S-599\tYou could have done better .\n",
            "T-599\tbạn có thể làm tốt hơn .\n",
            "H-599\t-0.2299935519695282\tBạn có thể làm tốt hơn .\n",
            "D-599\t-0.2299935519695282\tBạn có thể làm tốt hơn .\n",
            "P-599\t-0.3457 -0.3550 -0.1055 -0.3505 -0.1577 -0.0417 -0.3807 -0.1031\n",
            "S-553\tVery expensive real estate .\n",
            "T-553\tBiệt thự đắt tiền .\n",
            "H-553\t-0.9812033772468567\tMột môi trường rất đắt .\n",
            "D-553\t-0.9812033772468567\tMột môi trường rất đắt .\n",
            "P-553\t-3.3560 -1.7465 -0.0580 -0.7829 -0.1640 -0.6677 -0.0933\n",
            "S-526\tAnd the answer is yes .\n",
            "T-526\tVà câu trả lời là có .\n",
            "H-526\t-0.22749000787734985\tVà câu trả lời là có .\n",
            "D-526\t-0.22749000787734985\tVà câu trả lời là có .\n",
            "P-526\t-1.1339 -0.0520 -0.0376 -0.0384 -0.1886 -0.1039 -0.1646 -0.1009\n",
            "S-476\tAnd those days are gone .\n",
            "T-476\tnhững ngày đó ko còn nữa .\n",
            "H-476\t-0.43793541193008423\tVà những ngày đó đã biến mất .\n",
            "D-476\t-0.43793541193008423\tVà những ngày đó đã biến mất .\n",
            "P-476\t-0.5277 -1.1387 -0.0268 -0.5512 -0.4544 -0.9057 -0.0044 -0.2346 -0.0980\n",
            "S-263\tAnd I always have been .\n",
            "T-263\tVà vẫn luôn luôn như vậy .\n",
            "H-263\t-0.43523290753364563\tVà tôi luôn như vậy .\n",
            "D-263\t-0.43523290753364563\tVà tôi luôn như vậy .\n",
            "P-263\t-0.8965 -0.2185 -0.2297 -0.6186 -0.8003 -0.1832 -0.1000\n",
            "S-7379\tThis is Ohio .\n",
            "T-7379\tĐây là Ohio .\n",
            "H-7379\t-0.10306257009506226\tĐây là Ohio .\n",
            "D-7379\t-0.10306257009506226\tĐây là Ohio .\n",
            "P-7379\t-0.2201 -0.1148 -0.0023 -0.0063 -0.0034 -0.2769 -0.0976\n",
            "S-7230\tIt is absolutely gorgeous .\n",
            "T-7230\tĐiều đó thật đáng yêu .\n",
            "H-7230\t-0.7351520657539368\tNó hoàn toàn tuyệt vời .\n",
            "D-7230\t-0.7351520657539368\tNó hoàn toàn tuyệt vời .\n",
            "P-7230\t-1.6460 -1.0869 -0.0474 -0.7399 -1.2218 -0.3077 -0.0964\n",
            "S-351\tAnd what is that thing ?\n",
            "T-351\tVậy thì đó là cái gì chứ ?\n",
            "H-351\t-0.3215489089488983\tVà điều đó là gì ?\n",
            "D-351\t-0.3215489089488983\tVà điều đó là gì ?\n",
            "P-351\t-0.4297 -1.1709 -0.2576 -0.1026 -0.0582 -0.1289 -0.1029\n",
            "S-3134\tAnd it even got better .\n",
            "T-3134\tVà mọi chuyện còn tốt hơn nữa .\n",
            "H-3134\t-0.4966265559196472\tVà nó thậm chí tốt hơn .\n",
            "D-3134\t-0.4966265559196472\tVà nó thậm chí tốt hơn .\n",
            "P-3134\t-0.4672 -0.5261 -1.6086 -0.0797 -0.8711 -0.0553 -0.2603 -0.1048\n",
            "S-3003\tShe did it in secret .\n",
            "T-3003\tCô ấy làm một cách bí mật ,\n",
            "H-3003\t-0.5632933974266052\tCô ấy đã làm điều đó trong bí mật .\n",
            "D-3003\t-0.5632933974266052\tCô ấy đã làm điều đó trong bí mật .\n",
            "P-3003\t-0.9594 -1.0423 -0.8488 -0.4914 -0.7217 -0.5981 -0.5945 -0.0078 -0.0725 -0.7680 -0.0917\n",
            "S-2826\tIs it just imaginary ?\n",
            "T-2826\tCó phải đây chỉ là tưởng tượng ?\n",
            "H-2826\t-0.7613465189933777\tCó phải nó chỉ là tưởng tượng ?\n",
            "D-2826\t-0.7613465189933777\tCó phải nó chỉ là tưởng tượng ?\n",
            "P-2826\t-1.7770 -0.0928 -1.6645 -0.4804 -1.2310 -0.5608 -0.0053 -0.9339 -0.1065\n",
            "S-2676\tWe are a smaller brand .\n",
            "T-2676\tChúng tôi là một thương hiệu nhỏ .\n",
            "H-2676\t-0.47795823216438293\tChúng ta là một thương hiệu nhỏ hơn .\n",
            "D-2676\t-0.47795823216438293\tChúng ta là một thương hiệu nhỏ hơn .\n",
            "P-2676\t-0.2388 -0.8964 -1.3888 -0.4470 -1.2332 -0.0534 -0.0787 -0.0874 -0.2542 -0.1016\n",
            "S-2651\tWhat else is risky ?\n",
            "T-2651\tđiều gì có thể là ngu hiểm ?\n",
            "H-2651\t-0.9099786877632141\tCòn điều gì nữa ?\n",
            "D-2651\t-0.9099786877632141\tCòn điều gì nữa ?\n",
            "P-2651\t-2.0479 -2.7265 -0.0489 -0.2836 -0.2451 -0.1079\n",
            "S-2640\tThis would have been fine .\n",
            "T-2640\tBức hình này hoàn toàn okê .\n",
            "H-2640\t-0.6196470856666565\tĐiều này sẽ ổn .\n",
            "D-2640\t-0.6196470856666565\tĐiều này sẽ ổn .\n",
            "P-2640\t-0.3075 -0.3048 -1.0899 -1.2080 -0.7069 -0.1008\n",
            "S-2421\tWell , I was next .\n",
            "T-2421\tỒ , tôi là người tiếp theo .\n",
            "H-2421\t-0.9877590537071228\tVâng , tôi tiếp theo .\n",
            "D-2421\t-0.9877590537071228\tVâng , tôi tiếp theo .\n",
            "P-2421\t-2.4709 -0.1894 -0.3936 -3.4364 -0.1325 -0.1915 -0.1000\n",
            "S-1939\tI wanted to support them .\n",
            "T-1939\tVà tôi đã muốn ủng hộ họ .\n",
            "H-1939\t-0.39362677931785583\tTôi muốn hỗ trợ chúng .\n",
            "D-1939\t-0.39362677931785583\tTôi muốn hỗ trợ chúng .\n",
            "P-1939\t-0.1478 -0.1269 -0.9447 -0.0201 -1.1797 -0.2386 -0.0975\n",
            "S-1801\tWhat defines a story ?\n",
            "T-1801\tCái gì làm nên một câu chuyện ?\n",
            "H-1801\t-0.5403023362159729\tVậy câu chuyện là gì ?\n",
            "D-1801\t-0.5403023362159729\tVậy câu chuyện là gì ?\n",
            "P-1801\t-1.2556 -0.6613 -0.1102 -1.4911 -0.0323 -0.1208 -0.1108\n",
            "S-1793\tHow do we know that ?\n",
            "T-1793\tLàm sao chúng ta biết điều đó ?\n",
            "H-1793\t-0.36499515175819397\tLàm thế nào chúng ta biết được điều đó ?\n",
            "D-1793\t-0.36499515175819397\tLàm thế nào chúng ta biết được điều đó ?\n",
            "P-1793\t-0.2315 -1.3712 -0.0615 -0.9331 -0.1058 -0.1811 -0.1425 -0.4391 -0.3429 -0.1068 -0.0994\n",
            "S-1778\tThis is an old study .\n",
            "T-1778\tĐây là một nghiên cứu đã cũ .\n",
            "H-1778\t-0.1501961052417755\tĐây là một nghiên cứu cũ .\n",
            "D-1778\t-0.1501961052417755\tĐây là một nghiên cứu cũ .\n",
            "P-1778\t-0.0954 -0.1151 -0.3621 -0.0966 -0.0681 -0.0720 -0.2898 -0.1025\n",
            "S-1764\tHe had had the experience .\n",
            "T-1764\tAnh ta đã có sự trải nghiệm .\n",
            "H-1764\t-0.6343832612037659\tÔng có kinh nghiệm .\n",
            "D-1764\t-0.6343832612037659\tÔng có kinh nghiệm .\n",
            "P-1764\t-1.0682 -1.9265 -0.3588 -0.0125 -0.3349 -0.1055\n",
            "S-1662\tSo this is a wish .\n",
            "T-1662\tThế nên đây là một điều ước .\n",
            "H-1662\t-0.5311679244041443\tVà đây là điều ước .\n",
            "D-1662\t-0.5311679244041443\tVà đây là điều ước .\n",
            "P-1662\t-1.7797 -0.6695 -0.1692 -0.6220 -0.1335 -0.2457 -0.0986\n",
            "S-1249\tAnd I was an artist .\n",
            "T-1249\tVà tôi từng là một hoạ sĩ .\n",
            "H-1249\t-0.3963364362716675\tVà tôi là một nghệ sĩ .\n",
            "D-1249\t-0.3963364362716675\tVà tôi là một nghệ sĩ .\n",
            "P-1249\t-1.0946 -0.2140 -0.3224 -0.2571 -0.4329 -0.1827 -0.5697 -0.0974\n",
            "S-1139\tFinally : epic meaning .\n",
            "T-1139\tCuối cùng , ý nghĩa epic .\n",
            "H-1139\t-0.7447205781936646\tCuối cùng : ý nghĩa thực sự .\n",
            "D-1139\t-0.7447205781936646\tCuối cùng : ý nghĩa thực sự .\n",
            "P-1139\t-0.1584 -0.0290 -0.2908 -0.4765 -0.0884 -3.6450 -1.3966 -0.5217 -0.0960\n",
            "S-6915\tThey don &apos;t want that .\n",
            "T-6915\tHọ không muốn điều đó .\n",
            "H-6915\t-0.4069455862045288\tHọ không muốn thế .\n",
            "D-6915\t-0.4069455862045288\tHọ không muốn thế .\n",
            "P-6915\t-0.3831 -0.0888 -0.1357 -1.4832 -0.2474 -0.1035\n",
            "S-180\tThe flows have increased .\n",
            "T-180\tLượng băng tan ngày càng tăng .\n",
            "H-180\t-0.5678160190582275\tCác dòng chảy đã tăng lên .\n",
            "D-180\t-0.5678160190582275\tCác dòng chảy đã tăng lên .\n",
            "P-180\t-1.5580 -0.0974 -0.9934 -0.9288 -0.4392 -0.0953 -0.3253 -0.1050\n",
            "S-7363\tThis is really tough stuff .\n",
            "T-7363\tĐiều này thực sự khó khăn .\n",
            "H-7363\t-0.5024046897888184\tĐiều này thực sự khó khăn .\n",
            "D-7363\t-0.5024046897888184\tĐiều này thực sự khó khăn .\n",
            "P-7363\t-1.6011 -0.2175 -1.0876 -0.0557 -0.5663 -0.0688 -0.3298 -0.0926\n",
            "S-7347\tThis is a nice building .\n",
            "T-7347\tĐây là một toà nhà đẹp .\n",
            "H-7347\t-0.43356645107269287\tĐây là một toà nhà hay .\n",
            "D-7347\t-0.43356645107269287\tĐây là một toà nhà hay .\n",
            "P-7347\t-0.2507 -0.1341 -0.6100 -0.0580 -0.0468 -2.0905 -0.1677 -0.1108\n",
            "S-7324\tAnd I looked like this .\n",
            "T-7324\tVà tôi trông như thế này .\n",
            "H-7324\t-0.3336494266986847\tVà tôi trông như thế này .\n",
            "D-7324\t-0.3336494266986847\tVà tôi trông như thế này .\n",
            "P-7324\t-0.6723 -0.1931 -0.2725 -0.8856 -0.0925 -0.0629 -0.3852 -0.1050\n",
            "S-7173\tNo , not like that .\n",
            "T-7173\tKhông , không phải như vậy .\n",
            "H-7173\t-0.5772753357887268\tKhông , không giống thế .\n",
            "D-7173\t-0.5772753357887268\tKhông , không giống thế .\n",
            "P-7173\t-0.1375 -0.2297 -0.2311 -1.8916 -1.0801 -0.3709 -0.1001\n",
            "S-6918\tWhat would that be like ?\n",
            "T-6918\tNó sẽ trông như thế nào ?\n",
            "H-6918\t-0.4444938898086548\tNó sẽ như thế nào ?\n",
            "D-6918\t-0.4444938898086548\tNó sẽ như thế nào ?\n",
            "P-6918\t-2.0143 -0.1405 -0.5516 -0.0663 -0.0809 -0.1520 -0.1058\n",
            "S-6903\tOther teams followed suit .\n",
            "T-6903\tCác đội khác đã làm theo .\n",
            "H-6903\t-0.5472044944763184\tNhững đội khác theo dõi .\n",
            "D-6903\t-0.5472044944763184\tNhững đội khác theo dõi .\n",
            "P-6903\t-1.0927 -1.0016 -0.0324 -0.4212 -0.6893 -0.4857 -0.1076\n",
            "S-6841\tOne was Jason .\n",
            "T-6841\tMột người là Jason .\n",
            "H-6841\t-0.07803159952163696\tMột là Jason .\n",
            "D-6841\t-0.07803159952163696\tMột là Jason .\n",
            "P-6841\t-0.1076 -0.1654 -0.0056 -0.0028 -0.0073 -0.1566 -0.1010\n",
            "S-6684\tMany are not so fortunate .\n",
            "T-6684\tNhiều người không may mắn như thế\n",
            "H-6684\t-0.2905551493167877\tRất nhiều người không may mắn .\n",
            "D-6684\t-0.2905551493167877\tRất nhiều người không may mắn .\n",
            "P-6684\t-0.8316 -0.0890 -0.2339 -0.2450 -0.1076 -0.1086 -0.6173 -0.0915\n",
            "S-6553\tI &apos;m not for that .\n",
            "T-6553\tTôi không ủng hộ cách này .\n",
            "H-6553\t-0.5429925918579102\tTôi không phải vì điều đó .\n",
            "D-6553\t-0.5429925918579102\tTôi không phải vì điều đó .\n",
            "P-6553\t-0.2276 -0.2205 -1.8373 -1.1783 -0.1911 -0.2890 -0.2940 -0.1062\n",
            "S-6550\tHow do we do that ?\n",
            "T-6550\tLàm thế nào để thực hiện ?\n",
            "H-6550\t-0.5252819657325745\tLàm thế nào để làm được điều đó ?\n",
            "D-6550\t-0.5252819657325745\tLàm thế nào để làm được điều đó ?\n",
            "P-6550\t-0.5505 -0.9361 -0.0763 -1.3522 -0.7513 -0.4840 -0.6486 -0.2644 -0.0881 -0.1013\n",
            "S-6517\tI was kind of extreme .\n",
            "T-6517\tTôi thì thuộc dạng quá mức .\n",
            "H-6517\t-0.6170617938041687\tTôi hơi thái quá .\n",
            "D-6517\t-0.6170617938041687\tTôi hơi thái quá .\n",
            "P-6517\t-0.2851 -1.9189 -0.8143 -0.3803 -0.1980 -0.1058\n",
            "S-6508\tI &apos;m actually an engineer .\n",
            "T-6508\tThực ra , tôi là kỹ sư\n",
            "H-6508\t-0.4436759054660797\tTôi là một kỹ sư .\n",
            "D-6508\t-0.4436759054660797\tTôi là một kỹ sư .\n",
            "P-6508\t-0.3674 -1.1118 -0.4917 -0.6747 -0.0192 -0.3452 -0.0958\n",
            "S-6478\tJack is our favorite . &quot;\n",
            "T-6478\tChúng tôi yêu mến Jack . &quot;\n",
            "H-6478\t-0.5188391208648682\tJack là yêu thích của chúng tôi . &quot;\n",
            "D-6478\t-0.5188391208648682\tJack là yêu thích của chúng tôi . &quot;\n",
            "P-6478\t-0.1654 -0.3401 -2.9163 -0.0976 -0.2058 -0.1008 -0.6481 -0.4872 -0.1393 -0.0877\n",
            "S-6389\tHow predictive is it ?\n",
            "T-6389\tNó dự báo được đến đâu ?\n",
            "H-6389\t-0.8271722197532654\tLàm thế nào dự đoán được ?\n",
            "D-6389\t-0.8271722197532654\tLàm thế nào dự đoán được ?\n",
            "P-6389\t-4.4947 -0.8135 -0.0613 -0.6968 -0.0240 -0.2754 -0.1476 -0.1041\n",
            "S-4463\tOhhhh .\n",
            "T-4463\tOhhh .\n",
            "H-4463\t-0.16978232562541962\tOhhhh .\n",
            "D-4463\t-0.16978232562541962\tOhhhh .\n",
            "P-4463\t-0.0309 -0.0010 -0.0292 -0.3415 -0.3581 -0.3288 -0.0989\n",
            "S-1460\tNow , who &apos;s normal ?\n",
            "T-1460\tNào , ai bình thường ?\n",
            "H-1460\t-0.5846590399742126\tAi là người bình thường ?\n",
            "D-1460\t-0.5846590399742126\tAi là người bình thường ?\n",
            "P-1460\t-1.6024 -0.7714 -1.3953 -0.0547 -0.0727 -0.0951 -0.1010\n",
            "S-1029\tYes , there it is .\n",
            "T-1029\tVâng , máu đây này .\n",
            "H-1029\t-0.847268283367157\tVâng , đây .\n",
            "D-1029\t-0.847268283367157\tVâng , đây .\n",
            "P-1029\t-0.9463 -0.1799 -2.3923 -0.6169 -0.1010\n",
            "S-833\tSound familiar ? Right .\n",
            "T-833\tNghe quen quá phải không ?\n",
            "H-833\t-0.49879753589630127\tNghe quen không ?\n",
            "D-833\t-0.49879753589630127\tNghe quen không ?\n",
            "P-833\t-0.3886 -0.0354 -0.6378 -0.1769 -1.2552\n",
            "S-675\tinventing his own narrative .\n",
            "T-675\tsáng tạo ra câu chuyện .\n",
            "H-675\t-0.6581509709358215\tsáng tạo ra câu chuyện của riêng ông .\n",
            "D-675\t-0.6581509709358215\tsáng tạo ra câu chuyện của riêng ông .\n",
            "P-675\t-1.3458 -0.3767 -1.0207 -0.3043 -0.0326 -0.8900 -0.6422 -1.2841 -0.5876 -0.0974\n",
            "S-605\tSo let me remind you .\n",
            "T-605\tVậy để tôi nhắc bạn .\n",
            "H-605\t-0.3880104422569275\tĐể tôi nhắc nhở các bạn .\n",
            "D-605\t-0.3880104422569275\tĐể tôi nhắc nhở các bạn .\n",
            "P-605\t-1.1863 -0.0998 -0.1298 -0.4582 -0.6485 -0.0781 -0.4029 -0.1005\n",
            "S-235\tThis is the last one .\n",
            "T-235\tĐây là đoạn video cuối .\n",
            "H-235\t-0.3899092972278595\tĐây là điều cuối cùng .\n",
            "D-235\t-0.3899092972278595\tĐây là điều cuối cùng .\n",
            "P-235\t-0.4331 -0.1421 -1.7411 -0.0251 -0.0333 -0.2492 -0.1055\n",
            "S-7350\tIt &apos;s in Seattle .\n",
            "T-7350\tNó ở Seattle .\n",
            "H-7350\t-0.27130046486854553\tNó ở Seattle .\n",
            "D-7350\t-0.27130046486854553\tNó ở Seattle .\n",
            "P-7350\t-0.3060 -0.7915 -0.0196 -0.0604 -0.3522 -0.0981\n",
            "S-7087\tEach of us is conscious .\n",
            "T-7087\tai cũng có nhận thức\n",
            "H-7087\t-0.3481973707675934\tMỗi chúng ta đều có nhận thức .\n",
            "D-7087\t-0.3481973707675934\tMỗi chúng ta đều có nhận thức .\n",
            "P-7087\t-0.1517 -0.3674 -0.1440 -0.1980 -0.8229 -1.0418 -0.0344 -0.2700 -0.1036\n",
            "S-6325\tMany of them drown .\n",
            "T-6325\tNhiều em chết đuối .\n",
            "H-6325\t-0.6088153719902039\tNhiều người trong số họ chết .\n",
            "D-6325\t-0.6088153719902039\tNhiều người trong số họ chết .\n",
            "P-6325\t-1.1813 -0.2055 -0.3744 -0.0552 -0.1841 -2.3589 -0.4115 -0.0995\n",
            "S-6302\tThere were no back doors .\n",
            "T-6302\tKhông có cửa hậu .\n",
            "H-6302\t-0.5512462854385376\tKhông có nhà trong nhà .\n",
            "D-6302\t-0.5512462854385376\tKhông có nhà trong nhà .\n",
            "P-6302\t-0.3346 -0.5054 -0.6592 -1.8585 -0.1092 -0.2924 -0.0993\n",
            "S-5646\tNo , it didn &apos;t .\n",
            "T-5646\tKhông , không hề .\n",
            "H-5646\t-0.5531622171401978\tKhông , không .\n",
            "D-5646\t-0.5531622171401978\tKhông , không .\n",
            "P-5646\t-0.1864 -0.2012 -0.9453 -1.3287 -0.1043\n",
            "S-5107\tI was so shocked .\n",
            "T-5107\tTôi đã bị sốc .\n",
            "H-5107\t-0.48341652750968933\tTôi đã rất sốc .\n",
            "D-5107\t-0.48341652750968933\tTôi đã rất sốc .\n",
            "P-5107\t-0.1881 -1.2127 -0.6638 -0.5619 -0.1673 -0.1067\n",
            "S-5037\tWe have online criminals .\n",
            "T-5037\tTừ những tội phạm mạng\n",
            "H-5037\t-0.42271971702575684\tChúng ta có những tên tội phạm trực tuyến .\n",
            "D-5037\t-0.42271971702575684\tChúng ta có những tên tội phạm trực tuyến .\n",
            "P-5037\t-0.3928 -0.7141 -0.1556 -0.8187 -1.5644 -0.0144 -0.0009 -0.0781 -0.0013 -0.8141 -0.0957\n",
            "S-6864\tI have to use words .\n",
            "T-6864\tTôi phải dùng từ ngữ ,\n",
            "H-6864\t-0.3462958037853241\tTôi phải dùng từ ngữ .\n",
            "D-6864\t-0.3462958037853241\tTôi phải dùng từ ngữ .\n",
            "P-6864\t-0.2832 -0.4946 -0.6680 -0.2825 -0.2554 -0.3385 -0.1018\n",
            "S-3987\tThere were still fishes .\n",
            "T-3987\tCòn có rất nhiều cá\n",
            "H-3987\t-0.7242863774299622\tVẫn còn có những ước muốn .\n",
            "D-3987\t-0.7242863774299622\tVẫn còn có những ước muốn .\n",
            "P-3987\t-0.4964 -0.0032 -0.2155 -1.9062 -0.5695 -1.9886 -0.9673 -0.2719 -0.1000\n",
            "S-3056\tJust be who you are .\n",
            "T-3056\tHãy là chính mình .\n",
            "H-3056\t-0.7886263728141785\tChỉ là bạn là ai .\n",
            "D-3056\t-0.7886263728141785\tChỉ là bạn là ai .\n",
            "P-3056\t-0.9318 -0.4307 -2.5655 -1.0334 -0.0650 -0.3974 -0.0965\n",
            "S-2821\tHow about fitness ?\n",
            "T-2821\tSức khoẻ thì sao ?\n",
            "H-2821\t-1.0272377729415894\tThế còn về tính bền vững ?\n",
            "D-2821\t-1.0272377729415894\tThế còn về tính bền vững ?\n",
            "P-2821\t-1.1930 -0.1539 -1.3832 -0.2935 -3.9070 -0.9261 -0.2493 -0.1121\n",
            "S-2820\tQuite a few more .\n",
            "T-2820\tNhiều hơn một chút .\n",
            "H-2820\t-1.0789905786514282\tMột vài cái nữa .\n",
            "D-2820\t-1.0789905786514282\tMột vài cái nữa .\n",
            "P-2820\t-3.3165 -0.3905 -1.7348 -0.5441 -0.3963 -0.0917\n",
            "S-2228\tOne is South Korea .\n",
            "T-2228\tMột ở Hàn Quốc .\n",
            "H-2228\t-0.26577290892601013\tMột là Hàn Quốc .\n",
            "D-2228\t-0.26577290892601013\tMột là Hàn Quốc .\n",
            "P-2228\t-0.1366 -0.2654 -0.8293 -0.0131 -0.2523 -0.0980\n",
            "S-1463\tI don &apos;t think so .\n",
            "T-1463\tTôi không nghĩ vậy .\n",
            "H-1463\t-0.2907918393611908\tTôi không nghĩ vậy .\n",
            "D-1463\t-0.2907918393611908\tTôi không nghĩ vậy .\n",
            "P-1463\t-0.1797 -0.1264 -0.1600 -0.8801 -0.2946 -0.1041\n",
            "S-1312\tThis is really cool . &quot;\n",
            "T-1312\tThật là tuyệt . &quot;\n",
            "H-1312\t-0.7436790466308594\tĐiều này thật tuyệt . &quot;\n",
            "D-1312\t-0.7436790466308594\tĐiều này thật tuyệt . &quot;\n",
            "P-1312\t-1.7001 -0.3017 -0.5622 -1.6084 -0.7946 -0.1501 -0.0887\n",
            "S-839\tWho does the very best ?\n",
            "T-839\tAi làm tốt nhất ?\n",
            "H-839\t-0.5718026161193848\tAi làm được điều tốt nhất ?\n",
            "D-839\t-0.5718026161193848\tAi làm được điều tốt nhất ?\n",
            "P-839\t-0.0455 -1.0183 -2.1187 -0.8314 -0.3194 -0.0398 -0.0974 -0.1040\n",
            "S-678\tFly away , cat .\n",
            "T-678\tcon mèo bay đi .\n",
            "H-678\t-0.9069827198982239\tChuyến đi , mèo .\n",
            "D-678\t-0.9069827198982239\tChuyến đi , mèo .\n",
            "P-678\t-2.8774 -2.6695 -0.0165 -0.2767 -0.1902 -0.2131 -0.1056\n",
            "S-672\tThe orange tractor .\n",
            "T-672\tMáy kéo màu cam .\n",
            "H-672\t-0.9310761094093323\tMẩu màu cam .\n",
            "D-672\t-0.9310761094093323\tMẩu màu cam .\n",
            "P-672\t-1.2946 -2.8528 -0.8676 -0.0257 -0.4456 -0.1002\n",
            "S-5045\tThis is Stephen Watt .\n",
            "T-5045\tStephen Watt .\n",
            "H-5045\t-0.09297052025794983\tĐây là Stephen Watt .\n",
            "D-5045\t-0.09297052025794983\tĐây là Stephen Watt .\n",
            "P-5045\t-0.0985 -0.1186 -0.0230 -0.0770 -0.0003 -0.2311 -0.1022\n",
            "S-2823\tWhat about longevity ?\n",
            "T-2823\tTuổi thọ ?\n",
            "H-2823\t-0.5535574555397034\tThế còn tuổi thọ thì sao ?\n",
            "D-2823\t-0.5535574555397034\tThế còn tuổi thọ thì sao ?\n",
            "P-2823\t-2.7813 -0.1467 -1.0907 -0.0082 -0.1558 -0.0226 -0.1140 -0.1091\n",
            "S-823\tAnd it &apos;s pretty amazing .\n",
            "T-823\tThật ngạc nhiên .\n",
            "H-823\t-0.8773956894874573\tVà nó khá là kinh ngạc .\n",
            "D-823\t-0.8773956894874573\tVà nó khá là kinh ngạc .\n",
            "P-823\t-1.3754 -1.4975 -1.5125 -0.6167 -1.5134 -0.1512 -0.2535 -0.0989\n",
            "S-1918\tI &apos;ve loved only two .\n",
            "T-1918\tTôi chỉ yêu có hai .\n",
            "H-1918\t-0.8508301377296448\tTôi chỉ yêu 2 cái .\n",
            "D-1918\t-0.8508301377296448\tTôi chỉ yêu 2 cái .\n",
            "P-1918\t-0.1819 -0.5885 -0.6260 -1.6920 -2.4068 -0.3623 -0.0983\n",
            "S-6845\tAnd he leapt .\n",
            "T-6845\tRồi ông ấy nhảy xuống .\n",
            "H-6845\t-0.8051037192344666\tVà ông ấy nhảy .\n",
            "D-6845\t-0.8051037192344666\tVà ông ấy nhảy .\n",
            "P-6845\t-0.5395 -1.4178 -1.2100 -0.3895 -1.1674 -0.1063\n",
            "S-6194\tThis was the very first .\n",
            "T-6194\tĐây là tấm đầu tiên .\n",
            "H-6194\t-0.4249354302883148\tĐây là lần đầu tiên .\n",
            "D-6194\t-0.4249354302883148\tĐây là lần đầu tiên .\n",
            "P-6194\t-1.0469 -0.1516 -1.1987 -0.0794 -0.1114 -0.2839 -0.1027\n",
            "S-5977\tPeace . Thank you .\n",
            "T-5977\tChào . Xin cảm ơn .\n",
            "H-5977\t-0.678097128868103\tPeace . Xin cảm ơn .\n",
            "D-5977\t-0.678097128868103\tPeace . Xin cảm ơn .\n",
            "P-5977\t-3.8138 -0.1230 -0.1582 -0.1192 -0.7213 -0.0770 -0.3197 -0.0927\n",
            "S-5711\tThat was awkward .\n",
            "T-5711\tNó thật là kì cục .\n",
            "H-5711\t-0.5762224197387695\tĐiều đó thật lúng túng .\n",
            "D-5711\t-0.5762224197387695\tĐiều đó thật lúng túng .\n",
            "P-5711\t-0.6092 -0.7619 -1.3926 -1.7347 -0.0345 -0.0017 -0.0054 -0.5486 -0.0976\n",
            "S-4872\tBut there &apos;s another thing .\n",
            "T-4872\tNhưng một điều khác nữa .\n",
            "H-4872\t-0.5451280474662781\tNhưng có một điều khác .\n",
            "D-4872\t-0.5451280474662781\tNhưng có một điều khác .\n",
            "P-4872\t-0.1891 -1.2360 -0.2386 -1.1472 -0.4927 -0.4070 -0.1052\n",
            "S-4752\tIt &apos;s spreading virally .\n",
            "T-4752\tNó lan truyền rộng rãi .\n",
            "H-4752\t-0.5228056907653809\tNó lan truyền rộng rãi .\n",
            "D-4752\t-0.5228056907653809\tNó lan truyền rộng rãi .\n",
            "P-4752\t-0.2471 -0.4385 -0.9332 -0.6605 -0.8797 -0.3983 -0.1023\n",
            "S-4482\tSolar technology is ...\n",
            "T-4482\tCông nghệ Mặt Trời là ...\n",
            "H-4482\t-0.20500455796718597\tCông nghệ Solar là ...\n",
            "D-4482\t-0.20500455796718597\tCông nghệ Solar là ...\n",
            "P-4482\t-0.1447 -0.0205 -0.0819 -0.0072 -0.0190 -0.4813 -0.8201 -0.0654\n",
            "S-4367\tAnd here &apos;s the thing .\n",
            "T-4367\tVà vấn đề là đây .\n",
            "H-4367\t-0.31985265016555786\tVà đây là vấn đề .\n",
            "D-4367\t-0.31985265016555786\tVà đây là vấn đề .\n",
            "P-4367\t-0.2948 -0.4461 -0.2252 -0.7943 -0.0671 -0.3159 -0.0956\n",
            "S-4258\tAnd I felt really good .\n",
            "T-4258\tVà tôi cũng thấy tốt .\n",
            "H-4258\t-0.45319750905036926\tVà tôi cảm thấy rất tốt .\n",
            "D-4258\t-0.45319750905036926\tVà tôi cảm thấy rất tốt .\n",
            "P-4258\t-0.8082 -0.1717 -0.4744 -0.1686 -1.0109 -0.6921 -0.1945 -0.1052\n",
            "S-4192\tSo let me recap .\n",
            "T-4192\tĐể tôi khái quát lại .\n",
            "H-4192\t-0.8346034288406372\tĐể tôi đóng lại .\n",
            "D-4192\t-0.8346034288406372\tĐể tôi đóng lại .\n",
            "P-4192\t-1.9295 -0.1031 -2.3461 -0.1956 -0.3374 -0.0960\n",
            "S-4159\tOkay , there &apos;s some .\n",
            "T-4159\ttốt , có vài người .\n",
            "H-4159\t-0.6878929138183594\tĐược rồi , có một số .\n",
            "D-4159\t-0.6878929138183594\tĐược rồi , có một số .\n",
            "P-4159\t-1.2963 -0.1710 -0.2215 -0.6295 -1.0517 -1.0768 -0.9611 -0.0953\n",
            "S-4109\tThe first : Cut .\n",
            "T-4109\tĐầu tiên : Cắt giảm\n",
            "H-4109\t-0.43001601099967957\tĐầu tiên : Cắt .\n",
            "D-4109\t-0.43001601099967957\tĐầu tiên : Cắt .\n",
            "P-4109\t-0.8036 -0.1006 -0.2739 -0.7415 -0.9218 -0.0727 -0.0960\n",
            "S-3837\tIt will get to you .\n",
            "T-3837\tđến những điều vừa nêu .\n",
            "H-3837\t-0.6520909667015076\tNó sẽ giúp bạn .\n",
            "D-3837\t-0.6520909667015076\tNó sẽ giúp bạn .\n",
            "P-3837\t-0.5445 -0.2318 -2.4018 -0.3776 -0.2556 -0.1013\n",
            "S-1678\tThank you . Thank you .\n",
            "T-1678\tCảm ơn . Cảm ơn .\n",
            "H-1678\t-0.3114038109779358\tXin cảm ơn .\n",
            "D-1678\t-0.3114038109779358\tXin cảm ơn .\n",
            "P-1678\t-0.0357 -0.9752 -0.0958 -0.2633 -0.1871\n",
            "S-2250\tMy name is Amit .\n",
            "T-2250\tTên tôi là Amit .\n",
            "H-2250\t-1.042803168296814\tTên tôi là Aye .\n",
            "D-2250\t-1.042803168296814\tTên tôi là Aye .\n",
            "P-2250\t-0.6616 -0.1054 -0.0968 -0.0166 -6.0654 -0.2509 -0.1030\n",
            "S-2324\tAnd the answer is no .\n",
            "T-2324\tCâu trả lời là không .\n",
            "H-2324\t-0.2629411816596985\tVà câu trả lời là không .\n",
            "D-2324\t-0.2629411816596985\tVà câu trả lời là không .\n",
            "P-2324\t-1.1613 -0.0663 -0.0547 -0.0331 -0.3618 -0.1549 -0.1677 -0.1038\n",
            "S-2617\tJK : Both .\n",
            "T-2617\tJK : Cả hai .\n",
            "H-2617\t-0.5587549805641174\tJK : Both .\n",
            "D-2617\t-0.5587549805641174\tJK : Both .\n",
            "P-2617\t-0.0042 -0.0013 -0.0399 -3.2851 -0.0771 -0.4055 -0.0981\n",
            "S-3100\tIt &apos;s completely directed .\n",
            "T-3100\tHoàn toàn trực tiếp .\n",
            "H-3100\t-0.4905325770378113\tNó hoàn toàn hướng dẫn .\n",
            "D-3100\t-0.4905325770378113\tNó hoàn toàn hướng dẫn .\n",
            "P-3100\t-0.9185 -0.0279 -0.0403 -0.4755 -1.4951 -0.3780 -0.0984\n",
            "S-3125\tAnd that worked pretty well .\n",
            "T-3125\tKết quả khá thành công .\n",
            "H-3125\t-0.9010871648788452\tVà điều đó khá tốt .\n",
            "D-3125\t-0.9010871648788452\tVà điều đó khá tốt .\n",
            "P-3125\t-0.8718 -1.1653 -0.7339 -2.5736 -0.6133 -0.2432 -0.1065\n",
            "S-3181\tI &apos;ve got a question .\n",
            "T-3181\tTôi có một câu hỏi .\n",
            "H-3181\t-0.2295464277267456\tTôi có một câu hỏi .\n",
            "D-3181\t-0.2295464277267456\tTôi có một câu hỏi .\n",
            "P-3181\t-0.2573 -0.5342 -0.3995 -0.0264 -0.0480 -0.2390 -0.1024\n",
            "S-3274\tHe liked it very much .\n",
            "T-3274\tVà ông ấy rất thích .\n",
            "H-3274\t-0.6134316921234131\tAnh ấy thích nó rất nhiều .\n",
            "D-3274\t-0.6134316921234131\tAnh ấy thích nó rất nhiều .\n",
            "P-3274\t-1.2000 -0.8006 -0.8401 -0.5729 -1.0851 -0.0937 -0.2144 -0.1006\n",
            "S-3343\tI was in awe .\n",
            "T-3343\tTôi cảm thấy kinh ngạc .\n",
            "H-3343\t-0.9748056530952454\tTôi đã ở trong aurus .\n",
            "D-3343\t-0.9748056530952454\tTôi đã ở trong aurus .\n",
            "P-3343\t-0.1985 -1.5446 -0.7777 -0.2735 -0.5691 -4.2177 -0.7362 -0.3584 -0.0976\n",
            "S-3756\tWe &apos;ve been disconnected .\n",
            "T-3756\tthế là chúng ta tách biệt\n",
            "H-3756\t-0.6859676837921143\tChúng ta đã bị chia cắt .\n",
            "D-3756\t-0.6859676837921143\tChúng ta đã bị chia cắt .\n",
            "P-3756\t-0.1556 -0.5433 -0.2716 -0.9086 -1.3477 -1.9924 -0.1658 -0.1027\n",
            "S-3811\tAnd I thought about that .\n",
            "T-3811\tvà tôi nghĩ về điều này\n",
            "H-3811\t-0.34814730286598206\tVà tôi nghĩ về điều đó .\n",
            "D-3811\t-0.34814730286598206\tVà tôi nghĩ về điều đó .\n",
            "P-3811\t-0.6553 -0.1425 -0.4619 -0.4013 -0.3876 -0.3858 -0.2500 -0.1008\n",
            "S-3873\tI don &apos;t believe that .\n",
            "T-3873\tTôi không tin như thế .\n",
            "H-3873\t-0.5891361236572266\tTôi không tin điều đó .\n",
            "D-3873\t-0.5891361236572266\tTôi không tin điều đó .\n",
            "P-3873\t-0.1536 -0.1001 -0.1361 -3.1000 -0.3383 -0.1875 -0.1082\n",
            "S-6748\tMost die on impact .\n",
            "T-6748\tĐa số đều chết do va chạm .\n",
            "H-6748\t-0.45856237411499023\tHầu hết đều chết vì ảnh hưởng .\n",
            "D-6748\t-0.45856237411499023\tHầu hết đều chết vì ảnh hưởng .\n",
            "P-6748\t-0.3702 -0.0913 -1.6523 -0.0401 -0.6101 -1.0241 -0.0177 -0.2179 -0.1032\n",
            "S-4462\tWhat does this mean ?\n",
            "T-4462\tVideo của Bear Vaxquez : Điều này có nghĩa gì ?\n",
            "H-4462\t-0.21809253096580505\tĐiều này có nghĩa là gì ?\n",
            "D-4462\t-0.21809253096580505\tĐiều này có nghĩa là gì ?\n",
            "P-4462\t-0.4156 -0.3761 -0.1650 -0.2435 -0.3153 -0.0377 -0.0955 -0.0960\n",
            "S-6085\tWe have zero infrastructure .\n",
            "T-6085\tChúng tôi không có bất cứ cơ sở hạ tầng nào .\n",
            "H-6085\t-0.355366587638855\tChúng ta có 0 cơ sở hạ tầng .\n",
            "D-6085\t-0.355366587638855\tChúng ta có 0 cơ sở hạ tầng .\n",
            "P-6085\t-0.2025 -0.3367 -0.1585 -2.1803 -0.1774 -0.0090 -0.0149 -0.0026 -0.3740 -0.0978\n",
            "S-5377\tWe victims need everyone .\n",
            "T-5377\tChúng ta những nạn nhân cần đến tất cả mọi người .\n",
            "H-5377\t-0.5369518995285034\tChúng ta cần các nạn nhân .\n",
            "D-5377\t-0.5369518995285034\tChúng ta cần các nạn nhân .\n",
            "P-5377\t-0.2162 -0.1446 -0.0800 -3.1345 -0.0362 -0.0006 -0.5815 -0.1021\n",
            "S-961\tWhat happens is this .\n",
            "T-961\tBây giờ tôi sẽ giải thích cho các bạn được rõ .\n",
            "H-961\t-0.5566818118095398\tĐiều xảy ra là đây .\n",
            "D-961\t-0.5566818118095398\tĐiều xảy ra là đây .\n",
            "P-961\t-0.5521 -0.3980 -0.0939 -0.4779 -2.0449 -0.2366 -0.0934\n",
            "S-204\tThis happened around Christmas .\n",
            "T-204\tVụ này xảy ra gần Giáng Sinh .\n",
            "H-204\t-0.3703165650367737\tĐiều này xảy ra xung quanh Giáng sinh .\n",
            "D-204\t-0.3703165650367737\tĐiều này xảy ra xung quanh Giáng sinh .\n",
            "P-204\t-0.6183 -0.2973 -0.8564 -0.0793 -0.5848 -0.0286 -0.2448 -0.0007 -0.8093 -0.4607 -0.0933\n",
            "S-4765\tAnd that &apos;s nothing .\n",
            "T-4765\tNhưng những con số chẳng là gì cả .\n",
            "H-4765\t-0.691043496131897\tVà đó không phải là điều gì .\n",
            "D-4765\t-0.691043496131897\tVà đó không phải là điều gì .\n",
            "P-4765\t-0.4797 -1.6494 -0.8182 -0.2510 -0.1720 -1.3140 -0.7996 -0.6285 -0.1070\n",
            "S-4697\tScore them again .\n",
            "T-4697\tĐánh giá lại chúng một lần nữa .\n",
            "H-4697\t-0.8496308922767639\tSlõi lần nữa .\n",
            "D-4697\t-0.8496308922767639\tSlõi lần nữa .\n",
            "P-4697\t-3.3650 -1.0989 -0.2355 -0.0282 -0.2703 -0.1000\n",
            "S-3974\tSo what happens here ?\n",
            "T-3974\tVậy thì điều gì xảy ra tại đây ?\n",
            "H-3974\t-0.3571035861968994\tVậy điều gì xảy ra ở đây ?\n",
            "D-3974\t-0.3571035861968994\tVậy điều gì xảy ra ở đây ?\n",
            "P-3974\t-0.6164 -0.5472 -0.0572 -1.3557 -0.0950 -0.2810 -0.0797 -0.0835 -0.0981\n",
            "S-2683\tSuperior technology .\n",
            "T-2683\tNgười phụ nữ : công nghệ hiện đại .\n",
            "H-2683\t-0.47278469800949097\tCông nghệ hay công nghệ .\n",
            "D-2683\t-0.47278469800949097\tCông nghệ hay công nghệ .\n",
            "P-2683\t-1.0157 -0.0410 -1.1516 -0.2223 -0.0464 -0.7345 -0.0981\n",
            "  5% 3/60 [00:04<01:30,  1.58s/it, wps=533]S-6933\tYou step up into the pocket .\n",
            "T-6933\tBạn bị chèn .\n",
            "H-6933\t-0.4780316650867462\tBạn bước vào túi .\n",
            "D-6933\t-0.4780316650867462\tBạn bước vào túi .\n",
            "P-6933\t-0.4391 -0.0871 -0.9153 -0.9973 -0.3246 -0.1047\n",
            "S-220\tLeave that up to us .\n",
            "T-220\tCứ để đấy cho chúng tôi .\n",
            "H-220\t-0.896690845489502\tHãy để nó đến với chúng ta .\n",
            "D-220\t-0.896690845489502\tHãy để nó đến với chúng ta .\n",
            "P-220\t-0.9450 -1.7675 -1.1626 -2.3856 -0.3948 -0.1643 -0.8249 -0.3266 -0.0990\n",
            "S-6598\tIt is the criteria .\n",
            "T-6598\tĐó là các tiêu chuẩn .\n",
            "H-6598\t-0.4701867699623108\tĐó là tiêu chuẩn .\n",
            "D-6598\t-0.4701867699623108\tĐó là tiêu chuẩn .\n",
            "P-6598\t-1.0175 -0.3110 -0.3576 -0.5932 -0.4406 -0.1012\n",
            "S-6371\tLet &apos;s take a step back .\n",
            "T-6371\tTa hãy lùi một bước .\n",
            "H-6371\t-0.7119684219360352\tHãy lùi lại một chút .\n",
            "D-6371\t-0.7119684219360352\tHãy lùi lại một chút .\n",
            "P-6371\t-0.8297 -1.8474 -0.1358 -0.4626 -1.2743 -0.3273 -0.1066\n",
            "S-6182\tAnd everyone was doing the same .\n",
            "T-6182\tTất cả đều làm vậy .\n",
            "H-6182\t-0.5796811580657959\tVà mọi người đều làm điều tương tự .\n",
            "D-6182\t-0.5796811580657959\tVà mọi người đều làm điều tương tự .\n",
            "P-6182\t-0.8043 -0.4800 -0.1036 -0.6447 -1.0369 -2.1774 -0.1641 -0.0437 -0.2322 -0.1100\n",
            "S-5928\tSee , I &apos;m an artist .\n",
            "T-5928\tTôi là một nghệ sĩ .\n",
            "H-5928\t-0.38144591450691223\tThấy không , tôi là một nghệ sĩ .\n",
            "D-5928\t-0.38144591450691223\tThấy không , tôi là một nghệ sĩ .\n",
            "P-5928\t-1.6016 -0.0087 -0.5173 -0.1253 -0.1728 -0.1795 -0.3044 -0.3900 -0.1865 -0.6112 -0.0986\n",
            "S-5741\tIt will look something like this .\n",
            "T-5741\tGiống như thế này đây .\n",
            "H-5741\t-0.34324735403060913\tNó sẽ trông như thế này .\n",
            "D-5741\t-0.34324735403060913\tNó sẽ trông như thế này .\n",
            "P-5741\t-0.2537 -0.2826 -0.2361 -1.1446 -0.0957 -0.0817 -0.5421 -0.1094\n",
            "S-5273\tBut I will do a trial .\n",
            "T-5273\tNhưng để tôi thử xem .\n",
            "H-5273\t-0.48716557025909424\tNhưng tôi sẽ thực hiện phép thử .\n",
            "D-5273\t-0.48716557025909424\tNhưng tôi sẽ thực hiện phép thử .\n",
            "P-5273\t-0.1946 -0.1456 -0.2175 -1.4715 -0.1032 -1.9041 -0.0100 -0.2312 -0.1068\n",
            "S-4573\tIt &apos;s not moving like that .\n",
            "T-4573\tNó không phải như vậy .\n",
            "H-4573\t-0.32364514470100403\tNó không di chuyển như thế .\n",
            "D-4573\t-0.32364514470100403\tNó không di chuyển như thế .\n",
            "P-4573\t-0.3203 -0.2626 -0.2193 -0.0305 -0.2797 -0.7653 -0.6029 -0.1086\n",
            "S-4408\tAll right , let &apos;s go .\n",
            "T-4408\tChúng ta bắt đầu nào .\n",
            "H-4408\t-0.5471038222312927\tĐược rồi , hãy cùng đi .\n",
            "D-4408\t-0.5471038222312927\tĐược rồi , hãy cùng đi .\n",
            "P-4408\t-0.9418 -0.0728 -0.2212 -0.7151 -1.3280 -0.3740 -0.6237 -0.1003\n",
            "S-3988\tThey were still kind of happy .\n",
            "T-3988\tchúng vẫn rất yên ổn .\n",
            "H-3988\t-0.33068761229515076\tHọ vẫn hạnh phúc .\n",
            "D-3988\t-0.33068761229515076\tHọ vẫn hạnh phúc .\n",
            "P-3988\t-0.4600 -0.0862 -0.9337 -0.0310 -0.3682 -0.1050\n",
            "S-782\tSo , I just started playing .\n",
            "T-782\tVậy nên tôi bắt đầu chơi\n",
            "H-782\t-0.7813235521316528\tThế nên , tôi bắt đầu chơi .\n",
            "D-782\t-0.7813235521316528\tThế nên , tôi bắt đầu chơi .\n",
            "P-782\t-2.6486 -0.6054 -1.0958 -0.1455 -1.1530 -0.0769 -0.4644 -0.7426 -0.0997\n",
            "S-41\tThey speared each other .\n",
            "T-41\tHọ còn đâm lẫn nhau .\n",
            "H-41\t-0.895248532295227\tHọ xoay lẫn nhau .\n",
            "D-41\t-0.895248532295227\tHọ xoay lẫn nhau .\n",
            "P-41\t-1.1339 -2.0754 -1.6587 -0.1563 -0.2438 -0.1034\n",
            "S-7214\tDoes Canada have its own consciousness ?\n",
            "T-7214\tCanada có nhận thức riêng\n",
            "H-7214\t-0.3557562828063965\tLiệu Canada có nhận thức của riêng mình không ?\n",
            "D-7214\t-0.3557562828063965\tLiệu Canada có nhận thức của riêng mình không ?\n",
            "P-7214\t-0.1255 -0.0181 -0.1272 -0.4565 -0.0205 -1.5797 -0.4500 -0.3005 -0.6666 -0.0669 -0.1018\n",
            "S-4621\tSo what was the next step ?\n",
            "T-4621\tVậy bước tiếp theo là gì ?\n",
            "H-4621\t-0.10778925567865372\tVậy bước tiếp theo là gì ?\n",
            "D-4621\t-0.10778925567865372\tVậy bước tiếp theo là gì ?\n",
            "P-4621\t-0.2179 -0.0299 -0.2319 -0.0089 -0.1204 -0.0451 -0.0996 -0.1085\n",
            "S-6908\tIt was more entertaining .\n",
            "T-6908\tThú vị hơn .\n",
            "H-6908\t-0.6761947274208069\tNó thú vị hơn .\n",
            "D-6908\t-0.6761947274208069\tNó thú vị hơn .\n",
            "P-6908\t-0.7524 -2.6502 -0.0382 -0.0907 -0.4190 -0.1067\n",
            "S-5965\tNow don &apos;t get me wrong .\n",
            "T-5965\tĐừng hiểu lầm tôi .\n",
            "H-5965\t-0.420815646648407\tĐừng hiểu sai ý tôi .\n",
            "D-5965\t-0.420815646648407\tĐừng hiểu sai ý tôi .\n",
            "P-5965\t-0.9695 -0.2542 -0.9865 -0.0480 -0.3271 -0.2556 -0.1047\n",
            "S-5872\tIt &apos;s much better than that .\n",
            "T-5872\tHơn mức đó nhiều chứ\n",
            "H-5872\t-0.42880597710609436\tNó tốt hơn thế nhiều .\n",
            "D-5872\t-0.42880597710609436\tNó tốt hơn thế nhiều .\n",
            "P-5872\t-1.3409 -0.2971 -0.0879 -0.3384 -0.5025 -0.3297 -0.1051\n",
            "S-5212\tHe screamed a lot .\n",
            "T-5212\tEm la hét nhiều .\n",
            "H-5212\t-0.42784881591796875\tAnh ta la hét rất nhiều .\n",
            "D-5212\t-0.42784881591796875\tAnh ta la hét rất nhiều .\n",
            "P-5212\t-1.2280 -0.6526 -0.6224 -0.2582 -0.2806 -0.0734 -0.2050 -0.1027\n",
            "S-3240\tItaly wins . Yeah .\n",
            "T-3240\tÝ thắng . Yeah .\n",
            "H-3240\t-1.1129786968231201\tNgười Ý . Đúng vậy .\n",
            "D-3240\t-1.1129786968231201\tNgười Ý . Đúng vậy .\n",
            "P-3240\t-3.6355 -0.1085 -1.0275 -1.7889 -0.8785 -0.2621 -0.0899\n",
            "S-3153\tThat &apos;s cool , huh ?\n",
            "T-3153\tHay quá phải không ?\n",
            "H-3153\t-0.5641351938247681\tThật tuyệt , phải không ?\n",
            "D-3153\t-0.5641351938247681\tThật tuyệt , phải không ?\n",
            "P-3153\t-0.8600 -0.8414 -0.8526 -0.8254 -0.0613 -0.4067 -0.1016\n",
            "S-3028\tAww , thank you .\n",
            "T-3028\tỒ , cảm ơn .\n",
            "H-3028\t-0.34363365173339844\tXin cảm ơn .\n",
            "D-3028\t-0.34363365173339844\tXin cảm ơn .\n",
            "P-3028\t-0.2041 -0.9705 -0.0667 -0.3844 -0.0926\n",
            "S-3004\tShe did it for three years .\n",
            "T-3004\ttrong vòng ba năm ,\n",
            "H-3004\t-0.611487865447998\tCô ấy đã làm điều đó trong 3 năm .\n",
            "D-3004\t-0.611487865447998\tCô ấy đã làm điều đó trong 3 năm .\n",
            "P-3004\t-0.6882 -0.9827 -0.3951 -0.3457 -1.6395 -0.8142 -0.2645 -0.9046 -0.0510 -0.5487 -0.0923\n",
            "S-948\tSo , here &apos;s what happens .\n",
            "T-948\tNó là thế này .\n",
            "H-948\t-0.5177536606788635\tVà đây là những gì xảy ra .\n",
            "D-948\t-0.5177536606788635\tVà đây là những gì xảy ra .\n",
            "P-948\t-1.2497 -0.2885 -0.1527 -0.7011 -0.1076 -1.5876 -0.1024 -0.3771 -0.0932\n",
            "S-1596\tThis is a lot of volume .\n",
            "T-1596\tĐây là rất nhiều\n",
            "H-1596\t-0.6287106275558472\tĐây là một khối lượng rất lớn .\n",
            "D-1596\t-0.6287106275558472\tĐây là một khối lượng rất lớn .\n",
            "P-1596\t-1.2037 -0.1863 -1.6667 -0.6088 -0.0357 -1.1719 -0.4900 -0.1968 -0.0985\n",
            "S-686\tSo let &apos;s have a look .\n",
            "T-686\tHãy thử xem .\n",
            "H-686\t-1.0033831596374512\tChúng ta hãy xem nhé .\n",
            "D-686\t-1.0033831596374512\tChúng ta hãy xem nhé .\n",
            "P-686\t-3.2052 -0.0646 -0.1138 -1.6516 -1.5930 -0.2883 -0.1073\n",
            "S-406\tDon &apos;t be daunted .\n",
            "T-406\tĐừng nản lòng .\n",
            "H-406\t-0.665553867816925\tĐừng bị tổn thương .\n",
            "D-406\t-0.665553867816925\tĐừng bị tổn thương .\n",
            "P-406\t-0.0178 -0.2278 -3.3289 -0.0596 -0.2600 -0.0993\n",
            "S-617\tThey actually make us worse off .\n",
            "T-617\tChúng làm ta thấy tồi tệ .\n",
            "H-617\t-0.6835589408874512\tChúng làm chúng ta tệ hơn .\n",
            "D-617\t-0.6835589408874512\tChúng làm chúng ta tệ hơn .\n",
            "P-617\t-1.6407 -0.8223 -0.4993 -0.4058 -1.6145 -0.0613 -0.3214 -0.1032\n",
            "S-4506\tIt can know where we are .\n",
            "T-4506\tNó biết ta đang ở đâu .\n",
            "H-4506\t-0.23179109394550323\tNó có thể biết chúng ta đang ở đâu .\n",
            "D-4506\t-0.23179109394550323\tNó có thể biết chúng ta đang ở đâu .\n",
            "P-4506\t-0.7411 -0.5176 -0.0804 -0.1195 -0.3233 -0.1291 -0.0781 -0.1286 -0.0733 -0.2568 -0.1020\n",
            "S-4318\tAnd I went back to work .\n",
            "T-4318\tVà tôi quay lại làm việc .\n",
            "H-4318\t-0.4560838043689728\tVà tôi trở lại làm việc .\n",
            "D-4318\t-0.4560838043689728\tVà tôi trở lại làm việc .\n",
            "P-4318\t-0.9047 -0.2723 -1.5993 -0.2791 -0.1094 -0.1010 -0.2820 -0.1010\n",
            "S-4312\tWhy did I go into medicine ?\n",
            "T-4312\tTại sao tôi học ngành y ?\n",
            "H-4312\t-0.5888726115226746\tTại sao tôi lại đi vào thuốc ?\n",
            "D-4312\t-0.5888726115226746\tTại sao tôi lại đi vào thuốc ?\n",
            "P-4312\t-0.1449 -0.0639 -0.2233 -0.3181 -2.3060 -0.8196 -1.2439 -0.0833 -0.0968\n",
            "S-4209\tIt &apos;s called batting average .\n",
            "T-4209\tĐó là chỉ số đập bóng .\n",
            "H-4209\t-0.25503814220428467\tNó được gọi là đánh bóng trung bình .\n",
            "D-4209\t-0.25503814220428467\tNó được gọi là đánh bóng trung bình .\n",
            "P-4209\t-0.5890 -0.2878 -0.0791 -0.1264 -0.2785 -0.7005 -0.1163 -0.0069 -0.2648 -0.1011\n",
            "S-3783\tIt &apos;s not our burden .\n",
            "T-3783\tkhông phải gánh nặng của chúng ta\n",
            "H-3783\t-0.30801817774772644\tNó không phải gánh nặng của chúng ta .\n",
            "D-3783\t-0.30801817774772644\tNó không phải gánh nặng của chúng ta .\n",
            "P-3783\t-1.2242 -0.1327 -0.2635 -0.0863 -0.0010 -0.2476 -0.3178 -0.3074 -0.4006 -0.0992\n",
            "S-3779\tI mean , it &apos;s fascinating .\n",
            "T-3779\tthật sự khó mà tưởng tượng nỗi\n",
            "H-3779\t-0.6113736629486084\tÝ tôi là , thật thú vị .\n",
            "D-3779\t-0.6113736629486084\tÝ tôi là , thật thú vị .\n",
            "P-3779\t-1.5251 -0.1346 -0.1107 -0.5313 -1.4574 -1.4008 -0.0273 -0.2096 -0.1055\n",
            "S-3596\tCenters were established .\n",
            "T-3596\tCác trung tâm được thành lập .\n",
            "H-3596\t-0.49685972929000854\tCenters đã được thành lập .\n",
            "D-3596\t-0.49685972929000854\tCenters đã được thành lập .\n",
            "P-3596\t-0.4405 -0.0087 -0.8976 -1.1077 -0.4430 -1.3094 -0.0065 -0.1536 -0.1048\n",
            "S-3546\tThis is not a finished story .\n",
            "T-3546\tCâu chuyện này chưa kết thúc .\n",
            "H-3546\t-0.335208535194397\tĐây không phải là một câu chuyện hoàn chỉnh .\n",
            "D-3546\t-0.335208535194397\tĐây không phải là một câu chuyện hoàn chỉnh .\n",
            "P-3546\t-0.2960 -0.1382 -0.0756 -0.1891 -1.4094 -0.0627 -0.0511 -0.0643 -1.0688 -0.2255 -0.1066\n",
            "S-3321\tIt &apos;s called The Cloud .\n",
            "T-3321\tTên gọi là The Cloud .\n",
            "H-3321\t-0.5292209386825562\tNó được gọi là The Cây .\n",
            "D-3321\t-0.5292209386825562\tNó được gọi là The Cây .\n",
            "P-3321\t-0.5261 -0.2523 -0.0432 -0.1318 -0.2171 -0.0382 -2.4194 -1.0338 -0.1011\n",
            "S-3162\tYour plant can blow up .\n",
            "T-3162\tNhà máy có thể nổ tung .\n",
            "H-3162\t-0.37876632809638977\tCây của bạn có thể thổi phồng lên .\n",
            "D-3162\t-0.37876632809638977\tCây của bạn có thể thổi phồng lên .\n",
            "P-3162\t-0.6605 -0.1364 -0.4124 -0.4231 -0.1675 -0.1000 -0.2846 -1.1787 -0.1406 -0.7171 -0.2137 -0.1107\n",
            "S-3090\tThat &apos;s easy , huh ?\n",
            "T-3090\tNghe thật dễ dàng phải không ?\n",
            "H-3090\t-0.8069389462471008\tThật dễ dàng phải không ?\n",
            "D-3090\t-0.8069389462471008\tThật dễ dàng phải không ?\n",
            "P-3090\t-1.8009 -0.1161 -2.6677 -0.5119 -0.0343 -0.4206 -0.0969\n",
            "S-2955\tWho are these cousins ?\n",
            "T-2955\tNhững họ hàng này là ai ?\n",
            "H-2955\t-0.5107039213180542\tAi là anh em họ ?\n",
            "D-2955\t-0.5107039213180542\tAi là anh em họ ?\n",
            "P-2955\t-2.8035 -0.2100 -0.2355 -0.0749 -0.0145 -0.1338 -0.1027\n",
            "S-2815\tHow many people would choose creativity ?\n",
            "T-2815\tBao nhiêu người chọn sáng tạo ?\n",
            "H-2815\t-0.22362050414085388\tBao nhiêu người sẽ chọn sáng tạo ?\n",
            "D-2815\t-0.22362050414085388\tBao nhiêu người sẽ chọn sáng tạo ?\n",
            "P-2815\t-0.5824 -0.0981 -0.0891 -0.4281 -0.0459 -0.5459 -0.0484 -0.0764 -0.0984\n",
            "S-2875\tI wanted to keep us healthy .\n",
            "T-2875\tTôi muốn chúng ta khoẻ mạnh .\n",
            "H-2875\t-0.37662872672080994\tTôi muốn giữ cho chúng tôi khoẻ mạnh .\n",
            "D-2875\t-0.37662872672080994\tTôi muốn giữ cho chúng tôi khoẻ mạnh .\n",
            "P-2875\t-0.1750 -0.1195 -0.7923 -1.0617 -0.1406 -1.0165 -0.1376 -0.0199 -0.2008 -0.1023\n",
            "S-588\tThe truth is more like this .\n",
            "T-588\tSự thật giống vầy hơn .\n",
            "H-588\t-0.3306094706058502\tSự thật thì giống như thế này .\n",
            "D-588\t-0.3306094706058502\tSự thật thì giống như thế này .\n",
            "P-588\t-0.0936 -0.0666 -0.7647 -0.1520 -0.7869 -0.2997 -0.1008 -0.6048 -0.1064\n",
            "S-1567\tIf you burn coal , no .\n",
            "T-1567\tNếu bạn đốt than , không .\n",
            "H-1567\t-0.18330460786819458\tNếu bạn đốt than , không .\n",
            "D-1567\t-0.18330460786819458\tNếu bạn đốt than , không .\n",
            "P-1567\t-0.1058 -0.4159 -0.0194 -0.0033 -0.2032 -0.2294 -0.3894 -0.1000\n",
            "S-1594\tWho &apos;s going to be sure ?\n",
            "T-1594\tAi sẽ đảm bảo điều đó ?\n",
            "H-1594\t-0.46305757761001587\tAi sẽ chắc chắn ?\n",
            "D-1594\t-0.46305757761001587\tAi sẽ chắc chắn ?\n",
            "P-1594\t-0.0509 -0.6778 -0.0497 -0.2675 -1.6189 -0.1136\n",
            "S-1947\t2.5 to one , great .\n",
            "T-1947\t2.5 lấy 1 , được .\n",
            "H-1947\t-0.38159725069999695\t2.5 đến 1 , tuyệt vời .\n",
            "D-1947\t-0.38159725069999695\t2.5 đến 1 , tuyệt vời .\n",
            "P-1947\t-0.0727 -0.0087 -0.2485 -0.1976 -0.7341 -1.3969 -0.2159 -0.4627 -0.0972\n",
            "S-2085\tI don &apos;t love that question .\n",
            "T-2085\tTôi không thích câu hỏi đó .\n",
            "H-2085\t-0.26805582642555237\tTôi không thích câu hỏi đó .\n",
            "D-2085\t-0.26805582642555237\tTôi không thích câu hỏi đó .\n",
            "P-2085\t-0.1476 -0.1245 -1.1117 -0.0694 -0.0668 -0.2741 -0.2421 -0.1084\n",
            "S-2122\tHe turns off the engines .\n",
            "T-2122\tÔng ấy tắt hết động cơ .\n",
            "H-2122\t-0.7455405592918396\tAnh ta tắt các động cơ .\n",
            "D-2122\t-0.7455405592918396\tAnh ta tắt các động cơ .\n",
            "P-2122\t-0.6337 -1.0120 -1.6932 -1.8074 -0.0921 -0.0332 -0.5913 -0.1015\n",
            "S-2209\tEverybody applauded politely .\n",
            "T-2209\tMọi người lịch sự tán thành .\n",
            "H-2209\t-1.0848721265792847\tTất cả mọi người đều ứng dụng .\n",
            "D-2209\t-1.0848721265792847\tTất cả mọi người đều ứng dụng .\n",
            "P-2209\t-2.8546 -0.0531 -0.0341 -0.1014 -0.8886 -3.7407 -0.1328 -1.8540 -0.1046\n",
            "S-2355\tAnd I &apos;ve never seen them .\n",
            "T-2355\tVà tôi chưa từng thấy chúng .\n",
            "H-2355\t-0.408998042345047\tVà tôi chưa bao giờ thấy chúng .\n",
            "D-2355\t-0.408998042345047\tVà tôi chưa bao giờ thấy chúng .\n",
            "P-2355\t-0.8335 -0.2323 -0.1220 -0.2783 -0.0433 -0.4496 -1.3554 -0.2614 -0.1051\n",
            "S-2494\tI was exposed to him .\n",
            "T-2494\tTôi được giới thiệu với anh .\n",
            "H-2494\t-0.6800282001495361\tTôi đã tiếp xúc với anh ta .\n",
            "D-2494\t-0.6800282001495361\tTôi đã tiếp xúc với anh ta .\n",
            "P-2494\t-0.1606 -1.3324 -2.1343 -0.1083 -0.0868 -1.1691 -0.8556 -0.1662 -0.1070\n",
            "S-2570\tI went to prison -- difficult .\n",
            "T-2570\tTôi sống trong ngục khắc nghiệt\n",
            "H-2570\t-0.6603848934173584\tTôi đi tù -- rất khó .\n",
            "D-2570\t-0.6603848934173584\tTôi đi tù -- rất khó .\n",
            "P-2570\t-0.1367 -2.7374 -0.0930 -0.7339 -0.9509 -0.0455 -0.4903 -0.0954\n",
            "S-3782\tIt &apos;s not our problem .\n",
            "T-3782\txem đó không phải là vấn đề của chúng ta ,\n",
            "H-3782\t-0.26420721411705017\tĐó không phải là vấn đề của chúng ta .\n",
            "D-3782\t-0.26420721411705017\tĐó không phải là vấn đề của chúng ta .\n",
            "P-3782\t-1.0586 -0.1077 -0.0734 -0.4769 -0.1097 -0.0791 -0.1299 -0.2125 -0.2436 -0.3168 -0.0980\n",
            "S-2695\tUm , my brand ?\n",
            "T-2695\tThanh niên : Hử , phong cách của tôi ?\n",
            "H-2695\t-0.677937388420105\tCó phải công ty của tôi không ?\n",
            "D-2695\t-0.677937388420105\tCó phải công ty của tôi không ?\n",
            "P-2695\t-3.8443 -0.1120 -0.6904 -0.0334 -0.6856 -0.1235 -0.4006 -0.1200 -0.0918\n",
            "S-2707\tI &apos;m the pet guy .\n",
            "T-2707\tNgười đàn ông : Mình là một anh chàng đồ chơi .\n",
            "H-2707\t-0.640346348285675\tTôi là người vật nuôi .\n",
            "D-2707\t-0.640346348285675\tTôi là người vật nuôi .\n",
            "P-2707\t-0.1952 -0.2845 -1.6065 -1.2420 -0.0311 -1.0207 -0.1025\n",
            "S-4059\tThink about your own choices .\n",
            "T-4059\tBây giờ , nghĩ về những sự lựa chọn của chính bạn\n",
            "H-4059\t-0.6068809032440186\tHãy nghĩ về lựa chọn của riêng bạn .\n",
            "D-4059\t-0.6068809032440186\tHãy nghĩ về lựa chọn của riêng bạn .\n",
            "P-4059\t-0.6636 -0.5704 -0.6646 -1.0221 -0.0844 -0.1387 -1.8386 -0.6675 -0.3161 -0.1029\n",
            "S-6391\tDoes it predict artificial intelligence ?\n",
            "T-6391\tNó có dự báo được trí thông minh của máy không ?\n",
            "H-6391\t-0.5354864001274109\tLiệu nó có thể dự đoán được trí thông minh nhân tạo ?\n",
            "D-6391\t-0.5354864001274109\tLiệu nó có thể dự đoán được trí thông minh nhân tạo ?\n",
            "P-6391\t-0.3651 -0.9528 -0.0492 -2.8839 -0.6018 -0.0097 -1.1686 -0.1655 -0.7761 -0.0204 -0.0028 -0.0042 -0.3988 -0.0979\n",
            "S-6693\tThat moment changed my life .\n",
            "T-6693\tKhoảnh khắc đó đã thay đổi cuộc đời tôi .\n",
            "H-6693\t-0.23998846113681793\tKhoảnh khắc đó đã thay đổi cuộc đời tôi .\n",
            "D-6693\t-0.23998846113681793\tKhoảnh khắc đó đã thay đổi cuộc đời tôi .\n",
            "P-6693\t-0.0884 -0.0031 -0.0026 -0.0093 -0.1484 -0.9512 -0.0426 -0.0302 -0.5833 -0.7868 -0.2277 -0.1431 -0.1031\n",
            "S-7235\tBecause apparently we don &apos;t .\n",
            "T-7235\tBởi vì đúng thật là ta không còn yêu nó nữa .\n",
            "H-7235\t-0.5175025463104248\tBởi vì dường như chúng ta không làm vậy .\n",
            "D-7235\t-0.5175025463104248\tBởi vì dường như chúng ta không làm vậy .\n",
            "P-7235\t-0.3513 -0.0918 -0.9406 -0.0860 -0.4260 -0.1591 -0.1381 -1.6223 -1.5549 -0.2185 -0.1040\n",
            "S-5064\tAnd his answer was yes .\n",
            "T-5064\tVà &quot; CÓ &quot; là câu trả lời của ông ta .\n",
            "H-5064\t-0.3029039204120636\tVà câu trả lời của ông là có .\n",
            "D-5064\t-0.3029039204120636\tVà câu trả lời của ông là có .\n",
            "P-5064\t-0.7105 -0.0516 -0.0359 -0.0355 -0.3246 -1.0109 -0.5081 -0.1085 -0.1447 -0.0987\n",
            "S-3784\tIt &apos;s not our struggle .\n",
            "T-3784\tcũng không phải điều mà chúng ta cần đấu tranh , nỗ lực .\n",
            "H-3784\t-0.32247135043144226\tĐó không phải là cuộc chiến của chúng ta .\n",
            "D-3784\t-0.32247135043144226\tĐó không phải là cuộc chiến của chúng ta .\n",
            "P-3784\t-0.8764 -0.0991 -0.0514 -0.6933 -0.6015 -0.2866 -0.1274 -0.1577 -0.2529 -0.3002 -0.1006\n",
            "S-3229\tHere you see the city .\n",
            "T-3229\tVà đây , bạn có thể thấy thành phố chúng ta như thế nào .\n",
            "H-3229\t-0.49310946464538574\tĐây là thành phố .\n",
            "D-3229\t-0.49310946464538574\tĐây là thành phố .\n",
            "P-3229\t-1.2241 -1.2534 -0.1143 -0.0472 -0.2207 -0.0990\n",
            "S-7052\tSo what opened my eyes ?\n",
            "T-7052\tVậy , cái gì đã khiê ́ n tôi thư ́ c ti <<unk>> nh ?\n",
            "H-7052\t-0.5829208493232727\tVậy điều gì đã mở mắt ra ?\n",
            "D-7052\t-0.5829208493232727\tVậy điều gì đã mở mắt ra ?\n",
            "P-7052\t-0.3958 -1.7292 -0.0443 -0.4623 -0.9059 -0.3689 -1.1760 -0.0543 -0.1096\n",
            "S-3554\tHe died broken by history .\n",
            "T-3554\tÔng qua đời , bị lịch sử quật ngã .\n",
            "H-3554\t-0.6461465954780579\tÔng mất bởi lịch sử .\n",
            "D-3554\t-0.6461465954780579\tÔng mất bởi lịch sử .\n",
            "P-3554\t-0.7795 -1.1353 -2.0139 -0.0041 -0.0790 -0.4072 -0.1040\n",
            "S-6558\tSo why does that matter ?\n",
            "T-6558\tTại sao điều này lại quan trọng ?\n",
            "H-6558\t-0.3766022324562073\tVậy tại sao điều đó lại quan trọng ?\n",
            "D-6558\t-0.3766022324562073\tVậy tại sao điều đó lại quan trọng ?\n",
            "P-6558\t-0.4888 -0.1436 -0.0462 -1.2340 -0.9130 -0.2859 -0.4578 -0.0324 -0.0612 -0.1031\n",
            "S-3699\tI never will forget it .\n",
            "T-3699\tVà tôi sẽ không bao giờ quên được .\n",
            "H-3699\t-0.28057944774627686\tTôi sẽ không bao giờ quên nó .\n",
            "D-3699\t-0.28057944774627686\tTôi sẽ không bao giờ quên nó .\n",
            "P-3699\t-0.1555 -0.7526 -0.1523 -0.0216 -0.0592 -0.0397 -0.9631 -0.2666 -0.1146\n",
            "S-3637\tHer mother raised her alone .\n",
            "T-3637\tMẹ của bà một mình nuôi bà lớn .\n",
            "H-3637\t-0.5199183821678162\tMẹ cô bé nuôi cô bé một mình .\n",
            "D-3637\t-0.5199183821678162\tMẹ cô bé nuôi cô bé một mình .\n",
            "P-3637\t-0.0733 -1.3795 -1.6254 -0.4997 -0.2766 -0.7108 -0.2308 -0.0035 -0.2966 -0.1029\n",
            "S-3284\tHere &apos;s the building working .\n",
            "T-3284\tĐây là cách kiến trúc này hoạt động .\n",
            "H-3284\t-0.3071146309375763\tĐây là toà nhà làm việc .\n",
            "D-3284\t-0.3071146309375763\tĐây là toà nhà làm việc .\n",
            "P-3284\t-0.2403 -0.1273 -0.1742 -0.0546 -1.5344 -0.0289 -0.1907 -0.1065\n",
            "S-3242\tYou saw the big peak .\n",
            "T-3242\tBạn thấy cái đỉnh to đấy rồi đó .\n",
            "H-3242\t-0.6019763350486755\tBạn thấy đỉnh cao lớn .\n",
            "D-3242\t-0.6019763350486755\tBạn thấy đỉnh cao lớn .\n",
            "P-3242\t-0.3270 -0.8537 -0.2175 -0.4688 -1.6396 -0.6064 -0.1009\n",
            "S-2838\tSome have come and gone .\n",
            "T-2838\tMột số loài xuất hiện và biến mất .\n",
            "H-2838\t-0.440064400434494\tMột số đã đến và biến mất .\n",
            "D-2838\t-0.440064400434494\tMột số đã đến và biến mất .\n",
            "P-2838\t-0.4244 -0.5654 -1.2514 -0.4252 -0.3015 -0.6313 -0.0108 -0.2498 -0.1009\n",
            "S-2804\tThat is a fantastic question .\n",
            "T-2804\tĐó thật là một câu hỏi thú vị .\n",
            "H-2804\t-0.2045135796070099\tĐó là một câu hỏi tuyệt vời .\n",
            "D-2804\t-0.2045135796070099\tĐó là một câu hỏi tuyệt vời .\n",
            "P-2804\t-0.2357 -0.2607 -0.2959 -0.0425 -0.0349 -0.6175 -0.0816 -0.1700 -0.1019\n",
            "S-2413\tI remember my first fire .\n",
            "T-2413\tTôi nhớ đám cháy đầu tiên của mình .\n",
            "H-2413\t-0.42875954508781433\tTôi nhớ ngọn lửa đầu tiên của mình .\n",
            "D-2413\t-0.42875954508781433\tTôi nhớ ngọn lửa đầu tiên của mình .\n",
            "P-2413\t-0.1194 -0.1734 -2.3628 -0.0010 -0.2081 -0.0418 -0.4511 -0.4804 -0.3463 -0.1034\n",
            "S-2278\tI see this plus sign .\n",
            "T-2278\tBạn có thể thấy bản chú thích này .\n",
            "H-2278\t-0.8377397656440735\tTôi thấy cái biển báo này .\n",
            "D-2278\t-0.8377397656440735\tTôi thấy cái biển báo này .\n",
            "P-2278\t-0.1377 -0.6583 -4.1839 -0.2833 -0.5498 -0.1067 -0.6813 -0.1009\n",
            "S-1941\tLet &apos;s call him Don .\n",
            "T-1941\tTa gọi tạm ông ấy là Don nhé .\n",
            "H-1941\t-0.43057316541671753\tHãy gọi anh ta là Don .\n",
            "D-1941\t-0.43057316541671753\tHãy gọi anh ta là Don .\n",
            "P-1941\t-0.3712 -0.1785 -1.2628 -0.4679 -0.1562 -0.4074 -0.4955 -0.1050\n",
            "S-1368\tTremendously exciting .\n",
            "T-1368\tMột sự hưng phấn tột cùng .\n",
            "H-1368\t-0.496045857667923\tTreo rất thú vị .\n",
            "D-1368\t-0.496045857667923\tTreo rất thú vị .\n",
            "P-1368\t-1.8009 -0.0250 -0.5515 -0.6810 -0.5550 -0.0181 -0.2398 -0.0971\n",
            "S-852\tAnd I tried something interesting .\n",
            "T-852\tTôi đã thử một điều thú vị khác .\n",
            "H-852\t-0.4882565140724182\tVà tôi đã thử một điều thú vị .\n",
            "D-852\t-0.4882565140724182\tVà tôi đã thử một điều thú vị .\n",
            "P-852\t-0.6199 -0.1295 -0.3868 -0.2778 -0.8215 -1.3708 -0.9034 -0.0337 -0.2343 -0.1049\n",
            "S-260\tLike that , you know .\n",
            "T-260\tBạn biết đấy , cũng giống như vậy .\n",
            "H-260\t-0.5957993268966675\tNhư vậy , bạn biết đấy .\n",
            "D-260\t-0.5957993268966675\tNhư vậy , bạn biết đấy .\n",
            "P-260\t-0.6331 -1.5544 -0.6971 -0.6226 -0.1711 -0.6538 -0.3350 -0.0993\n",
            "S-6734\tThere should be an understanding .\n",
            "T-6734\tSẽ cần có nhiều sự thấu hiểu .\n",
            "H-6734\t-0.6201173067092896\tPhải có một sự hiểu biết .\n",
            "D-6734\t-0.6201173067092896\tPhải có một sự hiểu biết .\n",
            "P-6734\t-2.1913 -0.2223 -0.6649 -0.6374 -0.3387 -0.0887 -0.7149 -0.1027\n",
            "S-6713\tMany are not so fortunate .\n",
            "T-6713\tNhiều người không may mắn như vậy .\n",
            "H-6713\t-0.3023264706134796\tRất nhiều người không may mắn .\n",
            "D-6713\t-0.3023264706134796\tRất nhiều người không may mắn .\n",
            "P-6713\t-0.7586 -0.0847 -0.1604 -0.2596 -0.1917 -0.1054 -0.7651 -0.0931\n",
            "S-6710\tThat was a powerful moment .\n",
            "T-6710\tNó là một khoảnh khắc kỳ diệu .\n",
            "H-6710\t-0.355913907289505\tĐó là một khoảnh khắc mạnh mẽ .\n",
            "D-6710\t-0.355913907289505\tĐó là một khoảnh khắc mạnh mẽ .\n",
            "P-6710\t-0.1659 -0.2659 -0.5110 -0.3366 -0.0891 -1.3156 -0.0682 -0.3473 -0.1037\n",
            "S-3706\tI will never forget it .\n",
            "T-3706\tTôi sẽ không bao giờ quên lời bà .\n",
            "H-3706\t-0.22189465165138245\tTôi sẽ không bao giờ quên nó .\n",
            "D-3706\t-0.22189465165138245\tTôi sẽ không bao giờ quên nó .\n",
            "P-3706\t-0.1693 -0.1898 -0.1521 -0.0198 -0.0603 -0.0360 -0.9989 -0.2551 -0.1158\n",
            "S-6027\tAnd here I am today .\n",
            "T-6027\tVà tôi ở đây ngày hôm nay .\n",
            "H-6027\t-0.6385642886161804\tVà tôi ở đây hôm nay .\n",
            "D-6027\t-0.6385642886161804\tVà tôi ở đây hôm nay .\n",
            "P-6027\t-0.3378 -1.6149 -2.3949 -0.0527 -0.2435 -0.0585 -0.3063 -0.0999\n",
            "S-5947\tThat &apos;s the whole idea .\n",
            "T-5947\tToàn bộ ý tưởng là thế mà .\n",
            "H-5947\t-0.19071538746356964\tĐó là toàn bộ ý tưởng .\n",
            "D-5947\t-0.19071538746356964\tĐó là toàn bộ ý tưởng .\n",
            "P-5947\t-0.2564 -0.3246 -0.4109 -0.0161 -0.0868 -0.1319 -0.1951 -0.1039\n",
            "S-5906\tAnd then somebody complained .\n",
            "T-5906\tRồi sau đó có người than phiền .\n",
            "H-5906\t-0.43782684206962585\tVà rồi một người phàn nàn .\n",
            "D-5906\t-0.43782684206962585\tVà rồi một người phàn nàn .\n",
            "P-5906\t-0.5463 -1.3247 -1.4028 -0.3416 -0.2859 -0.0010 -0.0037 -0.0067 -0.3548 -0.1106\n",
            "S-5453\tWere we being followed ?\n",
            "T-5453\tChúng tôi có bị theo dõi không ?\n",
            "H-5453\t-0.5356645584106445\tLiệu chúng ta có đang theo dõi ?\n",
            "D-5453\t-0.5356645584106445\tLiệu chúng ta có đang theo dõi ?\n",
            "P-5453\t-0.7336 -0.1982 -0.1647 -0.2579 -1.2062 -0.6376 -0.3201 -1.2027 -0.1001\n",
            "S-5244\tHa . He &apos;s ready .\n",
            "T-5244\tÀ . Anh ta đang sẵn sàng .\n",
            "H-5244\t-0.5534046292304993\tHa . Ông đã sẵn sàng .\n",
            "D-5244\t-0.5534046292304993\tHa . Ông đã sẵn sàng .\n",
            "P-5244\t-1.0598 -0.5864 -1.1745 -1.2597 -0.0446 -0.0053 -0.2009 -0.0961\n",
            "S-4707\tBut they do the job .\n",
            "T-4707\tNhưng chúng thực hiện được công việc .\n",
            "H-4707\t-0.4230193495750427\tNhưng họ làm công việc .\n",
            "D-4707\t-0.4230193495750427\tNhưng họ làm công việc .\n",
            "P-4707\t-0.2134 -0.4958 -0.6592 -0.6373 -0.0262 -0.8242 -0.1051\n",
            "S-4677\tThere are billions of them .\n",
            "T-4677\tBởi có hàng tỉ bóng bán dẫn .\n",
            "H-4677\t-0.5297175049781799\tCó hàng tỉ người .\n",
            "D-4677\t-0.5297175049781799\tCó hàng tỉ người .\n",
            "P-4677\t-0.2027 -0.0338 -0.8055 -1.4753 -0.5595 -0.1014\n",
            "S-4450\tAnd then it went international .\n",
            "T-4450\tvà sau đó nó mang tầm quốc tế\n",
            "H-4450\t-0.8111702799797058\tVà rồi nó chuyển sang quốc tế .\n",
            "D-4450\t-0.8111702799797058\tVà rồi nó chuyển sang quốc tế .\n",
            "P-4450\t-0.7236 -1.1539 -0.4484 -3.3337 -0.9309 -0.0387 -0.2128 -0.3596 -0.0990\n",
            "S-4448\tThere were remixes .\n",
            "T-4448\tCó cả những bản phối khí lại .\n",
            "H-4448\t-1.1494394540786743\tCó sự giao dịch .\n",
            "D-4448\t-1.1494394540786743\tCó sự giao dịch .\n",
            "P-4448\t-0.9785 -1.9464 -2.1610 -1.4200 -0.2909 -0.0998\n",
            "S-4295\tAnd the family gathered .\n",
            "T-4295\tVà cả gia đình tụ họp lại .\n",
            "H-4295\t-0.5074591636657715\tVà gia đình tập hợp lại .\n",
            "D-4295\t-0.5074591636657715\tVà gia đình tập hợp lại .\n",
            "P-4295\t-0.4083 -1.0473 -0.0363 -0.8976 -0.3178 -0.9801 -0.2645 -0.1077\n",
            "S-4238\tAnd I memorized everything .\n",
            "T-4238\tVà tôi thuộc làu mọi thứ .\n",
            "H-4238\t-0.2796769440174103\tVà tôi nhớ mọi thứ .\n",
            "D-4238\t-0.2796769440174103\tVà tôi nhớ mọi thứ .\n",
            "P-4238\t-0.8057 -0.1851 -0.0522 -0.4589 -0.1454 -0.2075 -0.1030\n",
            "S-4161\tOkay , a bit more .\n",
            "T-4161\tTốt rồi , nhiều hơn 1 chút .\n",
            "H-4161\t-0.7214660048484802\tĐược rồi , một chút nữa .\n",
            "D-4161\t-0.7214660048484802\tĐược rồi , một chút nữa .\n",
            "P-4161\t-1.4169 -0.3522 -0.2337 -2.4418 -0.2524 -0.6643 -0.3074 -0.1029\n",
            "S-3813\tI couldn &apos;t bear it .\n",
            "T-3813\tTôi không thể làm ngơ được .\n",
            "H-3813\t-0.45175233483314514\tTôi không thể chịu nổi .\n",
            "D-3813\t-0.45175233483314514\tTôi không thể chịu nổi .\n",
            "P-3813\t-0.1595 -0.2298 -0.1272 -0.0789 -1.5349 -0.9193 -0.1126\n",
            "S-3757\tIt &apos;s interesting to me .\n",
            "T-3757\tnhưng điều này lại khiến tôi quan tâm\n",
            "H-3757\t-0.65748131275177\tĐiều đó thật thú vị với tôi .\n",
            "D-3757\t-0.65748131275177\tĐiều đó thật thú vị với tôi .\n",
            "P-3757\t-2.3124 -1.2765 -0.8822 -0.3971 -0.0337 -0.5740 -0.1137 -0.2213 -0.1064\n",
            "S-3501\tSo where do we go ?\n",
            "T-3501\tNhư vậy chúng ta phải đi đâu ?\n",
            "H-3501\t-0.48069941997528076\tVậy chúng ta sẽ đi đâu ?\n",
            "D-3501\t-0.48069941997528076\tVậy chúng ta sẽ đi đâu ?\n",
            "P-3501\t-0.8337 -0.5564 -0.2832 -0.7548 -0.2729 -0.8911 -0.1595 -0.0940\n",
            "S-280\tAre you comfortable with that ?\n",
            "T-280\tBạn có cảm thấy thoải mái với nó không ?\n",
            "H-280\t-0.3590947091579437\tBạn có thoải mái với điều đó không ?\n",
            "D-280\t-0.3590947091579437\tBạn có thoải mái với điều đó không ?\n",
            "P-280\t-0.5811 -0.2012 -0.5747 -0.0141 -0.0722 -0.8831 -0.5439 -0.5433 -0.0778 -0.0994\n",
            "S-3234\tThe match begins -- silence .\n",
            "T-3234\tTrận đấu bắt đầu - mọi thứ im lặng .\n",
            "H-3234\t-0.6058593392372131\tCâu chuyện bắt đầu -- sự im lặng .\n",
            "D-3234\t-0.6058593392372131\tCâu chuyện bắt đầu -- sự im lặng .\n",
            "P-3234\t-3.7037 -0.1529 -0.7558 -0.1580 -0.5674 -0.2506 -0.0848 -0.0068 -0.2679 -0.1108\n",
            "S-2743\tThanks for you patience .\n",
            "T-2743\tRất cảm ơn vì anh đã kiên nhẫn giải thích .\n",
            "H-2743\t-0.3882961869239807\tXin cảm ơn vì sự kiên nhẫn .\n",
            "D-2743\t-0.3882961869239807\tXin cảm ơn vì sự kiên nhẫn .\n",
            "P-2743\t-0.3334 -0.7595 -0.0753 -0.8632 -0.6563 -0.0476 -0.2640 -0.4027 -0.0927\n",
            "S-2697\tI like really nice clothes .\n",
            "T-2697\tTôi rất ưa chuộng quần áo hợp thời trang .\n",
            "H-2697\t-0.5473005771636963\tTôi thích quần áo đẹp .\n",
            "D-2697\t-0.5473005771636963\tTôi thích quần áo đẹp .\n",
            "P-2697\t-0.2681 -0.9881 -1.3076 -0.0036 -0.9234 -0.2330 -0.1074\n",
            "S-7075\tI am not my father .\n",
            "T-7075\tTôi không pha <<unk>> i la <<unk>> cha tôi .\n",
            "H-7075\t-0.21533147990703583\tTôi không phải cha tôi .\n",
            "D-7075\t-0.21533147990703583\tTôi không phải cha tôi .\n",
            "P-7075\t-0.2673 -0.1624 -0.0331 -0.3554 -0.2949 -0.2918 -0.1025\n",
            "S-6797\tHe never made it there .\n",
            "T-6797\tNhưng thằng bé chẳng bao giờ đến đó được .\n",
            "H-6797\t-0.7265437841415405\tAnh ta không bao giờ làm được điều đó .\n",
            "D-6797\t-0.7265437841415405\tAnh ta không bao giờ làm được điều đó .\n",
            "P-6797\t-1.2698 -1.0045 -0.6254 -0.2044 -0.0650 -0.5382 -2.0688 -1.2951 -0.3605 -0.4459 -0.1144\n",
            "S-6497\tYou are speaking your truth .\n",
            "T-6497\tBạn đang nói về sự thật của bản thân .\n",
            "H-6497\t-0.47680482268333435\tBạn đang nói về sự thật .\n",
            "D-6497\t-0.47680482268333435\tBạn đang nói về sự thật .\n",
            "P-6497\t-0.4801 -0.1701 -0.0971 -1.0032 -0.0276 -0.0830 -1.8495 -0.1040\n",
            "S-5834\tNo expensive staff time required .\n",
            "T-5834\tKhông tốn thời giờ vàng bạc của nhân viên .\n",
            "H-5834\t-0.7820360660552979\tKhông có thời gian tốn kém lắm .\n",
            "D-5834\t-0.7820360660552979\tKhông có thời gian tốn kém lắm .\n",
            "P-5834\t-0.2339 -1.2786 -1.1350 -0.0603 -1.4721 -0.2667 -1.9459 -0.5470 -0.0989\n",
            "S-5202\tDon &apos;t they sound incredible ?\n",
            "T-5202\tNhững chuyện này nghe thật tuyệt vời phải không ?\n",
            "H-5202\t-1.0513114929199219\tĐừng tin được những âm thanh tuyệt vời ?\n",
            "D-5202\t-1.0513114929199219\tĐừng tin được những âm thanh tuyệt vời ?\n",
            "P-5202\t-0.7377 -2.8671 -1.1238 -2.9490 -0.4418 -0.0137 -1.7337 -0.1081 -0.4402 -0.0980\n",
            "S-5099\tAnd I was very proud .\n",
            "T-5099\tTôi đã rất tự hào về đất nước tôi .\n",
            "H-5099\t-0.3017847537994385\tVà tôi rất tự hào .\n",
            "D-5099\t-0.3017847537994385\tVà tôi rất tự hào .\n",
            "P-5099\t-0.6202 -0.1678 -0.8591 -0.0685 -0.0392 -0.2548 -0.1029\n",
            "S-4835\tHave you seen these guys ?\n",
            "T-4835\tBạn đã bao giờ thấy những con người này ?\n",
            "H-4835\t-0.43329158425331116\tBạn đã bao giờ thấy những người này chưa ?\n",
            "D-4835\t-0.43329158425331116\tBạn đã bao giờ thấy những người này chưa ?\n",
            "P-4835\t-0.2226 -0.1370 -0.7569 -0.0429 -0.9065 -0.3492 -1.3373 -0.3084 -0.5642 -0.0434 -0.0979\n",
            "S-4818\tIt connected those two people .\n",
            "T-4818\tNó kết nối hai người đó lại với nhau .\n",
            "H-4818\t-0.5517958998680115\tNó kết nối hai người đó .\n",
            "D-4818\t-0.5517958998680115\tNó kết nối hai người đó .\n",
            "P-4818\t-0.5954 -0.9096 -0.0411 -0.5324 -0.2392 -1.2020 -0.7903 -0.1043\n",
            "S-4213\tThree times out of 10 .\n",
            "T-4213\tCứ 10 lần thì có 3 lần như vậy .\n",
            "H-4213\t-0.6294253468513489\tGấp ba lần 10 lần .\n",
            "D-4213\t-0.6294253468513489\tGấp ba lần 10 lần .\n",
            "P-4213\t-1.9994 -0.0178 -0.3597 -0.0319 -2.0814 -0.0313 -0.4046 -0.1093\n",
            "S-3238\tFirst overtime , second .\n",
            "T-3238\tHiệp phụ thứ nhất , hiệp phụ thứ hai .\n",
            "H-3238\t-0.8272000551223755\tLần đầu tiên , điều thứ hai .\n",
            "D-3238\t-0.8272000551223755\tLần đầu tiên , điều thứ hai .\n",
            "P-3238\t-0.8803 -0.3570 -0.0866 -0.6630 -4.1597 -0.1798 -0.1322 -0.8837 -0.1026\n",
            "S-2653\tThat &apos;s very risky .\n",
            "T-2653\tHành động đó thật sự rất kinh dị .\n",
            "H-2653\t-0.6992034316062927\tĐiều đó rất mạo hiểm .\n",
            "D-2653\t-0.6992034316062927\tĐiều đó rất mạo hiểm .\n",
            "P-2653\t-1.8164 -0.7850 -0.9584 -0.9993 -0.0033 -0.2390 -0.0929\n",
            "S-323\tCan we do this differently ?\n",
            "T-323\tChúng ta có làm gì khác đi được không ?\n",
            "H-323\t-0.3941574990749359\tChúng ta có thể làm khác đi được không ?\n",
            "D-323\t-0.3941574990749359\tChúng ta có thể làm khác đi được không ?\n",
            "P-323\t-0.8348 -0.0802 -0.2702 -0.0944 -0.1083 -0.6901 -0.2959 -1.4749 -0.3106 -0.0794 -0.0970\n",
            "S-3337\tYou can enter inside it .\n",
            "T-3337\tBạn có thể bước vào bên trong .\n",
            "H-3337\t-0.38242262601852417\tBạn có thể bước vào bên trong nó .\n",
            "D-3337\t-0.38242262601852417\tBạn có thể bước vào bên trong nó .\n",
            "P-3337\t-0.2014 -0.1840 -0.0998 -1.0430 -0.0474 -0.7833 -0.0329 -1.0691 -0.2557 -0.1075\n",
            "S-7070\tWell , that &apos;s simple .\n",
            "T-7070\tRâ ́ t đơn gia <<unk>> n ,\n",
            "H-7070\t-0.6451778411865234\tVâng , thật đơn giản .\n",
            "D-7070\t-0.6451778411865234\tVâng , thật đơn giản .\n",
            "P-7070\t-1.7257 -0.1648 -2.2072 -0.0549 -0.0333 -0.2228 -0.1075\n",
            "S-6960\tIt was all very normal .\n",
            "T-6960\tTất cả đều rất đỗi bình thường .\n",
            "H-6960\t-0.45207372307777405\tTất cả đều bình thường .\n",
            "D-6960\t-0.45207372307777405\tTất cả đều bình thường .\n",
            "P-6960\t-1.5806 -0.0531 -0.5059 -0.6607 -0.0309 -0.2319 -0.1014\n",
            "S-6936\tThe ball comes off track .\n",
            "T-6936\tQuả bóng văng ra khỏi sân .\n",
            "H-6936\t-0.8404335379600525\tQuả bóng chạy ra theo dõi .\n",
            "D-6936\t-0.8404335379600525\tQuả bóng chạy ra theo dõi .\n",
            "P-6936\t-0.7529 -1.3692 -0.5703 -2.4139 -0.1571 -0.4363 -1.2012 -0.5637 -0.0992\n",
            "S-6880\tFans want that experience .\n",
            "T-6880\tNgười hâm mộ muốn trải nghiệm đó .\n",
            "H-6880\t-0.34562933444976807\tNhững người Fans muốn trải nghiệm đó .\n",
            "D-6880\t-0.34562933444976807\tNhững người Fans muốn trải nghiệm đó .\n",
            "P-6880\t-0.9929 -0.2760 -0.6325 -0.4657 -0.2563 -0.1176 -0.1002 -0.3101 -0.2041 -0.1011\n",
            "S-6003\tSo I had an idea .\n",
            "T-6003\tVì thế tôi đã có một ý tưởng .\n",
            "H-6003\t-0.6048229932785034\tVì vậy tôi có một ý tưởng .\n",
            "D-6003\t-0.6048229932785034\tVì vậy tôi có một ý tưởng .\n",
            "P-6003\t-2.1388 -0.9048 -0.4545 -0.7750 -0.4118 -0.1273 -0.1558 -0.3760 -0.0994\n",
            "S-5647\tWhat is it , then ?\n",
            "T-5647\tVậy cuối cùng nó đã giúp ích gì ?\n",
            "H-5647\t-0.8273281455039978\tVậy nó là gì ?\n",
            "D-5647\t-0.8273281455039978\tVậy nó là gì ?\n",
            "P-5647\t-1.7767 -1.4276 -0.2159 -0.0767 -1.3736 -0.0935\n",
            "S-5358\tSo I broke the silence .\n",
            "T-5358\tVì vậy tôi phát vỡ sự yên lặng .\n",
            "H-5358\t-0.5702747702598572\tVì vậy tôi đã phá vỡ sự im lặng .\n",
            "D-5358\t-0.5702747702598572\tVì vậy tôi đã phá vỡ sự im lặng .\n",
            "P-5358\t-1.7356 -0.8593 -0.6836 -1.5173 -0.8201 -0.0293 -0.2684 -0.0207 -0.0018 -0.2269 -0.1100\n",
            "S-5303\tHe told me two things .\n",
            "T-5303\tAnh ta kể với tôi về hai thứ .\n",
            "H-5303\t-0.5820720791816711\tÔng nói với tôi hai điều .\n",
            "D-5303\t-0.5820720791816711\tÔng nói với tôi hai điều .\n",
            "P-5303\t-1.1677 -1.5473 -0.2060 -0.1036 -0.6251 -0.6878 -0.2175 -0.1016\n",
            "S-5136\tThese girls were so lucky .\n",
            "T-5136\tnhững cô gái này đã rất may mắn .\n",
            "H-5136\t-0.3395477533340454\tNhững cô gái này thật may mắn .\n",
            "D-5136\t-0.3395477533340454\tNhững cô gái này thật may mắn .\n",
            "P-5136\t-0.2614 -0.4776 -0.5290 -0.3240 -0.9047 -0.1058 -0.0078 -0.3476 -0.0982\n",
            "S-4908\tOr is it photography ?\n",
            "T-4908\tNó có phải là nhiếp ảnh không nhỉ ?\n",
            "H-4908\t-0.48232653737068176\tHay đó là nhiếp ảnh ?\n",
            "D-4908\t-0.48232653737068176\tHay đó là nhiếp ảnh ?\n",
            "P-4908\t-0.7758 -1.2364 -0.4526 -0.6711 -0.0045 -0.1239 -0.1119\n",
            "S-4849\tThey &apos;re using their hands .\n",
            "T-4849\tHọ sử dụng đôi bàn tay của mình .\n",
            "H-4849\t-0.6927881836891174\tHọ sử dụng đôi tay của mình .\n",
            "D-4849\t-0.6927881836891174\tHọ sử dụng đôi tay của mình .\n",
            "P-4849\t-0.6489 -3.2640 -0.0566 -0.6452 -0.0246 -0.5558 -0.7029 -0.2355 -0.1017\n",
            "S-4406\tSo how does it happen ?\n",
            "T-4406\tVậy điều này xảy đến như thế nào ?\n",
            "H-4406\t-0.4890742003917694\tVậy điều đó xảy ra như thế nào ?\n",
            "D-4406\t-0.4890742003917694\tVậy điều đó xảy ra như thế nào ?\n",
            "P-4406\t-0.6520 -2.0166 -0.6075 -0.7269 -0.0764 -0.4080 -0.0836 -0.0721 -0.1454 -0.1021\n",
            "S-4026\tYou always lose rare animals .\n",
            "T-4026\tBạn chỉ mất đi những động vật quý hiếm\n",
            "H-4026\t-0.5745437145233154\tBạn luôn mất động vật hiếm .\n",
            "D-4026\t-0.5745437145233154\tBạn luôn mất động vật hiếm .\n",
            "P-4026\t-0.6901 -0.2545 -1.3234 -1.0149 -0.0069 -0.8863 -0.3187 -0.1015\n",
            "S-3965\tHe was actually collecting fish .\n",
            "T-3965\tThực ra Ông thu thập các loại cá .\n",
            "H-3965\t-0.8034281134605408\tAnh ấy đang thu thập cá .\n",
            "D-3965\t-0.8034281134605408\tAnh ấy đang thu thập cá .\n",
            "P-3965\t-1.7498 -1.2217 -1.6682 -0.4519 -0.8002 -0.1742 -0.2635 -0.0980\n",
            "S-3879\tI sometimes push too hard .\n",
            "T-3879\tThỉnh thoảng khi tôi cố quá sức ,\n",
            "H-3879\t-0.8587173819541931\tĐôi khi tôi đẩy quá sức mạnh .\n",
            "D-3879\t-0.8587173819541931\tĐôi khi tôi đẩy quá sức mạnh .\n",
            "P-3879\t-0.2445 -0.2637 -0.1745 -2.8408 -0.0112 -3.1019 -0.6604 -0.3317 -0.0997\n",
            "  7% 4/60 [00:06<01:38,  1.76s/it, wps=535]S-6017\tOne of them was this grandmother .\n",
            "T-6017\tMột trong số đó là người bà này .\n",
            "H-6017\t-0.3925623595714569\tMột trong số đó là bà ấy .\n",
            "D-6017\t-0.3925623595714569\tMột trong số đó là bà ấy .\n",
            "P-6017\t-0.1021 -0.3063 -0.0756 -0.1766 -0.1494 -0.0852 -2.3012 -0.2338 -0.1028\n",
            "S-7372\tDwarves became columns .\n",
            "T-7372\tNhững chú lùn trở thành cột chống .\n",
            "H-7372\t-0.990490734577179\tPhân tử trở thành cột .\n",
            "D-7372\t-0.990490734577179\tPhân tử trở thành cột .\n",
            "P-7372\t-3.0024 -1.5782 -1.7136 -0.0974 -0.4995 -0.6384 -0.2948 -0.0995\n",
            "S-7286\tIt &apos;s not enough by itself .\n",
            "T-7286\tViệc giải phóng tiềm năng là chưa đủ .\n",
            "H-7286\t-0.7843469977378845\tNó chưa đủ bằng chính bản thân mình .\n",
            "D-7286\t-0.7843469977378845\tNó chưa đủ bằng chính bản thân mình .\n",
            "P-7286\t-1.4390 -0.9126 -0.0593 -2.4279 -0.0290 -0.9553 -0.0326 -1.6161 -0.2684 -0.1032\n",
            "S-7284\tBut how do we do that ?\n",
            "T-7284\tChúng ta làm điều đó như thế nào ?\n",
            "H-7284\t-0.4695151150226593\tNhưng làm thế nào chúng ta làm được điều đó ?\n",
            "D-7284\t-0.4695151150226593\tNhưng làm thế nào chúng ta làm được điều đó ?\n",
            "P-7284\t-0.2784 -0.5197 -1.4257 -0.0655 -1.1594 -0.3326 -0.5897 -0.3251 -0.4880 -0.2528 -0.0954 -0.1020\n",
            "S-7247\tThere &apos;s simply no privacy .\n",
            "T-7247\tĐơn giản là không có sự riêng tư .\n",
            "H-7247\t-0.3251796364784241\tĐơn giản là không có sự riêng tư .\n",
            "D-7247\t-0.3251796364784241\tĐơn giản là không có sự riêng tư .\n",
            "P-7247\t-0.7210 -0.0322 -0.2999 -0.2375 -0.1274 -0.9267 -0.0008 -0.0018 -0.8013 -0.1032\n",
            "S-7232\tShe absolutely loves her reflection .\n",
            "T-7232\tNó rất thích ảnh phản chiếu của mình .\n",
            "H-7232\t-0.4187953770160675\tCô ấy hoàn toàn thích sự phản chiếu của mình .\n",
            "D-7232\t-0.4187953770160675\tCô ấy hoàn toàn thích sự phản chiếu của mình .\n",
            "P-7232\t-0.5468 -1.0985 -0.6004 -0.0272 -0.5278 -0.5226 -0.0311 -0.4472 -0.2697 -0.2786 -0.5840 -0.0917\n",
            "S-7011\tAnd I know why it happens .\n",
            "T-7011\tVà tôi biết vì sao nó xảy ra .\n",
            "H-7011\t-0.3721449673175812\tVà tôi biết tại sao nó xảy ra .\n",
            "D-7011\t-0.3721449673175812\tVà tôi biết tại sao nó xảy ra .\n",
            "P-7011\t-0.6228 -0.1347 -0.3757 -0.4311 -0.0530 -0.9663 -0.5671 -0.0832 -0.3886 -0.0991\n",
            "S-7000\tWe do overcome some things .\n",
            "T-7000\tChúng tôi phải vượt qua một vài điều .\n",
            "H-7000\t-0.6769450902938843\tChúng ta làm quá nhiều thứ .\n",
            "D-7000\t-0.6769450902938843\tChúng ta làm quá nhiều thứ .\n",
            "P-7000\t-0.2058 -0.6141 -1.6256 -1.1065 -0.3353 -1.1452 -0.2823 -0.1009\n",
            "S-6850\tSuicide is preventable .\n",
            "T-6850\tTự sát là có thể ngăn chặn được .\n",
            "H-6850\t-1.02609384059906\tToà án được ngăn ngừa .\n",
            "D-6850\t-1.02609384059906\tToà án được ngăn ngừa .\n",
            "P-6850\t-0.9629 -1.8710 -1.3239 -1.9618 -0.9308 -0.4662 -0.5938 -0.0985\n",
            "S-6779\tWould you know what to say ?\n",
            "T-6779\tBạn biết mình cần phải nói gì không ?\n",
            "H-6779\t-0.2915768325328827\tBạn có biết phải nói gì không ?\n",
            "D-6779\t-0.2915768325328827\tBạn có biết phải nói gì không ?\n",
            "P-6779\t-0.5646 -0.2115 -0.0709 -1.0199 -0.2239 -0.1764 -0.1451 -0.1099 -0.1018\n",
            "S-6632\tIt was called Talibanization .\n",
            "T-6632\tNó được gọi là taliban hoá .\n",
            "H-6632\t-0.8150777220726013\tNó được gọi là thảm hoạ .\n",
            "D-6632\t-0.8150777220726013\tNó được gọi là thảm hoạ .\n",
            "P-6632\t-0.5314 -0.1591 -0.0668 -0.1270 -4.5932 -0.4112 -0.5356 -0.0963\n",
            "S-6613\tYes , I must mention it .\n",
            "T-6613\tCó , tôi phải đề cập đến nó .\n",
            "H-6613\t-0.5797310471534729\tVâng , tôi phải đề cập đến nó .\n",
            "D-6613\t-0.5797310471534729\tVâng , tôi phải đề cập đến nó .\n",
            "P-6613\t-1.1408 -0.1378 -0.3137 -0.1598 -1.5491 -0.0191 -0.8831 -1.2359 -0.2514 -0.1067\n",
            "S-6602\tAnd what happens at the end ?\n",
            "T-6602\tVà những gì cuối cùng sẽ xảy ra ?\n",
            "H-6602\t-0.6471824049949646\tVà điều gì sẽ xảy ra ở cuối ?\n",
            "D-6602\t-0.6471824049949646\tVà điều gì sẽ xảy ra ở cuối ?\n",
            "P-6602\t-0.6754 -0.9616 -0.1172 -1.3924 -0.1206 -0.1288 -2.1348 -0.3977 -0.4436 -0.0997\n",
            "S-6095\tLet me tell you a secret .\n",
            "T-6095\tĐể tôi nói bạn biết một bí mật .\n",
            "H-6095\t-0.48319846391677856\tĐể tôi nói cho các bạn một bí mật .\n",
            "D-6095\t-0.48319846391677856\tĐể tôi nói cho các bạn một bí mật .\n",
            "P-6095\t-0.2366 -0.0990 -0.8665 -0.9215 -1.2215 -0.0782 -1.1776 -0.0299 -0.0385 -0.5509 -0.0949\n",
            "S-6068\tJust go and read her book .\n",
            "T-6068\thãy tìm đọc cuốn sách của bà ấy .\n",
            "H-6068\t-0.6249606609344482\tHãy đọc cuốn sách của cô ấy .\n",
            "D-6068\t-0.6249606609344482\tHãy đọc cuốn sách của cô ấy .\n",
            "P-6068\t-0.4172 -1.2742 -0.9891 -0.0841 -0.1132 -0.7517 -1.6164 -0.2730 -0.1058\n",
            "S-6065\tThe book was published in 2009 .\n",
            "T-6065\tCuốn sách được phát hành năm 2009 .\n",
            "H-6065\t-0.193750262260437\tCuốn sách được xuất bản năm 2009 .\n",
            "D-6065\t-0.193750262260437\tCuốn sách được xuất bản năm 2009 .\n",
            "P-6065\t-0.4114 -0.0106 -0.0277 -0.5995 -0.0201 -0.0045 -0.3991 -0.0153 -0.3460 -0.1033\n",
            "S-7423\tThat &apos;s ammunition .\n",
            "T-7423\tĐó là nguồn cung ý tưởng cho họ .\n",
            "H-7423\t-0.6862694025039673\tĐó là sự đoàn kết .\n",
            "D-7423\t-0.6862694025039673\tĐó là sự đoàn kết .\n",
            "P-7423\t-0.2422 -0.2012 -1.0841 -2.8926 -0.0748 -0.1997 -0.1092\n",
            "S-5657\tThat &apos;s the real zipper .\n",
            "T-5657\tĐó mới là cái khoá kéo thật sự .\n",
            "H-5657\t-0.857962429523468\tĐó là loài báo thực sự .\n",
            "D-5657\t-0.857962429523468\tĐó là loài báo thực sự .\n",
            "P-5657\t-0.4228 -0.3789 -3.3383 -0.2533 -1.8767 -0.2818 -0.2075 -0.1043\n",
            "S-5567\tYou can see all of this .\n",
            "T-5567\tBạn có thể thấy tất cả điều đó .\n",
            "H-5567\t-0.398384690284729\tBạn có thể thấy tất cả những thứ này .\n",
            "D-5567\t-0.398384690284729\tBạn có thể thấy tất cả những thứ này .\n",
            "P-5567\t-0.5889 -0.1335 -0.0823 -0.3976 -0.9893 -0.0475 -0.4838 -0.9449 -0.3554 -0.2583 -0.1007\n",
            "S-5454\tDo they know where we live ?\n",
            "T-5454\tHọ có biết chỗ chúng tôi ở không ?\n",
            "H-5454\t-0.30130210518836975\tHọ có biết chúng ta sống ở đâu không ?\n",
            "D-5454\t-0.30130210518836975\tHọ có biết chúng ta sống ở đâu không ?\n",
            "P-5454\t-0.7479 -0.1766 -0.0540 -0.2839 -0.3855 -0.8695 -0.0663 -0.0372 -0.5199 -0.0732 -0.1001\n",
            "S-5389\tAnd I &apos;ll tell you why .\n",
            "T-5389\tTôi sẽ nói cho bạn biết tại sao .\n",
            "H-5389\t-0.4922265410423279\tVà tôi sẽ giải thích tại sao .\n",
            "D-5389\t-0.4922265410423279\tVà tôi sẽ giải thích tại sao .\n",
            "P-5389\t-0.7462 -0.1581 -0.1940 -1.5377 -0.0166 -1.3785 -0.0578 -0.2402 -0.1011\n",
            "S-5287\tIt may even be your story .\n",
            "T-5287\tĐây có thể là câu chuyện của bạn .\n",
            "H-5287\t-0.48107007145881653\tNó thậm chí là câu chuyện của bạn .\n",
            "D-5287\t-0.48107007145881653\tNó thậm chí là câu chuyện của bạn .\n",
            "P-5287\t-1.8523 -0.9830 -0.0438 -0.6299 -0.2029 -0.0863 -0.1661 -0.4010 -0.3389 -0.1065\n",
            "S-5203\tBut most people don &apos;t agree .\n",
            "T-5203\tNhưng hầu hết mọi người không đồng ý .\n",
            "H-5203\t-0.15719065070152283\tNhưng hầu hết mọi người không đồng ý .\n",
            "D-5203\t-0.15719065070152283\tNhưng hầu hết mọi người không đồng ý .\n",
            "P-5203\t-0.2382 -0.2954 -0.0622 -0.0660 -0.0866 -0.2652 -0.0140 -0.2276 -0.2094 -0.1073\n",
            "S-5091\tPrivacy is implied .\n",
            "T-5091\tQuyền riêng tư phải được đảm bảo .\n",
            "H-5091\t-0.9290335178375244\tQuyền riêng tư được coi trọng .\n",
            "D-5091\t-0.9290335178375244\tQuyền riêng tư được coi trọng .\n",
            "P-5091\t-0.6326 -0.3107 -0.4396 -0.3697 -3.7182 -1.6001 -0.9426 -0.2464 -0.1013\n",
            "S-4928\tSometimes the perspective is the illusion .\n",
            "T-4928\tĐôi khi phối cảnh tạo nên ảo giác .\n",
            "H-4928\t-0.4440367519855499\tĐôi khi quan điểm là ảo tưởng .\n",
            "D-4928\t-0.4440367519855499\tĐôi khi quan điểm là ảo tưởng .\n",
            "P-4928\t-0.5668 -0.3271 -0.8496 -0.0238 -0.9641 -0.0131 -0.7650 -0.3794 -0.1073\n",
            "S-4501\tThey stopped us from being inspired .\n",
            "T-4501\tChúng ngăn trở những cảm hứng sáng tạo .\n",
            "H-4501\t-0.7775458693504333\tChúng ngăn chúng ta khỏi việc bị truyền cảm hứng .\n",
            "D-4501\t-0.7775458693504333\tChúng ngăn chúng ta khỏi việc bị truyền cảm hứng .\n",
            "P-4501\t-2.1612 -1.0883 -0.6964 -0.8504 -1.4238 -0.7332 -1.2202 -0.4630 -0.0249 -0.0070 -0.5650 -0.0971\n",
            "S-4493\tAnd this made me really sad .\n",
            "T-4493\tVà điều này khiến tôi buồn vô cùng .\n",
            "H-4493\t-0.6195935606956482\tVà điều này làm tôi thật buồn .\n",
            "D-4493\t-0.6195935606956482\tVà điều này làm tôi thật buồn .\n",
            "P-4493\t-1.1391 -0.3479 -0.3714 -0.5695 -0.1417 -1.5716 -0.4048 -0.9224 -0.1079\n",
            "S-4484\tOkay . Thank you very much .\n",
            "T-4484\tĐược rồi . Xin cám ơn rất nhiều .\n",
            "H-4484\t-0.43241506814956665\tĐược rồi . Xin cảm ơn .\n",
            "D-4484\t-0.43241506814956665\tĐược rồi . Xin cảm ơn .\n",
            "P-4484\t-1.2393 -0.5332 -0.1974 -0.2212 -0.4628 -0.0889 -0.6182 -0.0983\n",
            "S-4430\tSo what happened on this day ?\n",
            "T-4430\tVậy điều gì xảy ra vào ngày này ?\n",
            "H-4430\t-0.5259738564491272\tVậy điều gì đã xảy ra vào ngày hôm nay ?\n",
            "D-4430\t-0.5259738564491272\tVậy điều gì đã xảy ra vào ngày hôm nay ?\n",
            "P-4430\t-1.3442 -1.0118 -0.0511 -0.6103 -0.3309 -0.0894 -1.4677 -0.0717 -0.9743 -0.2042 -0.0559 -0.1002\n",
            "S-4284\tWell she was back all right .\n",
            "T-4284\tỒ được rồi , bà phải quay lại .\n",
            "H-4284\t-0.8459821343421936\tCô ấy trở lại đúng .\n",
            "D-4284\t-0.8459821343421936\tCô ấy trở lại đúng .\n",
            "P-4284\t-2.3504 -0.5659 -1.6392 -0.4519 -0.2883 -0.5296 -0.0967\n",
            "S-4206\tAnd there &apos;s hundreds of them .\n",
            "T-4206\tVà có hàng trăm con số như thế .\n",
            "H-4206\t-0.7119380831718445\tVà có hàng trăm trong số đó .\n",
            "D-4206\t-0.7119380831718445\tVà có hàng trăm trong số đó .\n",
            "P-4206\t-0.5500 -0.6723 -0.0731 -0.0334 -4.0359 -0.2521 -0.5357 -0.1542 -0.1009\n",
            "S-4123\tThey &apos;re all important choices . &quot;\n",
            "T-4123\tTất cả đều là sự lựa chọn quan trọng\n",
            "H-4123\t-0.3782058358192444\tChúng đều là những sự lựa chọn quan trọng . &quot;\n",
            "D-4123\t-0.3782058358192444\tChúng đều là những sự lựa chọn quan trọng . &quot;\n",
            "P-4123\t-0.9040 -0.2504 -0.4091 -0.8237 -1.2555 -0.0325 -0.0856 -0.1335 -0.0791 -0.3144 -0.1597 -0.0908\n",
            "S-3980\tThis was my first sunburn .\n",
            "T-3980\tĐây là vết rám nắng đầu tiên của tôi\n",
            "H-3980\t-0.18478910624980927\tĐây là mặt trời đầu tiên của tôi .\n",
            "D-3980\t-0.18478910624980927\tĐây là mặt trời đầu tiên của tôi .\n",
            "P-3980\t-0.3204 -0.1620 -0.5253 -0.0559 -0.0791 -0.0494 -0.1786 -0.1066 -0.2646 -0.1061\n",
            "S-137\tTalk about getting by with nothing .\n",
            "T-137\tVà đi khỏi mà không cần mang theo thứ gì .\n",
            "H-137\t-0.5583557486534119\tNói về việc không có gì .\n",
            "D-137\t-0.5583557486534119\tNói về việc không có gì .\n",
            "P-137\t-0.1412 -0.1974 -0.0390 -0.9173 -0.9925 -0.1346 -1.9443 -0.1007\n",
            "S-6835\tThis is what suicide does .\n",
            "T-6835\tĐó chính là những gì tự sát gây ra .\n",
            "H-6835\t-0.48577970266342163\tĐây là những gì tự tử làm .\n",
            "D-6835\t-0.48577970266342163\tĐây là những gì tự tử làm .\n",
            "P-6835\t-0.7883 -0.2332 -1.3742 -0.1094 -0.1295 -0.6386 -0.7803 -0.2171 -0.1015\n",
            "S-6649\tYou stood for the right cause .\n",
            "T-6649\tAnh đã đứng lên vì những điều đúng đắn .\n",
            "H-6649\t-0.6089589595794678\tBạn đứng về nguyên nhân đúng đắn .\n",
            "D-6649\t-0.6089589595794678\tBạn đứng về nguyên nhân đúng đắn .\n",
            "P-6649\t-0.3497 -0.5389 -2.1236 -1.1653 -0.0646 -0.5095 -0.4114 -0.2127 -0.1050\n",
            "S-6568\tYou think the Internet was big .\n",
            "T-6568\tBạn cho rằng Internet là vô cùng rộng lớn .\n",
            "H-6568\t-0.8133701682090759\tBạn nghĩ Internet rất lớn .\n",
            "D-6568\t-0.8133701682090759\tBạn nghĩ Internet rất lớn .\n",
            "P-6568\t-0.2449 -0.3025 -0.7829 -2.7380 -1.2350 -0.2928 -0.0975\n",
            "S-6436\tI would have that hard conversation .\n",
            "T-6436\tĐó là cuộc trò chuyện khó nói của tôi .\n",
            "H-6436\t-0.5387590527534485\tTôi có một cuộc trò chuyện khó khăn đó .\n",
            "D-6436\t-0.5387590527534485\tTôi có một cuộc trò chuyện khó khăn đó .\n",
            "P-6436\t-0.2524 -1.1680 -1.1323 -0.1337 -0.9876 -0.0602 -0.2528 -0.8216 -0.8023 -0.2150 -0.1003\n",
            "S-6151\tThis person has never been born .\n",
            "T-6151\tNhân vật này chưa bao giờ được sinh ra .\n",
            "H-6151\t-0.18113180994987488\tNgười này chưa bao giờ được sinh ra .\n",
            "D-6151\t-0.18113180994987488\tNgười này chưa bao giờ được sinh ra .\n",
            "P-6151\t-0.1866 -0.2559 -0.1555 -0.4715 -0.0488 -0.2576 -0.0156 -0.0209 -0.2959 -0.1031\n",
            "S-6098\tSo planning has this blind spot .\n",
            "T-6098\tVậy nên hoạch định có một điểm mù này .\n",
            "H-6098\t-0.6454866528511047\tVậy nên kế hoạch này có điểm mù .\n",
            "D-6098\t-0.6454866528511047\tVậy nên kế hoạch này có điểm mù .\n",
            "P-6098\t-1.5638 -0.6210 -0.9470 -0.0062 -0.8172 -0.4914 -0.2939 -0.1746 -1.4479 -0.0920\n",
            "S-6088\tYou can give somebody an idea .\n",
            "T-6088\tBạn có thể cho ai đó một ý tưởng .\n",
            "H-6088\t-0.4083331227302551\tBạn có thể cho ai đó một ý tưởng .\n",
            "D-6088\t-0.4083331227302551\tBạn có thể cho ai đó một ý tưởng .\n",
            "P-6088\t-0.3374 -0.1842 -0.0938 -1.5912 -1.0007 -0.0688 -0.4351 -0.1857 -0.1540 -0.3423 -0.0984\n",
            "S-5918\tThat &apos;s 20 Central Parks .\n",
            "T-5918\tTương đương với 20 lần Công viên trung tâm ,\n",
            "H-5918\t-0.7450640797615051\tĐó là 20 Đảng Trung Quốc .\n",
            "D-5918\t-0.7450640797615051\tĐó là 20 Đảng Trung Quốc .\n",
            "P-5918\t-2.5629 -0.1393 -0.0141 -1.6531 -0.3137 -0.7483 -0.8910 -0.2875 -0.0957\n",
            "S-5562\tIt &apos;s about all of us .\n",
            "T-5562\tNó là thông tin về tất cả chúng ta .\n",
            "H-5562\t-0.3859885334968567\tĐó là về tất cả chúng ta .\n",
            "D-5562\t-0.3859885334968567\tĐó là về tất cả chúng ta .\n",
            "P-5562\t-1.9628 -0.2154 -0.4756 -0.2821 -0.0398 -0.1058 -0.0899 -0.1991 -0.1034\n",
            "S-5552\tI want to make them public .\n",
            "T-5552\tTôi muốn nó được biết đến bởi công chúng .\n",
            "H-5552\t-0.47726383805274963\tTôi muốn làm cho họ công chúng .\n",
            "D-5552\t-0.47726383805274963\tTôi muốn làm cho họ công chúng .\n",
            "P-5552\t-0.1908 -0.0758 -1.4271 -1.0271 -0.7333 -0.1048 -0.3807 -0.2570 -0.0990\n",
            "S-4926\tIs it something about the light ?\n",
            "T-4926\tCó phải một chút gì đó về ánh sáng ?\n",
            "H-4926\t-0.6921641826629639\tNó có phải là về ánh sáng không ?\n",
            "D-4926\t-0.6921641826629639\tNó có phải là về ánh sáng không ?\n",
            "P-4926\t-2.3268 -0.1843 -0.6499 -0.7136 -1.7803 -0.0557 -0.0259 -0.9436 -0.1364 -0.1051\n",
            "S-4332\tAnd fortunately he didn &apos;t die .\n",
            "T-4332\tVà may mắn là anh bệnh nhân không chết .\n",
            "H-4332\t-0.5235177278518677\tVà may mắn thay anh ta không chết .\n",
            "D-4332\t-0.5235177278518677\tVà may mắn thay anh ta không chết .\n",
            "P-4332\t-0.6135 -0.3066 -0.3645 -1.0575 -1.3729 -0.6634 -0.3820 -0.1583 -0.2034 -0.1131\n",
            "S-4285\tShe was back and near death .\n",
            "T-4285\tBà quay lại và cận kề cái chết .\n",
            "H-4285\t-0.35896286368370056\tCô ấy quay lại và gần cái chết .\n",
            "D-4285\t-0.35896286368370056\tCô ấy quay lại và gần cái chết .\n",
            "P-4285\t-0.7803 -0.5170 -0.7905 -0.5253 -0.3087 -0.1173 -0.0935 -0.0353 -0.3216 -0.1002\n",
            "S-4085\tNow we see the opposite effect .\n",
            "T-4085\tBây giờ chúng ta thấy hiệu ứng ngược lại .\n",
            "H-4085\t-0.36509111523628235\tBây giờ chúng ta thấy ảnh hưởng ngược lại .\n",
            "D-4085\t-0.36509111523628235\tBây giờ chúng ta thấy ảnh hưởng ngược lại .\n",
            "P-4085\t-0.9492 -0.0573 -0.3146 -0.1146 -0.4603 -1.3684 -0.0217 -0.1107 -0.2452 -0.2722 -0.1018\n",
            "S-4004\tThis is a dead turtle .\n",
            "T-4004\tĐây là một con rùa biển đã chết\n",
            "H-4004\t-0.46188291907310486\tĐây là một con rùa chết .\n",
            "D-4004\t-0.46188291907310486\tĐây là một con rùa chết .\n",
            "P-4004\t-0.2799 -0.1656 -0.3333 -1.9587 -0.0299 -0.0189 -0.9505 -0.3148 -0.1054\n",
            "S-3916\tI had written these crazy things .\n",
            "T-3916\tChính tôi đã viết những điều điên rồ này .\n",
            "H-3916\t-0.30265477299690247\tTôi đã viết những thứ điên rồ này .\n",
            "D-3916\t-0.30265477299690247\tTôi đã viết những thứ điên rồ này .\n",
            "P-3916\t-0.1319 -0.3755 -0.0829 -0.4036 -0.6744 -0.0093 -0.1467 -0.6952 -0.4039 -0.1032\n",
            "S-3623\tSo I followed my hunches .\n",
            "T-3623\tThế nên tôi đi theo linh cảm của mình .\n",
            "H-3623\t-1.0062034130096436\tThế là tôi đi theo những đoạn săn của mình .\n",
            "D-3623\t-1.0062034130096436\tThế là tôi đi theo những đoạn săn của mình .\n",
            "P-3623\t-3.0668 -0.4465 -0.1966 -0.9908 -0.4715 -0.9741 -3.9853 -0.1308 -1.4302 -0.0382 -0.2423 -0.1012\n",
            "S-3474\tSo what happened years afterward ?\n",
            "T-3474\tThế chuyện gì xảy ra những năm sau đó ?\n",
            "H-3474\t-0.6990392804145813\tVậy điều gì đã xảy ra sau những năm ?\n",
            "D-3474\t-0.6990392804145813\tVậy điều gì đã xảy ra sau những năm ?\n",
            "P-3474\t-1.4399 -1.7783 -0.0730 -0.3600 -0.1863 -0.0873 -0.5149 -2.6993 -0.0466 -0.4073 -0.0965\n",
            "S-3220\tLet &apos;s starting with sensing .\n",
            "T-3220\tHãy bắt đầu với việc cảm nhận trước nhé .\n",
            "H-3220\t-0.27140331268310547\tHãy bắt đầu với cảm giác .\n",
            "D-3220\t-0.27140331268310547\tHãy bắt đầu với cảm giác .\n",
            "P-3220\t-0.8489 -0.1180 -0.0660 -0.2027 -0.1976 -0.3688 -0.2624 -0.1068\n",
            "S-2733\tI like things that are different .\n",
            "T-2733\ttôi có hứng thú với những điều đặc biệt .\n",
            "H-2733\t-0.3142193853855133\tTôi thích những thứ khác nhau .\n",
            "D-2733\t-0.3142193853855133\tTôi thích những thứ khác nhau .\n",
            "P-2733\t-0.2413 -0.0921 -0.2297 -0.2952 -0.2148 -1.0797 -0.2635 -0.0975\n",
            "S-2722\tYou brought your pictures , right ?\n",
            "T-2722\tAnh có mang theo các bức ảnh phải không ?\n",
            "H-2722\t-0.6538284420967102\tBạn đưa những bức ảnh của mình , đúng không ?\n",
            "D-2722\t-0.6538284420967102\tBạn đưa những bức ảnh của mình , đúng không ?\n",
            "P-2722\t-0.5078 -1.0523 -1.3601 -0.7671 -0.7406 -0.9322 -0.6082 -0.7312 -0.7623 -0.1017 -0.1873 -0.0952\n",
            "S-2674\tThat &apos;s the two-cent tour .\n",
            "T-2674\tđây là một yếu tố hoàn toàn khả thi .\n",
            "H-2674\t-0.7625183463096619\tĐó là chuyến đi hai đảng .\n",
            "D-2674\t-0.7625183463096619\tĐó là chuyến đi hai đảng .\n",
            "P-2674\t-0.2999 -0.1595 -0.7703 -0.1720 -0.9499 -3.1703 -0.4731 -0.1051\n",
            "S-2443\tMark , Mark , come back .\n",
            "T-2443\tMark , Mark , hãy quay lại đây nào .\n",
            "H-2443\t-0.3067755103111267\tMark , trở lại .\n",
            "D-2443\t-0.3067755103111267\tMark , trở lại .\n",
            "P-2443\t-0.0072 -0.1168 -0.7604 -0.3857 -0.4829 -0.0877\n",
            "S-2384\tAnd so we measured its motion .\n",
            "T-2384\tVà rồi chúng tôi đo chuyển động của nó .\n",
            "H-2384\t-0.5645906925201416\tVà vì vậy chúng tôi đo chuyển động .\n",
            "D-2384\t-0.5645906925201416\tVà vì vậy chúng tôi đo chuyển động .\n",
            "P-2384\t-0.9905 -1.2414 -0.6003 -0.1688 -0.3228 -0.9606 -0.2310 -0.0046 -1.0266 -0.0993\n",
            "S-2320\tIt really comes from these artists .\n",
            "T-2320\tNhưng thực sự nó đến từ những hoạ sĩ .\n",
            "H-2320\t-0.37140339612960815\tNó thực sự đến từ những nghệ sĩ này .\n",
            "D-2320\t-0.37140339612960815\tNó thực sự đến từ những nghệ sĩ này .\n",
            "P-2320\t-0.7154 -1.0667 -0.1319 -0.2714 -0.0815 -0.5652 -0.1165 -0.1764 -0.5673 -0.2958 -0.0973\n",
            "S-2248\tThis is an idea worth spreading .\n",
            "T-2248\tĐây là một ý tưởng đáng được nhân rộng .\n",
            "H-2248\t-0.3642830550670624\tĐây là một ý tưởng đáng được lan truyền .\n",
            "D-2248\t-0.3642830550670624\tĐây là một ý tưởng đáng được lan truyền .\n",
            "P-2248\t-0.2677 -0.1452 -0.7340 -0.0853 -0.0803 -0.0679 -0.5577 -0.7578 -1.0345 -0.1707 -0.1059\n",
            "S-2111\tImagine a plane full of smoke .\n",
            "T-2111\tHãy hình dung 1 máy bay tràn ngập khói .\n",
            "H-2111\t-0.4225662350654602\tHãy tưởng tượng một chiếc máy bay đầy khói .\n",
            "D-2111\t-0.4225662350654602\tHãy tưởng tượng một chiếc máy bay đầy khói .\n",
            "P-2111\t-0.5936 -0.1602 -0.0394 -0.8505 -0.7175 -0.0876 -0.0029 -1.4357 -0.1551 -0.4991 -0.1066\n",
            "S-1430\tIt &apos;s part of our life .\n",
            "T-1430\tNó là một phần cuộc sống của chúng ta .\n",
            "H-1430\t-0.36281561851501465\tĐó là một phần trong cuộc sống của chúng ta .\n",
            "D-1430\t-0.36281561851501465\tĐó là một phần trong cuộc sống của chúng ta .\n",
            "P-1430\t-0.6481 -0.1806 -0.2027 -0.1600 -1.5421 -0.1384 -0.4602 -0.4288 -0.1736 -0.1146 -0.2018 -0.1030\n",
            "S-861\tWhat do you think happened then ?\n",
            "T-861\tCác bạn nghĩ điều gì sẽ xảy ra tiếp ?\n",
            "H-861\t-0.3855714201927185\tBạn nghĩ gì đã xảy ra ?\n",
            "D-861\t-0.3855714201927185\tBạn nghĩ gì đã xảy ra ?\n",
            "P-861\t-0.5446 -0.1700 -0.5964 -0.7305 -0.1451 -0.0702 -0.7239 -0.1038\n",
            "S-266\tYou know , is it rational ?\n",
            "T-266\tBạn biết đấy , nó có bình thường không ?\n",
            "H-266\t-0.5149142742156982\tBạn biết đấy , có lý trí không ?\n",
            "D-266\t-0.5149142742156982\tBạn biết đấy , có lý trí không ?\n",
            "P-266\t-0.5621 -0.2849 -0.8270 -0.1305 -2.0417 -0.1975 -0.6681 -0.2417 -0.0972 -0.0983\n",
            "S-1956\tLet &apos;s call him Don too .\n",
            "T-1956\tHãy gọi ông ấy là Don luôn .\n",
            "H-1956\t-0.571870744228363\tHãy gọi ông ấy nữa .\n",
            "D-1956\t-0.571870744228363\tHãy gọi ông ấy nữa .\n",
            "P-1956\t-0.1791 -0.2158 -1.4068 -0.8177 -1.0661 -0.2151 -0.1024\n",
            "S-5193\tRemi knows what love is .\n",
            "T-5193\tRemi biết tình yêu là gì .\n",
            "H-5193\t-0.17910972237586975\tRemi biết tình yêu là gì .\n",
            "D-5193\t-0.17910972237586975\tRemi biết tình yêu là gì .\n",
            "P-5193\t-0.7004 -0.0478 -0.1968 -0.0094 -0.0295 -0.1377 -0.1310 -0.2644 -0.0950\n",
            "S-4568\tThey sort of go like this .\n",
            "T-4568\tChúng dường như chuyển động như thế này\n",
            "H-4568\t-0.435812383890152\tChúng kiểu như thế này .\n",
            "D-4568\t-0.435812383890152\tChúng kiểu như thế này .\n",
            "P-4568\t-0.9166 -1.0627 -0.2115 -0.2397 -0.0708 -0.4458 -0.1036\n",
            "S-4226\tSomehow this isn &apos;t working .\n",
            "T-4226\tRõ là thế này vẫn chưa ổn .\n",
            "H-4226\t-0.6591787934303284\tBằng cách nào đó điều này không hiệu quả .\n",
            "D-4226\t-0.6591787934303284\tBằng cách nào đó điều này không hiệu quả .\n",
            "P-4226\t-2.0380 -0.0870 -0.0545 -0.2277 -2.0358 -0.4696 -0.2943 -1.5532 -0.0349 -0.3580 -0.0982\n",
            "S-3775\tI mean , it &apos;s fascinating .\n",
            "T-3775\tý tôi là , thật khó tin !\n",
            "H-3775\t-0.6113736629486084\tÝ tôi là , thật thú vị .\n",
            "D-3775\t-0.6113736629486084\tÝ tôi là , thật thú vị .\n",
            "P-3775\t-1.5251 -0.1346 -0.1107 -0.5313 -1.4574 -1.4008 -0.0273 -0.2096 -0.1055\n",
            "S-3644\tMy mother phoned minutes later .\n",
            "T-3644\tVài phút sau mẹ tôi gọi điện .\n",
            "H-3644\t-0.7942898869514465\tMẹ tôi gọi những phút sau đó .\n",
            "D-3644\t-0.7942898869514465\tMẹ tôi gọi những phút sau đó .\n",
            "P-3644\t-0.0658 -0.0950 -3.7989 -1.7435 -0.0793 -0.0225 -0.6905 -0.5575 -0.0957\n",
            "S-3367\tAnd this video is real time .\n",
            "T-3367\tVà đoạn phim này là thời gian thực\n",
            "H-3367\t-0.44327470660209656\tVà video này là thời gian thực .\n",
            "D-3367\t-0.44327470660209656\tVà video này là thời gian thực .\n",
            "P-3367\t-0.8214 -0.9406 -0.2439 -0.5627 -0.5718 -0.1664 -0.3171 -0.2681 -0.0975\n",
            "S-2908\tIt cost 2.7 billion dollars .\n",
            "T-2908\tvà tốn 2,7 tỉ đô la .\n",
            "H-2908\t-0.4805457592010498\tNó tốn khoảng 2.7 tỉ đô .\n",
            "D-2908\t-0.4805457592010498\tNó tốn khoảng 2.7 tỉ đô .\n",
            "P-2908\t-1.4610 -0.3475 -0.9470 -0.0134 -0.0021 -0.7551 -0.2353 -0.4671 -0.0964\n",
            "S-2802\tThank you very much , guys .\n",
            "T-2802\tCảm ơn các bạn đã lắng nghe .\n",
            "H-2802\t-0.6131442189216614\tXin cảm ơn các bạn .\n",
            "D-2802\t-0.6131442189216614\tXin cảm ơn các bạn .\n",
            "P-2802\t-0.1538 -0.5865 -0.0969 -1.3488 -0.0902 -1.9290 -0.0868\n",
            "S-2274\tKeep going . Have fun .\n",
            "T-2274\tTiếp tục đi . Tận hưởng .\n",
            "H-2274\t-0.9436315298080444\tHãy tiếp tục đi . Hãy vui .\n",
            "D-2274\t-0.9436315298080444\tHãy tiếp tục đi . Hãy vui .\n",
            "P-2274\t-2.7503 -0.5460 -0.1779 -1.5298 -0.1944 -0.9114 -0.7059 -1.5820 -0.0951\n",
            "S-2257\tAnd I grew up in India .\n",
            "T-2257\tTôi đã lớn lên ở Ấn Độ .\n",
            "H-2257\t-0.23343472182750702\tVà tôi lớn lên ở Ấn Độ .\n",
            "D-2257\t-0.23343472182750702\tVà tôi lớn lên ở Ấn Độ .\n",
            "P-2257\t-0.9178 -0.2561 -0.1562 -0.0304 -0.2912 -0.0046 -0.1065 -0.2399 -0.0983\n",
            "S-2136\tI &apos;ve lived a good life .\n",
            "T-2136\tTôi đã sống 1 cuộc sống tốt .\n",
            "H-2136\t-0.30419111251831055\tTôi đã sống một cuộc sống tốt đẹp .\n",
            "D-2136\t-0.30419111251831055\tTôi đã sống một cuộc sống tốt đẹp .\n",
            "P-2136\t-0.1411 -0.3529 -0.0872 -0.8377 -0.0309 -0.3090 -0.1942 -0.8030 -0.1807 -0.1052\n",
            "S-2042\tThis is an ecological network .\n",
            "T-2042\tĐây là một mạng lưới sinh thái .\n",
            "H-2042\t-0.16425609588623047\tĐây là một mạng lưới sinh thái .\n",
            "D-2042\t-0.16425609588623047\tĐây là một mạng lưới sinh thái .\n",
            "P-2042\t-0.1531 -0.1171 -0.5544 -0.2203 -0.0357 -0.0317 -0.0032 -0.2597 -0.1031\n",
            "S-2035\t&quot; Yes , &quot; he said .\n",
            "T-2035\t&quot; Đúng thế , &quot; anh nói .\n",
            "H-2035\t-0.7087478637695312\t&quot; Vâng , &quot; anh ta nói .\n",
            "D-2035\t-0.7087478637695312\t&quot; Vâng , &quot; anh ta nói .\n",
            "P-2035\t-0.0881 -1.6616 -0.1938 -1.1604 -1.2287 -0.8854 -0.3380 -0.6797 -0.1429\n",
            "S-2020\tBut what are your fish eating ?\n",
            "T-2020\tNhưng cá của anh ăn những gì ?\n",
            "H-2020\t-0.4355895221233368\tNhưng con cá của bạn đang ăn gì ?\n",
            "D-2020\t-0.4355895221233368\tNhưng con cá của bạn đang ăn gì ?\n",
            "P-2020\t-0.1848 -1.9572 -0.0116 -0.4075 -0.4427 -0.6424 -0.0212 -0.4416 -0.1421 -0.1047\n",
            "S-1998\tThey flooded the canals .\n",
            "T-1998\tHọ đã làm tràn các con kênh .\n",
            "H-1998\t-0.6265021562576294\tChúng lũ lụt .\n",
            "D-1998\t-0.6265021562576294\tChúng lũ lụt .\n",
            "P-1998\t-1.7339 -0.1779 -1.0397 -0.1647 -0.5395 -0.1034\n",
            "S-5560\tThat &apos;s a little bit scary .\n",
            "T-5560\tTôi đã có một chút sợ hãi .\n",
            "H-5560\t-0.5549324750900269\tĐiều đó hơi đáng sợ .\n",
            "D-5560\t-0.5549324750900269\tĐiều đó hơi đáng sợ .\n",
            "P-5560\t-1.8623 -0.7217 -0.1657 -0.5909 -0.0150 -0.4232 -0.1056\n",
            "S-1863\tYou have that much uncertainty .\n",
            "T-1863\tBạn có chừng đó sự dao động .\n",
            "H-1863\t-0.37277403473854065\tBạn có sự không chắc chắn đó .\n",
            "D-1863\t-0.37277403473854065\tBạn có sự không chắc chắn đó .\n",
            "P-1863\t-0.4411 -0.2130 -1.3970 -0.2411 -0.0040 -0.0198 -0.6510 -0.2846 -0.1033\n",
            "S-1230\tI want to ask a question .\n",
            "T-1230\tTôi muốn đưa ra một câu hỏi .\n",
            "H-1230\t-0.30160579085350037\tTôi muốn hỏi một câu hỏi .\n",
            "D-1230\t-0.30160579085350037\tTôi muốn hỏi một câu hỏi .\n",
            "P-1230\t-0.2080 -0.0945 -1.0271 -0.2508 -0.0360 -0.4201 -0.2749 -0.1014\n",
            "S-806\tSo , please forgive me .\n",
            "T-806\tVì vậy , tha thứ cho tôi .\n",
            "H-806\t-0.530204713344574\tXin hãy tha thứ cho tôi .\n",
            "D-806\t-0.530204713344574\tXin hãy tha thứ cho tôi .\n",
            "P-806\t-2.4910 -0.7821 -0.4427 -0.0079 -0.0171 -0.1379 -0.2634 -0.0995\n",
            "S-573\tDo you want them distressed ?\n",
            "T-573\tÔng có muốn duỗi thẳng nó ?\n",
            "H-573\t-0.5036149024963379\tBạn có muốn chúng bị phân tâm không ?\n",
            "D-573\t-0.5036149024963379\tBạn có muốn chúng bị phân tâm không ?\n",
            "P-573\t-0.4253 -0.0876 -0.0526 -0.8137 -0.4529 -2.2373 -0.0332 -0.7586 -0.0769 -0.0980\n",
            "S-483\tThe answer is &quot; No . &quot;\n",
            "T-483\tCâu trả lời là &quot; Không . &quot;\n",
            "H-483\t-0.18748265504837036\tCâu trả lời là &quot; Không . &quot;\n",
            "D-483\t-0.18748265504837036\tCâu trả lời là &quot; Không . &quot;\n",
            "P-483\t-0.0510 -0.0593 -0.0350 -0.1670 -0.2130 -0.1191 -0.8558 -0.0924 -0.0947\n",
            "S-392\tThat &apos;s God , you know .\n",
            "T-392\tĐó là Chúa , bạn biết đấy .\n",
            "H-392\t-0.4882207214832306\tĐó là Chúa , bạn biết đấy .\n",
            "D-392\t-0.4882207214832306\tĐó là Chúa , bạn biết đấy .\n",
            "P-392\t-1.1914 -0.2527 -0.5396 -0.3274 -0.8580 -0.1467 -0.6711 -0.3063 -0.1006\n",
            "S-6310\tThis is a family portrait .\n",
            "T-6310\tĐây là chân dung gia đình .\n",
            "H-6310\t-0.2506789565086365\tĐây là bức chân dung gia đình .\n",
            "D-6310\t-0.2506789565086365\tĐây là bức chân dung gia đình .\n",
            "P-6310\t-0.0717 -0.1423 -1.1300 -0.3828 -0.0024 -0.0471 -0.0237 -0.3528 -0.1032\n",
            "S-6295\tIt was more like a restaurant .\n",
            "T-6295\tNó giống 1 nhà hàng hơn .\n",
            "H-6295\t-0.30676954984664917\tNó giống như một nhà hàng .\n",
            "D-6295\t-0.30676954984664917\tNó giống như một nhà hàng .\n",
            "P-6295\t-0.5383 -0.1383 -0.5238 -0.5496 -0.0717 -0.0104 -0.5158 -0.1063\n",
            "S-6045\tAnd I was distraught .\n",
            "T-6045\tTôi đã rất sầu não .\n",
            "H-6045\t-0.8792324066162109\tVà tôi đã rất khó chịu .\n",
            "D-6045\t-0.8792324066162109\tVà tôi đã rất khó chịu .\n",
            "P-6045\t-0.8174 -0.2187 -2.5967 -0.4975 -2.4545 -0.1027 -0.2440 -0.1024\n",
            "S-5998\tBut lions are very clever .\n",
            "T-5998\tNhưng sư tử rất thông minh .\n",
            "H-5998\t-0.17554740607738495\tNhưng sư tử thì rất thông minh .\n",
            "D-5998\t-0.17554740607738495\tNhưng sư tử thì rất thông minh .\n",
            "P-5998\t-0.1447 -0.1863 -0.0007 -0.2685 -0.4454 -0.1568 -0.0199 -0.2594 -0.0982\n",
            "S-5988\tSo they kill the lions .\n",
            "T-5988\tVì thế họ giết sư tử .\n",
            "H-5988\t-0.538933277130127\tVì vậy họ giết những con sư tử .\n",
            "D-5988\t-0.538933277130127\tVì vậy họ giết những con sư tử .\n",
            "P-5988\t-1.6110 -0.6822 -1.0501 -0.4412 -1.1340 -0.0196 -0.0136 -0.0003 -0.3395 -0.0980\n",
            "S-5900\tBut you have to maintain it .\n",
            "T-5900\tNhưng bạn phải trông giữ nó .\n",
            "H-5900\t-0.3341358006000519\tNhưng bạn phải duy trì nó .\n",
            "D-5900\t-0.3341358006000519\tNhưng bạn phải duy trì nó .\n",
            "P-5900\t-0.2464 -0.6832 -0.3103 -0.6145 -0.0202 -0.4620 -0.2335 -0.1029\n",
            "S-5514\tAnd I will talk about this .\n",
            "T-5514\tTôi sẽ nói về điều đó .\n",
            "H-5514\t-0.3021146357059479\tVà tôi sẽ nói về điều này .\n",
            "D-5514\t-0.3021146357059479\tVà tôi sẽ nói về điều này .\n",
            "P-5514\t-0.7378 -0.1305 -0.1767 -0.2822 -0.0867 -0.6358 -0.3176 -0.2492 -0.1025\n",
            "S-5476\tMy family believes in me .\n",
            "T-5476\tGia đình tôi tin tưởng tôi .\n",
            "H-5476\t-0.14321504533290863\tGia đình tôi tin vào tôi .\n",
            "D-5476\t-0.14321504533290863\tGia đình tôi tin vào tôi .\n",
            "P-5476\t-0.0379 -0.0430 -0.1192 -0.0332 -0.2667 -0.3523 -0.1862 -0.1073\n",
            "S-5067\tThey sell certificates .\n",
            "T-5067\tHọ bán các chứng chỉ bảo mật\n",
            "H-5067\t-0.48894554376602173\tHọ bán giấy chứng nhận .\n",
            "D-5067\t-0.48894554376602173\tHọ bán giấy chứng nhận .\n",
            "P-5067\t-0.2940 -0.0027 -2.5608 -0.2643 -0.0785 -0.1197 -0.1026\n",
            "S-1366\tAnd it really changed the dynamic .\n",
            "T-1366\tVà nó thực sự thay đổi mọi thứ .\n",
            "H-1366\t-0.5019897222518921\tVà nó thực sự thay đổi động lực .\n",
            "D-1366\t-0.5019897222518921\tVà nó thực sự thay đổi động lực .\n",
            "P-1366\t-0.6512 -0.4390 -1.2230 -0.1141 -0.3626 -0.0336 -1.0831 -0.7780 -0.2328 -0.1026\n",
            "S-3627\tWe worked well into each night .\n",
            "T-3627\tChúng tôi làm việc đến đêm khuya .\n",
            "H-3627\t-0.35601434111595154\tChúng tôi làm việc tốt trong mỗi đêm .\n",
            "D-3627\t-0.35601434111595154\tChúng tôi làm việc tốt trong mỗi đêm .\n",
            "P-3627\t-0.1684 -0.1190 -0.4758 -0.2029 -0.5748 -0.9624 -0.4040 -0.3426 -0.2083 -0.1019\n",
            "S-3034\tWill it be under $ 20 ?\n",
            "T-3034\tGiá có dưới 20 đô la không ?\n",
            "H-3034\t-0.6562893390655518\tLiệu nó có dưới 20 đô la ?\n",
            "D-3034\t-0.6562893390655518\tLiệu nó có dưới 20 đô la ?\n",
            "P-3034\t-0.7401 -0.4816 -0.4438 -3.0622 -0.0109 -0.5402 -0.2347 -0.2923 -0.1008\n",
            "S-2898\tNow how could this come about ?\n",
            "T-2898\tVậy thì nó xảy ra như thế nào ?\n",
            "H-2898\t-0.540169358253479\tTại sao điều này lại xảy ra ?\n",
            "D-2898\t-0.540169358253479\tTại sao điều này lại xảy ra ?\n",
            "P-2898\t-2.1696 -0.0380 -1.2209 -0.2621 -0.2441 -0.6091 -0.1062 -0.1179 -0.0937\n",
            "S-2395\tI think this is really cool .\n",
            "T-2395\tTôi nghĩ điều này hết sức thú vị .\n",
            "H-2395\t-0.6127267479896545\tTôi nghĩ điều này thật tuyệt vời .\n",
            "D-2395\t-0.6127267479896545\tTôi nghĩ điều này thật tuyệt vời .\n",
            "P-2395\t-0.1775 -0.1787 -1.0166 -0.2349 -0.9449 -1.5220 -1.0716 -0.2695 -0.0987\n",
            "S-2319\tI probably shouldn &apos;t say that .\n",
            "T-2319\tDường như tôi không nên nói vậy .\n",
            "H-2319\t-0.5471365451812744\tCó lẽ tôi không nên nói thế .\n",
            "D-2319\t-0.5471365451812744\tCó lẽ tôi không nên nói thế .\n",
            "P-2319\t-1.2296 -0.6794 -0.2311 -0.3775 -0.3118 -0.0792 -1.6007 -0.3102 -0.1046\n",
            "S-2295\tAnd apparently it was quite popular .\n",
            "T-2295\tVà hình như nó khá là phổ biến .\n",
            "H-2295\t-0.4198550879955292\tVà rõ ràng là nó khá phổ biến .\n",
            "D-2295\t-0.4198550879955292\tVà rõ ràng là nó khá phổ biến .\n",
            "P-2295\t-0.3075 -1.3594 -0.0757 -1.2447 -0.3387 -0.4844 -0.0531 -0.0067 -0.2266 -0.1017\n",
            "S-2147\tYou can see the water coming .\n",
            "T-2147\tBạn có thể nhìn thấy nước tràn vào .\n",
            "H-2147\t-0.42766091227531433\tBạn có thể thấy nước đến .\n",
            "D-2147\t-0.42766091227531433\tBạn có thể thấy nước đến .\n",
            "P-2147\t-0.3553 -0.1444 -0.0935 -0.3382 -0.1841 -1.8397 -0.3651 -0.1011\n",
            "S-2096\tWant to feed the world ?\n",
            "T-2096\tMuốn cho cả thế giới ăn ư ?\n",
            "H-2096\t-0.5988098978996277\tMuốn thức ăn cho thế giới ?\n",
            "D-2096\t-0.5988098978996277\tMuốn thức ăn cho thế giới ?\n",
            "P-2096\t-1.6956 -1.7165 -1.0913 -0.0301 -0.2543 -0.1521 -0.0417 -0.3055 -0.1022\n",
            "S-1996\tThey literally flipped the switch .\n",
            "T-1996\tHọ thật sự đã bật công tắc lại .\n",
            "H-1996\t-0.6655538082122803\tHọ thực sự lật ngược công tắc .\n",
            "D-1996\t-0.6655538082122803\tHọ thực sự lật ngược công tắc .\n",
            "P-1996\t-1.9622 -1.7541 -0.3459 -1.3055 -0.0838 -0.0842 -0.0662 -0.2835 -0.1045\n",
            "S-1872\tIt is a completely different notion .\n",
            "T-1872\tNó hoàn toàn là một khái niệm khác .\n",
            "H-1872\t-0.3605864644050598\tĐó là một khái niệm hoàn toàn khác .\n",
            "D-1872\t-0.3605864644050598\tĐó là một khái niệm hoàn toàn khác .\n",
            "P-1872\t-0.7764 -1.5019 -0.2311 -0.2385 -0.0619 -0.0267 -0.0610 -0.0899 -0.5112 -0.1072\n",
            "S-1819\tYou have not changed the story .\n",
            "T-1819\tBạn đã không làm câu chuyện thay đổi .\n",
            "H-1819\t-0.42640364170074463\tBạn không thay đổi câu chuyện .\n",
            "D-1819\t-0.42640364170074463\tBạn không thay đổi câu chuyện .\n",
            "P-1819\t-0.8260 -0.3487 -1.0452 -0.0407 -0.0884 -0.0730 -0.8884 -0.1008\n",
            "S-1744\tEverybody talks about happiness these days .\n",
            "T-1744\tNgày nay ai cũng nói về hạnh phúc .\n",
            "H-1744\t-0.33313655853271484\tMọi người nói về hạnh phúc ngày nay .\n",
            "D-1744\t-0.33313655853271484\tMọi người nói về hạnh phúc ngày nay .\n",
            "P-1744\t-0.7475 -0.0707 -0.8228 -0.0627 -0.1429 -0.0603 -0.8546 -0.2740 -0.1937 -0.1022\n",
            "S-1597\tSo that &apos;s a tough one .\n",
            "T-1597\tVà kia là một cái khó nhằn .\n",
            "H-1597\t-0.5002401471138\tĐó là một điều khó khăn .\n",
            "D-1597\t-0.5002401471138\tĐó là một điều khó khăn .\n",
            "P-1597\t-1.2398 -0.1968 -0.4384 -1.4154 -0.1583 -0.1858 -0.2687 -0.0988\n",
            "S-1547\tFirst , we &apos;ve got population .\n",
            "T-1547\tĐầu tiên , chúng ta có dân số .\n",
            "H-1547\t-0.26195916533470154\tĐầu tiên , chúng ta có dân số .\n",
            "D-1547\t-0.26195916533470154\tĐầu tiên , chúng ta có dân số .\n",
            "P-1547\t-1.0368 -0.0397 -0.4094 -0.2984 -0.1032 -0.1894 -0.2205 -0.0298 -0.1892 -0.1032\n",
            "S-1541\tIt &apos;s been constantly going up .\n",
            "T-1541\tNhưng nó lại đang tăng lên liên tục .\n",
            "H-1541\t-0.7476221323013306\tNó liên tục tăng lên .\n",
            "D-1541\t-0.7476221323013306\tNó liên tục tăng lên .\n",
            "P-1541\t-1.2932 -1.6813 -0.0168 -1.6164 -0.0918 -0.4267 -0.1071\n",
            "S-4999\tI &apos;m going to stop that .\n",
            "T-4999\tTôi sẽ tắt tiếng này đi .\n",
            "H-4999\t-0.4526134133338928\tTôi sẽ dừng nó lại .\n",
            "D-4999\t-0.4526134133338928\tTôi sẽ dừng nó lại .\n",
            "P-4999\t-0.3298 -0.1454 -0.1180 -2.0403 -0.1726 -0.2536 -0.1085\n",
            "S-1231\tWhat do you think happens next ?\n",
            "T-1231\tBạn nghĩ điều gì sẽ đến tiếp theo ?\n",
            "H-1231\t-0.38359013199806213\tBạn nghĩ gì sẽ xảy ra tiếp theo ?\n",
            "D-1231\t-0.38359013199806213\tBạn nghĩ gì sẽ xảy ra tiếp theo ?\n",
            "P-1231\t-0.3413 -0.1638 -1.1417 -0.9232 -0.1897 -0.0871 -0.7972 -0.0473 -0.0441 -0.1004\n",
            "S-1206\tWe made this game in 2007 .\n",
            "T-1206\tChúng tôi xây dựng nó vào năm 2007 .\n",
            "H-1206\t-0.3804607093334198\tChúng tôi làm trò chơi này vào năm 2007 .\n",
            "D-1206\t-0.3804607093334198\tChúng tôi làm trò chơi này vào năm 2007 .\n",
            "P-1206\t-0.1831 -0.3135 -1.6989 -0.0317 -0.7609 -0.1480 -0.1606 -0.0163 -0.0104 -0.7644 -0.0975\n",
            "S-1080\tSo , you can do it .\n",
            "T-1080\tVậy nên bạn có thể thực hiện nó .\n",
            "H-1080\t-0.6279911994934082\tBạn có thể làm được .\n",
            "D-1080\t-0.6279911994934082\tBạn có thể làm được .\n",
            "P-1080\t-2.3612 -0.2181 -0.0901 -0.4608 -0.2506 -0.9142 -0.1009\n",
            "S-812\tAnd it was a huge success .\n",
            "T-812\tvà đã mang lại một thành công lớn .\n",
            "H-812\t-0.4075326919555664\tVà đó là một thành công lớn .\n",
            "D-812\t-0.4075326919555664\tVà đó là một thành công lớn .\n",
            "P-812\t-0.8863 -0.5924 -0.2308 -0.8215 -0.0426 -0.0353 -0.7309 -0.2204 -0.1077\n",
            "S-94\tWell , what does that mean ?\n",
            "T-94\tVậy , điều đó có nghĩa là gì ?\n",
            "H-94\t-0.28305763006210327\tĐiều đó có nghĩa là gì ?\n",
            "D-94\t-0.28305763006210327\tĐiều đó có nghĩa là gì ?\n",
            "P-94\t-0.6631 -0.6463 -0.2129 -0.1458 -0.3478 -0.0504 -0.1027 -0.0957\n",
            "S-73\tNow , what does that mean ?\n",
            "T-73\tGiờ thì điều đó có nghĩa là gì ?\n",
            "H-73\t-0.3135063946247101\tĐiều đó có nghĩa là gì ?\n",
            "D-73\t-0.3135063946247101\tĐiều đó có nghĩa là gì ?\n",
            "P-73\t-0.7840 -0.7080 -0.2442 -0.1566 -0.3678 -0.0484 -0.1032 -0.0958\n",
            "S-6993\tI could be that person . &quot;\n",
            "T-6993\tMình có thể đã là người đó &quot;\n",
            "H-6993\t-0.34227097034454346\tTôi có thể là người đó . &quot;\n",
            "D-6993\t-0.34227097034454346\tTôi có thể là người đó . &quot;\n",
            "P-6993\t-0.3711 -0.4374 -0.0963 -0.5513 -0.8278 -0.3576 -0.2275 -0.1146 -0.0967\n",
            "S-6513\tThere have been several close calls .\n",
            "T-6513\tVà cũng mấy lần suýt chết ,\n",
            "H-6513\t-0.38164782524108887\tĐã có vài cuộc gọi gần đây .\n",
            "D-6513\t-0.38164782524108887\tĐã có vài cuộc gọi gần đây .\n",
            "P-6513\t-1.0184 -0.1049 -0.8985 -0.1434 -0.1860 -0.3062 -0.4646 -0.2151 -0.0979\n",
            "S-6510\tAre you still smart or not ?\n",
            "T-6510\tBạn có còn thông minh nữa không ?\n",
            "H-6510\t-0.35360345244407654\tBạn vẫn thông minh hay không ?\n",
            "D-6510\t-0.35360345244407654\tBạn vẫn thông minh hay không ?\n",
            "P-6510\t-0.6147 -0.3188 -0.4495 -0.0514 -0.8629 -0.2973 -0.1339 -0.1004\n",
            "S-6447\tHow about that pancake ? &quot;\n",
            "T-6447\tCháu muốn gọi bánh kếp ? &quot;\n",
            "H-6447\t-0.7202160954475403\tCòn bánh mì thì sao ? &quot;\n",
            "D-6447\t-0.7202160954475403\tCòn bánh mì thì sao ? &quot;\n",
            "P-6447\t-1.5827 -0.4186 -3.1555 -0.1764 -0.0082 -0.1173 -0.2004 -0.1027\n",
            "S-6087\tThe most important thing is passion .\n",
            "T-6087\tCái quan trọng nhất là khát vọng .\n",
            "H-6087\t-0.17201195657253265\tĐiều quan trọng nhất là đam mê .\n",
            "D-6087\t-0.17201195657253265\tĐiều quan trọng nhất là đam mê .\n",
            "P-6087\t-0.3273 -0.0485 -0.0522 -0.1017 -0.3255 -0.3676 -0.0203 -0.2038 -0.1012\n",
            "S-6072\tBut they mean two different things .\n",
            "T-6072\tNhững chúng mang hai nghĩa khác biệt .\n",
            "H-6072\t-0.46707919239997864\tNhưng chúng có nghĩa là hai điều khác nhau .\n",
            "D-6072\t-0.46707919239997864\tNhưng chúng có nghĩa là hai điều khác nhau .\n",
            "P-6072\t-0.2734 -0.6013 -0.3957 -1.0749 -0.2665 -0.3813 -1.4602 -0.1558 -0.1876 -0.2408 -0.1004\n",
            "S-5983\tThey kill our livestock .\n",
            "T-5983\tChúng giết gia súc của chúng tôi .\n",
            "H-5983\t-0.41705650091171265\tHọ giết gia súc .\n",
            "D-5983\t-0.41705650091171265\tHọ giết gia súc .\n",
            "P-5983\t-0.4398 -0.2550 -0.5170 -0.2616 -0.9319 -0.0971\n",
            "S-5843\tWe see all the same symptoms .\n",
            "T-5843\tChúng ta thấy đều cùng triệu chứng .\n",
            "H-5843\t-0.5734192728996277\tChúng ta thấy các triệu chứng giống nhau .\n",
            "D-5843\t-0.5734192728996277\tChúng ta thấy các triệu chứng giống nhau .\n",
            "P-5843\t-0.3214 -0.1709 -1.5015 -1.7910 -0.1561 -0.0047 -1.3644 -0.0456 -0.2816 -0.0971\n",
            "S-5710\tSo why did I do that ?\n",
            "T-5710\tTại sao tôi lại làm như vậy ?\n",
            "H-5710\t-0.5165868401527405\tVậy tại sao tôi lại làm thế ?\n",
            "D-5710\t-0.5165868401527405\tVậy tại sao tôi lại làm thế ?\n",
            "P-5710\t-1.0036 -0.1261 -0.0477 -0.2050 -1.1309 -0.0904 -1.8542 -0.0930 -0.0985\n",
            "  8% 5/60 [00:08<01:44,  1.90s/it, wps=538]S-2194\tHe showed it to Javier .\n",
            "T-2194\tAnh ấy cho Javier xem .\n",
            "H-2194\t-0.7402006983757019\tAnh ấy đã chỉ ra nó cho Javier .\n",
            "D-2194\t-0.7402006983757019\tAnh ấy đã chỉ ra nó cho Javier .\n",
            "P-2194\t-1.4868 -0.8103 -0.6899 -2.6396 -0.4050 -0.9087 -1.0155 -0.0065 -0.2325 -0.2616 -0.3267 -0.0992\n",
            "S-6019\tAnd I said , &quot; Yes . &quot;\n",
            "T-6019\tTôi trả lời , &quot; Vâng &quot; .\n",
            "H-6019\t-0.6499866843223572\tVà tôi trả lời : &quot; Vâng . &quot;\n",
            "D-6019\t-0.6499866843223572\tVà tôi trả lời : &quot; Vâng . &quot;\n",
            "P-6019\t-1.0761 -0.1453 -1.1449 -0.0261 -1.4620 -0.0749 -2.1519 -0.2216 -0.0994 -0.0978\n",
            "S-5905\tAnd the garden , it was beautiful .\n",
            "T-5905\tVà mảnh vườn , nó rất đẹp .\n",
            "H-5905\t-0.4311583638191223\tVà khu vườn , nó rất đẹp .\n",
            "D-5905\t-0.4311583638191223\tVà khu vườn , nó rất đẹp .\n",
            "P-5905\t-0.3413 -0.3589 -0.0057 -0.2291 -0.9082 -1.6603 -0.0857 -0.1831 -0.1081\n",
            "S-5400\tThey are far from being extinct .\n",
            "T-5400\tHọ còn lâu mới bị tuyệt chủng .\n",
            "H-5400\t-0.7436419725418091\tChúng đã bị tuyệt chủng .\n",
            "D-5400\t-0.7436419725418091\tChúng đã bị tuyệt chủng .\n",
            "P-5400\t-0.1687 -2.6705 -1.7595 -0.0013 -0.0086 -0.4875 -0.1094\n",
            "S-4799\tNow we didn &apos;t write this app .\n",
            "T-4799\tChúng tôi không viết ứng dụng này .\n",
            "H-4799\t-0.38399219512939453\tChúng tôi không viết ứng dụng này .\n",
            "D-4799\t-0.38399219512939453\tChúng tôi không viết ứng dụng này .\n",
            "P-4799\t-1.3745 -0.3289 -0.9911 -0.0255 -0.0890 -0.0274 -0.1585 -0.3589 -0.1021\n",
            "S-4483\tOh , that &apos;s all my time ?\n",
            "T-4483\tỒ , tôi hết giờ rồi sao ?\n",
            "H-4483\t-0.6579077839851379\tỒ , tất cả thời gian của tôi là bao giờ ?\n",
            "D-4483\t-0.6579077839851379\tỒ , tất cả thời gian của tôi là bao giờ ?\n",
            "P-4483\t-0.8823 -0.0930 -2.8126 -0.0619 -0.2986 -0.0503 -0.2601 -0.2282 -0.9318 -1.6630 -0.9863 -0.1850 -0.0997\n",
            "S-4392\tMy name is Brian Goldman .\n",
            "T-4392\tTên tôi là Brian Goldman .\n",
            "H-4392\t-0.21573135256767273\tTên tôi là Brian Goldman .\n",
            "D-4392\t-0.21573135256767273\tTên tôi là Brian Goldman .\n",
            "P-4392\t-1.1521 -0.0976 -0.1009 -0.0145 -0.0092 -0.0396 -0.0019 -0.4297 -0.0960\n",
            "S-4306\tAnd it was what I was feeling .\n",
            "T-4306\tVà đó là điều tôi cảm thấy .\n",
            "H-4306\t-0.5559592843055725\tVà đó là những gì tôi cảm thấy .\n",
            "D-4306\t-0.5559592843055725\tVà đó là những gì tôi cảm thấy .\n",
            "P-4306\t-0.6427 -0.7781 -0.3753 -2.0187 -0.1502 -0.2346 -0.3136 -0.6641 -0.2781 -0.1042\n",
            "S-4275\tBut I carried on with my work .\n",
            "T-4275\tNhưng tôi vẫn tiếp tục làm việc .\n",
            "H-4275\t-0.27441033720970154\tNhưng tôi tiếp tục công việc của mình .\n",
            "D-4275\t-0.27441033720970154\tNhưng tôi tiếp tục công việc của mình .\n",
            "P-4275\t-0.2793 -0.1402 -0.2023 -0.0581 -1.2746 -0.0252 -0.2252 -0.1312 -0.3045 -0.1035\n",
            "S-3587\tSomething stiffened inside me .\n",
            "T-3587\tCó chút gì cứng lại trong tôi .\n",
            "H-3587\t-0.7769886255264282\tCó điều gì đó kích thích bên trong tôi .\n",
            "D-3587\t-0.7769886255264282\tCó điều gì đó kích thích bên trong tôi .\n",
            "P-3587\t-2.0476 -1.0704 -0.0267 -0.0346 -3.5797 -0.5652 -0.5019 -0.0920 -0.2089 -0.3177 -0.1022\n",
            "S-3279\tThe roof also is covered with water .\n",
            "T-3279\tMái nhà cũng phủ đầy nước .\n",
            "H-3279\t-0.3689533770084381\tmái nhà cũng được bao phủ bởi nước .\n",
            "D-3279\t-0.3689533770084381\tmái nhà cũng được bao phủ bởi nước .\n",
            "P-3279\t-0.9455 -0.0579 -0.2691 -0.3291 -1.5319 -0.0996 -0.1069 -0.0340 -0.2127 -0.1030\n",
            "S-3192\tI &apos;ve got something to show you .\n",
            "T-3192\tTôi muốn các bạn xem thứ này .\n",
            "H-3192\t-0.5539101362228394\tTôi có một thứ để cho các bạn xem .\n",
            "D-3192\t-0.5539101362228394\tTôi có một thứ để cho các bạn xem .\n",
            "P-3192\t-0.2182 -0.5401 -1.1116 -1.2921 -0.9223 -0.4725 -0.4300 -0.0741 -0.6945 -0.2394 -0.0981\n",
            "S-2968\tHave a look what she &apos;s doing .\n",
            "T-2968\tHãy nhìn xem con cái đang làm gì\n",
            "H-2968\t-0.4936334192752838\tHãy xem cô ấy đang làm gì .\n",
            "D-2968\t-0.4936334192752838\tHãy xem cô ấy đang làm gì .\n",
            "P-2968\t-0.1493 -1.5796 -0.9364 -0.6159 -0.4226 -0.1188 -0.2379 -0.2720 -0.1101\n",
            "S-2819\tHow many would opt for memory ?\n",
            "T-2819\tBao nhiêu người sẽ chọn trí nhớ ?\n",
            "H-2819\t-0.500793993473053\tBao nhiêu người sẽ chọn ký ức ?\n",
            "D-2819\t-0.500793993473053\tBao nhiêu người sẽ chọn ký ức ?\n",
            "P-2819\t-0.2678 -0.0541 -0.5572 -0.7918 -0.4264 -2.2323 -0.0322 -0.0458 -0.0996\n",
            "S-2650\tAnd it &apos;s also very risky .\n",
            "T-2650\tđồng thời nó cũng rất mạo hiểm .\n",
            "H-2650\t-0.4758261442184448\tVà nó cũng rất nguy hiểm .\n",
            "D-2650\t-0.4758261442184448\tVà nó cũng rất nguy hiểm .\n",
            "P-2650\t-0.7802 -0.3973 -0.5423 -0.3408 -1.3508 -0.0284 -0.2682 -0.0984\n",
            "S-2280\tNow this is one of the images .\n",
            "T-2280\tVà giờ là 1 trong số chúng .\n",
            "H-2280\t-0.2744309902191162\tĐây là một trong những hình ảnh .\n",
            "D-2280\t-0.2744309902191162\tĐây là một trong những hình ảnh .\n",
            "P-2280\t-0.4667 -0.1496 -0.3826 -0.0721 -0.4461 -0.6513 -0.0226 -0.1698 -0.1090\n",
            "S-6156\tHe wasn &apos;t alone when he started .\n",
            "T-6156\tÔng ấy không bắt đầu một mình .\n",
            "H-6156\t-0.7429957389831543\tAnh ấy không cô đơn khi bắt đầu .\n",
            "D-6156\t-0.7429957389831543\tAnh ấy không cô đơn khi bắt đầu .\n",
            "P-6156\t-2.1562 -0.7015 -0.1897 -0.9730 -1.2972 -0.4362 -0.8648 -0.0630 -0.6445 -0.1038\n",
            "S-2018\tHe pointed at the algae .\n",
            "T-2018\tAnh trỏ mấy cây tảo .\n",
            "H-2018\t-0.5951530337333679\tAnh ta chỉ vào tảo .\n",
            "D-2018\t-0.5951530337333679\tAnh ta chỉ vào tảo .\n",
            "P-2018\t-1.6185 -0.7024 -0.0388 -0.5064 -1.1226 -0.0194 -0.6338 -0.1194\n",
            "S-1995\tThey reversed the flow of water .\n",
            "T-1995\tHọ đã quay ngược lại dòng nước .\n",
            "H-1995\t-0.36052536964416504\tChúng làm đảo ngược dòng nước .\n",
            "D-1995\t-0.36052536964416504\tChúng làm đảo ngược dòng nước .\n",
            "P-1995\t-0.6070 -1.3320 -0.1245 -0.3668 -0.0073 -0.2036 -0.1399 -0.1031\n",
            "S-1865\tSo the correlation is low .\n",
            "T-1865\tVì vậy sự tương quan là thấp .\n",
            "H-1865\t-0.7925581932067871\tVậy mối tương quan là thấp .\n",
            "D-1865\t-0.7925581932067871\tVậy mối tương quan là thấp .\n",
            "P-1865\t-2.2028 -1.2100 -0.4081 -0.0111 -2.0123 -0.2190 -0.1725 -0.1046\n",
            "S-1631\tIt is kind of a crazy idea .\n",
            "T-1631\tĐó là một ý tưởng điên rồ .\n",
            "H-1631\t-0.32866156101226807\tĐó là một ý tưởng điên rồ .\n",
            "D-1631\t-0.32866156101226807\tĐó là một ý tưởng điên rồ .\n",
            "P-1631\t-1.3682 -0.3520 -0.3478 -0.2757 -0.1419 -0.0176 -0.1043 -0.2439 -0.1065\n",
            "S-1534\tAnd so that &apos;s a big challenge .\n",
            "T-1534\tVà đó là một thách thức lớn .\n",
            "H-1534\t-0.3628125786781311\tVà đó là một thách thức lớn .\n",
            "D-1534\t-0.3628125786781311\tVà đó là một thách thức lớn .\n",
            "P-1534\t-1.0047 -0.2713 -0.2810 -0.2906 -0.8523 -0.0759 -0.1401 -0.2479 -0.1016\n",
            "S-1145\tThey are building an epic story .\n",
            "T-1145\tHọ đang xây dựng một sử thi .\n",
            "H-1145\t-0.6425768136978149\tHọ đang xây dựng một câu chuyện hoang đường .\n",
            "D-1145\t-0.6425768136978149\tHọ đang xây dựng một câu chuyện hoang đường .\n",
            "P-1145\t-0.7681 -0.3088 -0.6436 -0.2124 -0.3632 -0.0880 -0.0578 -3.2623 -0.9252 -0.3332 -0.1058\n",
            "S-830\tAnd then they execute on it .\n",
            "T-830\trồi họ thực hiện kế hoạch đó .\n",
            "H-830\t-0.6175075173377991\tVà rồi họ điều hành nó .\n",
            "D-830\t-0.6175075173377991\tVà rồi họ điều hành nó .\n",
            "P-830\t-0.8119 -1.2732 -0.1540 -1.6821 -0.0018 -0.4105 -0.5023 -0.1042\n",
            "S-828\tBut there &apos;s another reason as well .\n",
            "T-828\tNhưng cũng còn một lý do khác .\n",
            "H-828\t-0.4249325692653656\tNhưng cũng có một lý do khác .\n",
            "D-828\t-0.4249325692653656\tNhưng cũng có một lý do khác .\n",
            "P-828\t-0.3088 -1.0543 -0.2801 -0.3216 -0.5041 -0.0611 -0.2382 -0.9493 -0.1069\n",
            "S-455\tThe official dogma of what ?\n",
            "T-455\tGiáo điều chính thống của cái gì ?\n",
            "H-455\t-0.568747878074646\tChính quyền chính thức của điều gì ?\n",
            "D-455\t-0.568747878074646\tChính quyền chính thức của điều gì ?\n",
            "P-455\t-0.7233 -1.1225 -0.8019 -0.2990 -0.6119 -1.0959 -0.2239 -0.1373 -0.1031\n",
            "S-422\tIt &apos;s nothing if not ambitious .\n",
            "T-422\tĐó là một tham vọng rất lớn .\n",
            "H-422\t-0.42232221364974976\tKhông có gì nếu không tham vọng .\n",
            "D-422\t-0.42232221364974976\tKhông có gì nếu không tham vọng .\n",
            "P-422\t-1.1743 -1.2406 -0.1491 -0.5443 -0.1331 -0.0087 -0.0080 -0.4396 -0.1033\n",
            "S-6321\tThis young child is eight years old .\n",
            "T-6321\tĐứa trẻ này 8 tuổi .\n",
            "H-6321\t-0.4799782931804657\tĐứa trẻ này đã 8 tuổi .\n",
            "D-6321\t-0.4799782931804657\tĐứa trẻ này đã 8 tuổi .\n",
            "P-6321\t-0.1536 -0.0036 -0.5254 -0.4578 -2.5013 -0.2810 -0.0378 -0.2537 -0.1055\n",
            "S-4749\tThis is a modest little app .\n",
            "T-4749\tĐây là một ứng dụng nhỏ .\n",
            "H-4749\t-0.4193664789199829\tĐây là một ứng dụng nhỏ nhất .\n",
            "D-4749\t-0.4193664789199829\tĐây là một ứng dụng nhỏ nhất .\n",
            "P-4749\t-0.1600 -0.1166 -0.6614 -0.0099 -0.0176 -1.4126 -1.1799 -0.1126 -0.1037\n",
            "S-4523\tAnd it opens up a map .\n",
            "T-4523\tVà một bản đồ mở ra .\n",
            "H-4523\t-0.29742032289505005\tVà nó mở ra một bản đồ .\n",
            "D-4523\t-0.29742032289505005\tVà nó mở ra một bản đồ .\n",
            "P-4523\t-1.0117 -0.2287 -0.1029 -0.1098 -0.7202 -0.1530 -0.0059 -0.2331 -0.1116\n",
            "S-4355\tThat &apos;s the system that we have .\n",
            "T-4355\tĐó là hệ thống ta có .\n",
            "H-4355\t-0.29178404808044434\tĐó là hệ thống mà chúng ta có .\n",
            "D-4355\t-0.29178404808044434\tĐó là hệ thống mà chúng ta có .\n",
            "P-4355\t-0.2838 -0.3172 -0.4602 -0.0313 -0.8016 -0.1952 -0.2392 -0.2566 -0.2317 -0.1011\n",
            "S-4181\tWhat am I going to look at ?\n",
            "T-4181\tĐiều tôi muốn nói là gì ?\n",
            "H-4181\t-0.33126845955848694\tTôi sẽ xem cái gì ?\n",
            "D-4181\t-0.33126845955848694\tTôi sẽ xem cái gì ?\n",
            "P-4181\t-0.1896 -0.1784 -0.8537 -0.6088 -0.0700 -0.3104 -0.1080\n",
            "S-1784\tAnd it &apos;s a very easy question .\n",
            "T-1784\tVà nó là một câu hỏi dễ dàng .\n",
            "H-1784\t-0.4063604176044464\tVà đó là một câu hỏi rất dễ .\n",
            "D-1784\t-0.4063604176044464\tVà đó là một câu hỏi rất dễ .\n",
            "P-1784\t-0.6950 -0.7014 -0.2629 -0.3721 -0.0524 -0.0459 -0.8057 -0.2748 -0.7460 -0.1074\n",
            "S-4509\tBut what are we doing with it ?\n",
            "T-4509\tNhưng ta đang làm gì với nó vậy ?\n",
            "H-4509\t-0.24906039237976074\tNhưng chúng ta đang làm gì với nó ?\n",
            "D-4509\t-0.24906039237976074\tNhưng chúng ta đang làm gì với nó ?\n",
            "P-4509\t-0.2450 -0.2357 -0.3965 -0.5692 -0.1322 -0.0989 -0.0843 -0.5182 -0.1067 -0.1040\n",
            "S-4360\tBut there are two problems with that .\n",
            "T-4360\tNhưng có hai vấn đề với điều đó .\n",
            "H-4360\t-0.40683239698410034\tNhưng có hai vấn đề với điều đó .\n",
            "D-4360\t-0.40683239698410034\tNhưng có hai vấn đề với điều đó .\n",
            "P-4360\t-0.2396 -0.5737 -0.6180 -0.0538 -0.0609 -0.2703 -1.3408 -0.5721 -0.2353 -0.1038\n",
            "S-4314\tI began to feel a bit better .\n",
            "T-4314\tTôi bắt đầu thấy khá hơn một chút .\n",
            "H-4314\t-0.28316906094551086\tTôi bắt đầu cảm thấy tốt hơn một chút .\n",
            "D-4314\t-0.28316906094551086\tTôi bắt đầu cảm thấy tốt hơn một chút .\n",
            "P-4314\t-0.1120 -0.1763 -0.0648 -0.1429 -0.3127 -0.3943 -0.0748 -1.3704 -0.0225 -0.3438 -0.1004\n",
            "S-4223\tBut , but , you know what ?\n",
            "T-4223\tNhưng , nhưng , bạn có biết không ?\n",
            "H-4223\t-0.513222336769104\tNhưng , bạn biết không ?\n",
            "D-4223\t-0.513222336769104\tNhưng , bạn biết không ?\n",
            "P-4223\t-0.1697 -0.4582 -1.7493 -0.1640 -0.7172 -0.2330 -0.1011\n",
            "S-3889\tYou should ask for some of that .\n",
            "T-3889\tthế thì mình nên xin họ một chút .\n",
            "H-3889\t-0.7171517610549927\tBạn nên hỏi một vài điều .\n",
            "D-3889\t-0.7171517610549927\tBạn nên hỏi một vài điều .\n",
            "P-3889\t-0.4712 -0.2807 -0.8858 -1.0455 -0.7064 -0.9861 -1.2590 -0.1025\n",
            "S-3785\tI talk a lot about these issues .\n",
            "T-3785\tTôi nói rất nhiều về những vấn đề này\n",
            "H-3785\t-0.27443090081214905\tTôi nói rất nhiều về những vấn đề này .\n",
            "D-3785\t-0.27443090081214905\tTôi nói rất nhiều về những vấn đề này .\n",
            "P-3785\t-0.1177 -0.6835 -0.7617 -0.0555 -0.0709 -0.4023 -0.0671 -0.0663 -0.3259 -0.3689 -0.0988\n",
            "S-3597\tI lived in parallel worlds .\n",
            "T-3597\tTôi sống trong hai thế giới song song .\n",
            "H-3597\t-0.26014670729637146\tTôi sống trong những thế giới song song .\n",
            "D-3597\t-0.26014670729637146\tTôi sống trong những thế giới song song .\n",
            "P-3597\t-0.0995 -0.1666 -0.3209 -1.0205 -0.0434 -0.0420 -0.0304 -0.4278 -0.3455 -0.1049\n",
            "S-3556\tI never knew him in real life .\n",
            "T-3556\tTôi chưa bao giờ gặp ông ngoài đời .\n",
            "H-3556\t-0.4721837341785431\tTôi không bao giờ biết ông trong đời thực .\n",
            "D-3556\t-0.4721837341785431\tTôi không bao giờ biết ông trong đời thực .\n",
            "P-3556\t-0.1412 -1.2949 -0.3579 -0.0555 -0.1463 -0.9483 -0.5404 -0.6036 -0.7987 -0.2025 -0.1048\n",
            "S-3515\tIt turns out to be really difficult .\n",
            "T-3515\tHoá ra nó khó hơn chúng ta nghĩ .\n",
            "H-3515\t-0.9011947512626648\tHoá ra rất khó .\n",
            "D-3515\t-0.9011947512626648\tHoá ra rất khó .\n",
            "P-3515\t-2.0508 -0.0796 -2.4746 -0.0710 -0.6294 -0.1017\n",
            "S-3373\tSo just imagine that for a moment .\n",
            "T-3373\tNên hãy tưởng tượng một giây lát thôi .\n",
            "H-3373\t-0.7523737549781799\tHãy tưởng tượng rằng trong một khoảnh khắc .\n",
            "D-3373\t-0.7523737549781799\tHãy tưởng tượng rằng trong một khoảnh khắc .\n",
            "P-3373\t-1.3073 -0.2769 -0.0220 -1.8337 -0.9087 -0.5667 -2.1585 -0.0668 -0.2729 -0.1102\n",
            "S-3026\tBut I don &apos;t buy anything new .\n",
            "T-3026\tNhưng tôi không hề mua quần áo mới .\n",
            "H-3026\t-0.43110421299934387\tNhưng tôi không mua gì mới .\n",
            "D-3026\t-0.43110421299934387\tNhưng tôi không mua gì mới .\n",
            "P-3026\t-0.2437 -0.1812 -0.2127 -0.1733 -1.8914 -0.0687 -0.5658 -0.1120\n",
            "S-2985\tPlay is not frivolous .\n",
            "T-2985\tChơi đùa thật sự không vô bổ .\n",
            "H-2985\t-0.8213015198707581\tChơi không phải là thân thiện .\n",
            "D-2985\t-0.8213015198707581\tChơi không phải là thân thiện .\n",
            "P-2985\t-0.9814 -1.2380 -2.4279 -0.1862 -0.1815 -1.9389 -0.0341 -0.3016 -0.1021\n",
            "S-2926\tThese will be irresistible .\n",
            "T-2926\tNhững khả năng này thật khó cưỡng lại .\n",
            "H-2926\t-0.6739786863327026\tNhững thứ này sẽ gây khó chịu .\n",
            "D-2926\t-0.6739786863327026\tNhững thứ này sẽ gây khó chịu .\n",
            "P-2926\t-1.3208 -1.4726 -0.4583 -0.4174 -1.5133 -0.5417 -0.0263 -0.2118 -0.1036\n",
            "S-2636\tNo , that &apos;s what I thought .\n",
            "T-2636\tKhông , đó không phải điều tôi nghĩ .\n",
            "H-2636\t-0.41271764039993286\tKhông , đó là điều tôi nghĩ .\n",
            "D-2636\t-0.41271764039993286\tKhông , đó là điều tôi nghĩ .\n",
            "P-2636\t-0.2005 -0.1764 -0.3085 -0.4406 -0.8636 -0.7326 -0.5885 -0.3042 -0.0996\n",
            "S-2381\tAnd so that &apos;s what we did .\n",
            "T-2381\tVà đó là điều chúng tôi đã làm .\n",
            "H-2381\t-0.3240983486175537\tVà đó là những gì chúng tôi đã làm .\n",
            "D-2381\t-0.3240983486175537\tVà đó là những gì chúng tôi đã làm .\n",
            "P-2381\t-0.6626 -0.2985 -0.3969 -0.9913 -0.1002 -0.1666 -0.1522 -0.3336 -0.1193 -0.2489 -0.0949\n",
            "S-3820\tWe love technology . We love creativity .\n",
            "T-3820\tyêu công nghệ , thích sáng tạo\n",
            "H-3820\t-0.22194451093673706\tChúng ta yêu công nghệ . Chúng ta yêu sự sáng tạo .\n",
            "D-3820\t-0.22194451093673706\tChúng ta yêu công nghệ . Chúng ta yêu sự sáng tạo .\n",
            "P-3820\t-0.1163 -0.3517 -0.2182 -0.0878 -0.0368 -0.4455 -0.1325 -0.1001 -0.2023 -0.8881 -0.0090 -0.0208 -0.4038 -0.0944\n",
            "S-1568\tIf you burn natural gas , no .\n",
            "T-1568\tNếu bạn đốt khí tự nhiên , không .\n",
            "H-1568\t-0.34691786766052246\tNếu bạn đốt khí ga tự nhiên , không .\n",
            "D-1568\t-0.34691786766052246\tNếu bạn đốt khí ga tự nhiên , không .\n",
            "P-1568\t-0.1079 -0.4981 -0.0074 -0.8509 -0.8869 -0.0305 -0.0351 -0.3538 -0.5433 -0.4019 -0.1003\n",
            "S-1390\tLet me read you the entry .\n",
            "T-1390\tĐể tôi đọc kết quả cho các bạn nghe\n",
            "H-1390\t-0.3679882287979126\tĐể tôi đọc cho các bạn nghe .\n",
            "D-1390\t-0.3679882287979126\tĐể tôi đọc cho các bạn nghe .\n",
            "P-1390\t-0.2992 -0.1011 -1.2146 -0.1516 -0.5809 -0.0923 -0.3970 -0.3718 -0.1035\n",
            "S-1335\tIt was really , really quite profound .\n",
            "T-1335\tMột cảm giác nằm sâu trong tâm trí .\n",
            "H-1335\t-0.8578112721443176\tNó thực sự rất sâu sắc .\n",
            "D-1335\t-0.8578112721443176\tNó thực sự rất sâu sắc .\n",
            "P-1335\t-2.0428 -1.5993 -0.1063 -0.4151 -2.2815 -0.0054 -0.3169 -0.0952\n",
            "S-1282\tAnd so that got me very excited .\n",
            "T-1282\tVà điều đó khiến tôi rất hứng thú .\n",
            "H-1282\t-0.6462213397026062\tVà điều đó khiến tôi rất hào hứng .\n",
            "D-1282\t-0.6462213397026062\tVà điều đó khiến tôi rất hào hứng .\n",
            "P-1282\t-0.8545 -0.7280 -0.5328 -1.2170 -0.0905 -1.0902 -1.4945 -0.0251 -0.3333 -0.0963\n",
            "S-1143\tFive million people use it every month .\n",
            "T-1143\tNăm triệu người sử dụng nó mỗi tháng .\n",
            "H-1143\t-0.34753257036209106\tNăm triệu người sử dụng nó mỗi tháng .\n",
            "D-1143\t-0.34753257036209106\tNăm triệu người sử dụng nó mỗi tháng .\n",
            "P-1143\t-0.9101 -0.0589 -0.1010 -1.1223 -0.0503 -0.5396 -0.1965 -0.0803 -0.3235 -0.0928\n",
            "S-1103\tThis is true . I believe this .\n",
            "T-1103\tĐiều này đúng . Tôi tin như vậy .\n",
            "H-1103\t-0.576204240322113\tĐiều này là đúng . Tôi tin vào điều này .\n",
            "D-1103\t-0.576204240322113\tĐiều này là đúng . Tôi tin vào điều này .\n",
            "P-1103\t-0.7490 -0.5874 -0.8711 -1.4609 -0.1865 -0.1141 -0.0453 -2.0535 -0.1949 -0.3810 -0.1726 -0.0980\n",
            "S-144\tThey &apos;re homelands of somebody .\n",
            "T-144\tĐó là quê hương của một ai đó .\n",
            "H-144\t-0.8336885571479797\tChúng là những người thân của một người .\n",
            "D-144\t-0.8336885571479797\tChúng là những người thân của một người .\n",
            "P-144\t-0.8263 -0.3091 -0.8660 -1.5191 -2.3635 -0.0924 -1.3117 -0.6436 -0.3072 -0.0980\n",
            "S-103\tAnd the problem is not technology itself .\n",
            "T-103\tVà vấn đề không phải là công nghệ .\n",
            "H-103\t-0.2477184534072876\tVà vấn đề không phải là công nghệ .\n",
            "D-103\t-0.2477184534072876\tVà vấn đề không phải là công nghệ .\n",
            "P-103\t-0.4890 -0.1353 -0.0794 -0.2126 -0.1606 -0.3935 -0.2321 -0.0318 -0.6405 -0.1023\n",
            "S-7425\tLet &apos;s be a part of this .\n",
            "T-7425\tHãy là một phần của việc này .\n",
            "H-7425\t-0.5738973021507263\tHãy trở thành một phần của điều này .\n",
            "D-7425\t-0.5738973021507263\tHãy trở thành một phần của điều này .\n",
            "P-7425\t-0.6156 -2.2250 -0.1086 -0.2618 -0.0380 -0.2725 -1.5899 -0.2005 -0.3179 -0.1091\n",
            "S-6869\tSo let &apos;s pull up some video .\n",
            "T-6869\tHãy kiểm tra một vài đoạn phim .\n",
            "H-6869\t-1.1339759826660156\tChúng ta hãy xem một vài video .\n",
            "D-6869\t-1.1339759826660156\tChúng ta hãy xem một vài video .\n",
            "P-6869\t-3.3484 -0.1157 -0.2610 -3.1048 -1.0941 -0.8083 -1.0553 -0.3113 -0.1067\n",
            "S-6793\tJust wanted to drop you a note .\n",
            "T-6793\tChỉ muốn viết cho anh vài dòng .\n",
            "H-6793\t-0.8780571818351746\tTôi chỉ muốn cho các bạn một nốt nhạc .\n",
            "D-6793\t-0.8780571818351746\tTôi chỉ muốn cho các bạn một nốt nhạc .\n",
            "P-6793\t-2.9990 -1.1282 -0.0691 -1.4663 -0.8731 -0.0878 -1.8515 -0.3466 -0.4036 -0.3266 -0.1067\n",
            "S-6762\tThis is Jason Garber .\n",
            "T-6762\tĐây là Jason Garber .\n",
            "H-6762\t-0.21280688047409058\tĐây là Jason Garber .\n",
            "D-6762\t-0.21280688047409058\tĐây là Jason Garber .\n",
            "P-6762\t-0.1170 -0.1147 -0.0047 -0.0014 -0.0050 -0.0068 -1.4094 -0.1543 -0.1020\n",
            "S-6634\tHundreds of schools were lost .\n",
            "T-6634\tHàng trăm ngôi trường bị tàn phá .\n",
            "H-6634\t-0.521885335445404\tHàng trăm trường học đã bị mất .\n",
            "D-6634\t-0.521885335445404\tHàng trăm trường học đã bị mất .\n",
            "P-6634\t-0.0867 -0.0120 -0.2381 -0.1958 -1.3741 -0.6991 -1.5751 -0.4206 -0.0953\n",
            "S-6523\tThis kind of thinking isn &apos;t new .\n",
            "T-6523\tKiểu tư duy này không mới .\n",
            "H-6523\t-0.6171637177467346\tLoại suy nghĩ này không mới .\n",
            "D-6523\t-0.6171637177467346\tLoại suy nghĩ này không mới .\n",
            "P-6523\t-1.7978 -0.4522 -0.0586 -0.6670 -0.3503 -0.8822 -0.6284 -0.1008\n",
            "S-6288\tThey have nothing to compare it to .\n",
            "T-6288\tHọ không có gì để so sánh .\n",
            "H-6288\t-0.5900760293006897\tChúng không có gì để so sánh nó với nó .\n",
            "D-6288\t-0.5900760293006897\tChúng không có gì để so sánh nó với nó .\n",
            "P-6288\t-1.1114 -0.2757 -0.6989 -0.2905 -1.0990 -0.0954 -0.0280 -0.3934 -0.2349 -1.8527 -0.8985 -0.1024\n",
            "S-3351\tBut the reality is far from it .\n",
            "T-3351\tNhưng thực tế không phải thế .\n",
            "H-3351\t-0.7935116291046143\tNhưng thực tế thì xa với nó .\n",
            "D-3351\t-0.7935116291046143\tNhưng thực tế thì xa với nó .\n",
            "P-3351\t-0.2613 -0.8554 -0.0687 -1.7526 -0.6925 -2.8960 -0.3065 -0.1932 -0.1154\n",
            "S-7014\tAnd the thing is , I am .\n",
            "T-7014\tCó chứ .\n",
            "H-7014\t-0.6358787417411804\tVà vấn đề là , tôi là như vậy .\n",
            "D-7014\t-0.6358787417411804\tVà vấn đề là , tôi là như vậy .\n",
            "P-7014\t-0.2393 -0.9269 -0.0757 -0.2443 -1.0667 -0.2072 -1.5818 -1.5926 -0.6986 -0.2606 -0.1010\n",
            "S-4777\tThey haven &apos;t given up on government .\n",
            "T-4777\tHọ chưa từ bỏ\n",
            "H-4777\t-0.5183759331703186\tHọ chưa từ bỏ chính phủ .\n",
            "D-4777\t-0.5183759331703186\tHọ chưa từ bỏ chính phủ .\n",
            "P-4777\t-0.7614 -1.2073 -1.4828 -0.0399 -0.1026 -0.1058 -0.3472 -0.1001\n",
            "S-7024\tIt &apos;s just not going to happen .\n",
            "T-7024\tKhông thể nào .\n",
            "H-7024\t-0.43192487955093384\tNó sẽ không xảy ra .\n",
            "D-7024\t-0.43192487955093384\tNó sẽ không xảy ra .\n",
            "P-7024\t-1.3349 -0.2741 -0.0811 -0.6805 -0.1002 -0.4470 -0.1057\n",
            "S-492\tWhat do you want to do ? &quot;\n",
            "T-492\tBạn muốn làm gì ?\n",
            "H-492\t-0.5099154114723206\tBạn muốn làm gì ? &quot;\n",
            "D-492\t-0.5099154114723206\tBạn muốn làm gì ? &quot;\n",
            "P-492\t-2.3729 -0.0797 -0.1940 -0.1232 -0.2335 -0.4776 -0.0885\n",
            "S-2406\tWell , that &apos;s not quite right .\n",
            "T-2406\tKhông hẳn như vây ;\n",
            "H-2406\t-0.5424314737319946\tVâng , điều đó không đúng .\n",
            "D-2406\t-0.5424314737319946\tVâng , điều đó không đúng .\n",
            "P-2406\t-1.5271 -0.1705 -0.8434 -0.4878 -0.3875 -0.2708 -0.5464 -0.1060\n",
            "S-2810\tHow about living longer with good health ?\n",
            "T-2810\tSống lâu hơn ?\n",
            "H-2810\t-0.42531993985176086\tCòn việc sống lâu hơn với sức khoẻ tốt thì sao ?\n",
            "D-2810\t-0.42531993985176086\tCòn việc sống lâu hơn với sức khoẻ tốt thì sao ?\n",
            "P-2810\t-1.9790 -1.1872 -0.1164 -0.1383 -0.0987 -0.1791 -0.6802 -0.0118 -0.2097 -0.6742 -0.0264 -0.1259 -0.1022\n",
            "S-6966\tBut they were right , you know .\n",
            "T-6966\tNhưng họ nói đúng .\n",
            "H-6966\t-0.4367573857307434\tNhưng họ đã đúng , bạn biết đấy .\n",
            "D-6966\t-0.4367573857307434\tNhưng họ đã đúng , bạn biết đấy .\n",
            "P-6966\t-0.1974 -0.7066 -0.7332 -0.1274 -0.2811 -0.8302 -0.1092 -0.9924 -0.2892 -0.1009\n",
            "S-1937\tIt doesn &apos;t taste very good either .\n",
            "T-1937\tVà cũng không ngon lắm .\n",
            "H-1937\t-0.8929203152656555\tNó cũng không ngon miệng .\n",
            "D-1937\t-0.8929203152656555\tNó cũng không ngon miệng .\n",
            "P-1937\t-1.3027 -0.2893 -0.7259 -2.2635 -0.6793 -0.8646 -0.1251\n",
            "S-2040\tHe shook his head , no .\n",
            "T-2040\tAnh lắc đầu , không .\n",
            "H-2040\t-0.733004093170166\tAnh ta lắc đầu mình , không .\n",
            "D-2040\t-0.733004093170166\tAnh ta lắc đầu mình , không .\n",
            "P-2040\t-1.5445 -0.2138 -1.6883 -0.1034 -2.0469 -0.3606 -0.2070 -0.3257 -0.1069\n",
            "S-2812\tWhich one would you like the most ?\n",
            "T-2812\tBạn muốn điều gì nhất ?\n",
            "H-2812\t-0.684711217880249\tBạn sẽ thích cái nào nhất ?\n",
            "D-2812\t-0.684711217880249\tBạn sẽ thích cái nào nhất ?\n",
            "P-2812\t-0.6020 -1.0013 -1.3293 -0.6876 -0.4629 -1.1584 -0.1339 -0.1022\n",
            "S-2852\tBut what will come in the future ?\n",
            "T-2852\tNhưng tương lai thì sao ?\n",
            "H-2852\t-0.2625733017921448\tNhưng điều gì sẽ xảy ra trong tương lai ?\n",
            "D-2852\t-0.2625733017921448\tNhưng điều gì sẽ xảy ra trong tương lai ?\n",
            "P-2852\t-0.1509 -1.2574 -0.0584 -0.0668 -0.7259 -0.1480 -0.2275 -0.0213 -0.0462 -0.0787 -0.1073\n",
            "S-3800\tWe &apos;re constantly running into each other .\n",
            "T-3800\tchúng ta không ngừng mâu thuẫn\n",
            "H-3800\t-0.5163397789001465\tChúng ta liên tục chạy vào nhau .\n",
            "D-3800\t-0.5163397789001465\tChúng ta liên tục chạy vào nhau .\n",
            "P-3800\t-0.2042 -0.4565 -0.5564 -0.0069 -1.1756 -1.6801 -0.2467 -0.2164 -0.1042\n",
            "S-3814\tIt would be unconscionable .\n",
            "T-3814\tNhư thế quá vô lương tâm\n",
            "H-3814\t-0.9118197560310364\tNó sẽ vô thức .\n",
            "D-3814\t-0.9118197560310364\tNó sẽ vô thức .\n",
            "P-3814\t-1.5217 -0.8854 -2.4320 -0.2785 -0.2494 -0.1040\n",
            "S-4309\tAnd I kept asking myself these questions .\n",
            "T-4309\tVà tôi cứ tự hỏi .\n",
            "H-4309\t-0.5567863583564758\tVà tôi luôn tự hỏi mình những câu hỏi này .\n",
            "D-4309\t-0.5567863583564758\tVà tôi luôn tự hỏi mình những câu hỏi này .\n",
            "P-4309\t-1.0545 -0.1212 -2.1526 -0.1037 -0.0663 -0.9000 -1.0461 -0.0314 -0.0816 -0.7603 -0.2683 -0.0955\n",
            "S-4007\tIt was not drowned yet .\n",
            "T-4007\tNó vẫn chưa bị ngộp\n",
            "H-4007\t-0.5779893398284912\tNó vẫn chưa chết đuối .\n",
            "D-4007\t-0.5779893398284912\tNó vẫn chưa chết đuối .\n",
            "P-4007\t-0.5384 -1.3605 -0.0090 -0.2171 -1.4529 -0.3630 -0.1051\n",
            "S-3098\tDidn &apos;t make sense to me .\n",
            "T-3098\tTôi không hiểu tại sao hết .\n",
            "H-3098\t-0.5551882386207581\tKhông có ý nghĩa gì với tôi .\n",
            "D-3098\t-0.5551882386207581\tKhông có ý nghĩa gì với tôi .\n",
            "P-3098\t-1.9661 -0.2745 -1.1346 -0.0406 -0.2446 -0.2912 -0.1487 -0.7945 -0.1018\n",
            "S-3032\tIs it going to be my size ?\n",
            "T-3032\tNó có vừa với tôi không ?\n",
            "H-3032\t-0.7180750370025635\tNó có kích thước của tôi không ?\n",
            "D-3032\t-0.7180750370025635\tNó có kích thước của tôi không ?\n",
            "P-3032\t-1.4743 -0.9783 -1.6481 -1.0244 -0.4171 -0.1316 -0.5899 -0.0936 -0.1053\n",
            "S-1946\t&quot; Best in the business . &quot;\n",
            "T-1946\t&quot; Tốt nhất trong ngành . &quot;\n",
            "H-1946\t-0.5019715428352356\t&quot; Best trong kinh doanh . &quot;\n",
            "D-1946\t-0.5019715428352356\t&quot; Best trong kinh doanh . &quot;\n",
            "P-1946\t-0.0755 -2.2251 -0.4665 -0.2230 -0.7032 -0.0626 -0.5801 -0.0807 -0.1010\n",
            "S-1127\tGamers don &apos;t sit around .\n",
            "T-1127\tGame thủ không ngồi chờ .\n",
            "H-1127\t-0.9207861423492432\tCác nhà Gamers không ngồi quanh .\n",
            "D-1127\t-0.9207861423492432\tCác nhà Gamers không ngồi quanh .\n",
            "P-1127\t-1.7686 -0.9427 -2.2071 -0.0015 -1.2156 -0.1542 -0.1001 -2.2643 -0.4506 -0.1032\n",
            "S-951\tI &apos;ll get my sleeve back .\n",
            "T-951\tTôi sẽ vén tay áo lên\n",
            "H-951\t-0.7090801000595093\tTôi sẽ đi ngủ lại .\n",
            "D-951\t-0.7090801000595093\tTôi sẽ đi ngủ lại .\n",
            "P-951\t-0.1638 -0.2060 -2.9767 -0.1918 -0.9888 -0.3330 -0.1035\n",
            "S-711\tI wouldn &apos;t recommend it .\n",
            "T-711\tTôi không khuyến khích cách này .\n",
            "H-711\t-0.5612847208976746\tTôi sẽ không đề nghị nó .\n",
            "D-711\t-0.5612847208976746\tTôi sẽ không đề nghị nó .\n",
            "P-711\t-0.2163 -0.6596 -0.0942 -1.1765 -0.2050 -1.6377 -0.3928 -0.1082\n",
            "S-628\tEverybody needs a fishbowl .\n",
            "T-628\tAi cũng cần một bể cá .\n",
            "H-628\t-0.7652573585510254\tMọi người cần một cái bát nước .\n",
            "D-628\t-0.7652573585510254\tMọi người cần một cái bát nước .\n",
            "P-628\t-1.1942 -0.0715 -0.3940 -0.4189 -0.6639 -0.8297 -0.1353 -3.4386 -0.3988 -0.1077\n",
            "S-7005\tI &apos;m quite fond of it .\n",
            "T-7005\tvà khá là thích nó .\n",
            "H-7005\t-0.5493582487106323\tTôi rất thích nó .\n",
            "D-7005\t-0.5493582487106323\tTôi rất thích nó .\n",
            "P-7005\t-0.1546 -1.7455 -0.2420 -0.7407 -0.3132 -0.1001\n",
            "S-6884\tHow do we take that next step ?\n",
            "T-6884\tChúng tôi làm bước kế tiếp\n",
            "H-6884\t-0.5483654141426086\tLàm thế nào để chúng ta bước tiếp theo ?\n",
            "D-6884\t-0.5483654141426086\tLàm thế nào để chúng ta bước tiếp theo ?\n",
            "P-6884\t-0.4545 -0.7399 -0.0691 -1.3571 -0.5876 -0.2791 -2.1657 -0.0679 -0.0232 -0.1848 -0.1029\n",
            "S-6206\tIt was very time-consuming .\n",
            "T-6206\tNó rất tốn thời gian .\n",
            "H-6206\t-0.8921364545822144\tNó rất tiêu thụ .\n",
            "D-6206\t-0.8921364545822144\tNó rất tiêu thụ .\n",
            "P-6206\t-1.6544 -0.6591 -1.4563 -0.8865 -0.5988 -0.0977\n",
            "S-4442\tIt &apos;s this , just like this .\n",
            "T-4442\tNó chỉ như thế này .\n",
            "H-4442\t-0.5723433494567871\tNó giống như thế này .\n",
            "D-4442\t-0.5723433494567871\tNó giống như thế này .\n",
            "P-4442\t-1.0084 -1.3211 -0.5711 -0.1966 -0.0637 -0.7423 -0.1033\n",
            "S-2618\t... Meaning not so optimistic .\n",
            "T-2618\t... Thật khó mà lạc quan trong những lúc như này .\n",
            "H-2618\t-0.8999981880187988\t... Y khoa học không lạc quan lắm .\n",
            "D-2618\t-0.8999981880187988\t... Y khoa học không lạc quan lắm .\n",
            "P-2618\t-0.1267 -4.2321 -0.9725 -0.7995 -0.3008 -1.3844 -0.0085 -0.8446 -0.2316 -0.0991\n",
            "S-2061\tI almost never cook with it .\n",
            "T-2061\tTôi gần như không bao giờ nấu mà có da cá .\n",
            "H-2061\t-0.3388734459877014\tTôi hầu như không bao giờ nấu ăn với nó .\n",
            "D-2061\t-0.3388734459877014\tTôi hầu như không bao giờ nấu ăn với nó .\n",
            "P-2061\t-0.1872 -1.0376 -0.0844 -0.4269 -0.0704 -0.0437 -0.1842 -0.4105 -0.8589 -0.3491 -0.3064 -0.1072\n",
            "S-1281\tThey were seeing something magical .\n",
            "T-1281\tHọ đã được xem điều gì đó giống như phép màu .\n",
            "H-1281\t-0.6451247334480286\tHọ đã nhìn thấy điều gì đó kì diệu .\n",
            "D-1281\t-0.6451247334480286\tHọ đã nhìn thấy điều gì đó kì diệu .\n",
            "P-1281\t-0.3684 -1.7903 -1.6341 -0.1343 -1.6431 -0.1823 -0.1139 -0.8554 -0.0380 -0.2329 -0.1037\n",
            "S-7414\tIt &apos;s a vacation community .\n",
            "T-7414\tNó là một nơi nghỉ ngơi của cộng đồng .\n",
            "H-7414\t-0.4106238782405853\tĐó là một cộng đồng kỳ nghỉ .\n",
            "D-7414\t-0.4106238782405853\tĐó là một cộng đồng kỳ nghỉ .\n",
            "P-7414\t-0.6152 -0.1561 -0.6439 -0.1989 -0.0390 -0.8845 -0.0417 -1.0115 -0.1048\n",
            "S-7403\tBecause architecture actually moves quite quickly .\n",
            "T-7403\tBởi vì kiến trúc thực sự di chuyển rất nhanh .\n",
            "H-7403\t-0.4008843004703522\tBởi vì kiến trúc thực sự di chuyển khá nhanh .\n",
            "D-7403\t-0.4008843004703522\tBởi vì kiến trúc thực sự di chuyển khá nhanh .\n",
            "P-7403\t-0.2309 -0.0623 -0.0643 -0.0220 -1.6833 -0.4864 -1.2638 -0.0538 -0.2640 -0.0145 -0.5606 -0.1047\n",
            "S-7384\tAnd then , something amazing happened .\n",
            "T-7384\tVà sau đó , điều kỳ diệu đã xảy ra .\n",
            "H-7384\t-0.5356054902076721\tVà sau đó , một điều kỳ diệu đã xảy ra .\n",
            "D-7384\t-0.5356054902076721\tVà sau đó , một điều kỳ diệu đã xảy ra .\n",
            "P-7384\t-0.5710 -1.6822 -0.0819 -0.4364 -1.1372 -0.1833 -1.9578 -0.0464 -0.2580 -0.1096 -0.0949 -0.3036 -0.1006\n",
            "S-5428\tWe &apos;re working with local communities .\n",
            "T-5428\tChúng tôi đang hợp tác với những cộng đồng địa phương\n",
            "H-5428\t-0.31423139572143555\tChúng tôi đang làm việc với các cộng đồng địa phương .\n",
            "D-5428\t-0.31423139572143555\tChúng tôi đang làm việc với các cộng đồng địa phương .\n",
            "P-5428\t-0.1823 -0.3205 -0.8410 -0.2258 -0.0445 -0.3853 -1.6784 -0.0452 -0.0345 -0.0098 -0.0078 -0.2117 -0.0983\n",
            "S-5374\tTalk about what you heard here .\n",
            "T-5374\tHãy kể về những gì bạn được nghe ở đây .\n",
            "H-5374\t-0.38028135895729065\tNói về những gì bạn đã nghe ở đây .\n",
            "D-5374\t-0.38028135895729065\tNói về những gì bạn đã nghe ở đây .\n",
            "P-5374\t-0.1543 -0.0836 -0.4100 -0.2058 -0.7754 -1.3039 -0.2755 -0.4482 -0.0828 -0.3412 -0.1023\n",
            "S-5327\tHe needed them to feel protected .\n",
            "T-5327\tAnh ta cần chúng để cảm thấy được bảo vệ .\n",
            "H-5327\t-0.4474080502986908\tAnh ta cần họ cảm thấy được bảo vệ .\n",
            "D-5327\t-0.4474080502986908\tAnh ta cần họ cảm thấy được bảo vệ .\n",
            "P-5327\t-1.3787 -0.8971 -0.0493 -0.5024 -0.6240 -0.1541 -0.9487 -0.0342 -0.0307 -0.1948 -0.1075\n",
            "S-4863\tHow could we help you ? &quot;\n",
            "T-4863\tChúng tôi có thể giúp gì được cho bạn ? &quot;\n",
            "H-4863\t-0.48031026124954224\tLàm thế nào để giúp bạn ? &quot;\n",
            "D-4863\t-0.48031026124954224\tLàm thế nào để giúp bạn ? &quot;\n",
            "P-4863\t-0.3133 -0.9311 -0.0716 -1.1693 -0.2629 -0.8581 -0.4597 -0.1612 -0.0956\n",
            "S-4445\tEven cats were watching this video .\n",
            "T-4445\tThậm chí những con mèo cũng đang xem video này .\n",
            "H-4445\t-0.47635388374328613\tNgay cả mèo đang xem đoạn phim này .\n",
            "D-4445\t-0.47635388374328613\tNgay cả mèo đang xem đoạn phim này .\n",
            "P-4445\t-0.5510 -0.0388 -1.3401 -0.8183 -0.1860 -0.9508 -0.1810 -0.1834 -0.4057 -0.1083\n",
            "S-4387\tShe shares her experience with others .\n",
            "T-4387\tChị chia sẻ trải nghiệm ấy với những người khác .\n",
            "H-4387\t-0.2802305817604065\tCô chia sẻ kinh nghiệm của mình với những người khác .\n",
            "D-4387\t-0.2802305817604065\tCô chia sẻ kinh nghiệm của mình với những người khác .\n",
            "P-4387\t-0.5935 -0.4667 -0.0508 -0.7094 -0.0082 -0.1408 -0.1849 -0.1232 -0.7762 -0.0939 -0.0614 -0.3343 -0.0998\n",
            "S-3565\tAll the adults knew the risks .\n",
            "T-3565\tTất cả những người lớn đều biết các rủi ro .\n",
            "H-3565\t-0.36859312653541565\tTất cả những người lớn đều biết về rủi ro .\n",
            "D-3565\t-0.36859312653541565\tTất cả những người lớn đều biết về rủi ro .\n",
            "P-3565\t-0.2506 -0.0426 -1.1243 -0.1196 -0.2020 -0.0186 -0.1090 -2.0640 -0.0820 -0.0144 -0.2873 -0.1088\n",
            "S-3300\tSo you can have this cloud .\n",
            "T-3300\tVà như vậy bạn có được đám mây này đây ,\n",
            "H-3300\t-0.4402174949645996\tBạn có thể có đám mây này .\n",
            "D-3300\t-0.4402174949645996\tBạn có thể có đám mây này .\n",
            "P-3300\t-2.0735 -0.1507 -0.0874 -0.3613 -0.0312 -0.0113 -0.9074 -0.2365 -0.1026\n",
            "S-3259\tThis data was not available before .\n",
            "T-3259\tTrước đây chúng ta không hề có dữ liệu này .\n",
            "H-3259\t-0.4049276113510132\tDữ liệu này không có sẵn trước đó .\n",
            "D-3259\t-0.4049276113510132\tDữ liệu này không có sẵn trước đó .\n",
            "P-3259\t-0.4243 -0.0357 -0.0261 -0.2270 -0.8015 -0.6487 -0.5987 -0.1232 -1.0411 -0.4271 -0.1007\n",
            "S-2287\tYou can zoom around very simply .\n",
            "T-2287\tBạn có thể phóng to thu nhỏ rất dễ dàng .\n",
            "H-2287\t-0.24327631294727325\tBạn có thể phóng to rất đơn giản .\n",
            "D-2287\t-0.24327631294727325\tBạn có thể phóng to rất đơn giản .\n",
            "P-2287\t-0.3563 -0.2265 -0.0892 -0.1395 -0.1070 -0.9818 -0.1483 -0.0356 -0.2470 -0.1017\n",
            "S-1902\tThat does not hold for emotions .\n",
            "T-1902\tĐiều đó không áp dụng được với các cảm xúc .\n",
            "H-1902\t-0.6922702789306641\tĐiều đó không giữ cho cảm xúc .\n",
            "D-1902\t-0.6922702789306641\tĐiều đó không giữ cho cảm xúc .\n",
            "P-1902\t-0.8455 -0.8961 -0.1818 -2.1523 -1.6122 -0.1229 -0.0303 -0.2889 -0.1003\n",
            "S-1094\tIt &apos;s just better than reality .\n",
            "T-1094\tĐó chỉ đơn giản là tốt đẹp hơn thực tế .\n",
            "H-1094\t-0.49245336651802063\tNó tốt hơn thực tế .\n",
            "D-1094\t-0.49245336651802063\tNó tốt hơn thực tế .\n",
            "P-1094\t-0.7439 -0.6772 -0.0762 -1.2248 -0.2882 -0.3297 -0.1071\n",
            "S-1191\tOkay , we can do that .\n",
            "T-1191\tĐược rồi , chúng ta có thể làm việc này .\n",
            "H-1191\t-0.3629961311817169\tĐược rồi , chúng ta có thể làm điều đó .\n",
            "D-1191\t-0.3629961311817169\tĐược rồi , chúng ta có thể làm điều đó .\n",
            "P-1191\t-0.9138 -0.1731 -0.1984 -0.3396 -0.2922 -0.1863 -0.0915 -0.1024 -1.4437 -0.2460 -0.2684 -0.1005\n",
            "S-6825\tWe truly thank God for you .\n",
            "T-6825\tChúng tôi thật sự cảm ơn Chúa vì ông đã đến .\n",
            "H-6825\t-0.36746346950531006\tChúng tôi thực sự cảm ơn Chúa vì bạn .\n",
            "D-6825\t-0.36746346950531006\tChúng tôi thực sự cảm ơn Chúa vì bạn .\n",
            "P-6825\t-0.3685 -0.2838 -0.7757 -0.0585 -0.3889 -0.1032 -0.0612 -0.1417 -1.4249 -0.3446 -0.0911\n",
            "S-2685\tWe talk about bold , fresh .\n",
            "T-2685\tNgười đàn ông : Chúng ta có nói tới sự tình táo , đầy sức sống .\n",
            "H-2685\t-0.4003618061542511\tChúng ta nói về táo bạo , mới .\n",
            "D-2685\t-0.4003618061542511\tChúng ta nói về táo bạo , mới .\n",
            "P-2685\t-0.3115 -0.1490 -0.5581 -0.1341 -0.1581 -0.0144 -0.6826 -1.5195 -0.3731 -0.1031\n",
            "S-2726\tTell me about this world .\n",
            "T-2726\tAnh có thể kể cho biết cảm nhận của anh về cuộc sống này .\n",
            "H-2726\t-0.3503919541835785\tNói với tôi về thế giới này .\n",
            "D-2726\t-0.3503919541835785\tNói với tôi về thế giới này .\n",
            "P-2726\t-1.2432 -1.0220 -0.1170 -0.0747 -0.0549 -0.0580 -0.1721 -0.3153 -0.0964\n",
            "S-1974\tShe kind of set us up .\n",
            "T-1974\tCô ấy đã sắp đặt cho tôi với em cá này được gặp nhau .\n",
            "H-1974\t-0.8032010197639465\tCô ấy đã khiến chúng tôi đứng dậy .\n",
            "D-1974\t-0.8032010197639465\tCô ấy đã khiến chúng tôi đứng dậy .\n",
            "P-1974\t-1.2105 -0.3548 -1.4032 -2.5849 -0.1320 -0.2398 -1.4934 -0.1095 -0.3978 -0.1060\n",
            "S-291\tSo Jesus , what a thought !\n",
            "T-291\tÔi chúa ơi , thật là một ý nghĩ hay ho phải không !\n",
            "H-291\t-0.7156489491462708\tGiê-su , một suy nghĩ nào !\n",
            "D-291\t-0.7156489491462708\tGiê-su , một suy nghĩ nào !\n",
            "P-291\t-1.9443 -0.1335 -0.6881 -0.0981 -0.1658 -1.8429 -0.4600 -0.1416 -2.2316 -0.0684 -0.0978\n",
            "S-7021\tIt makes life hard for us .\n",
            "T-7021\tNó khiến cuộc sống của chúng tôi trở nên khó khăn hơn .\n",
            "H-7021\t-0.47155600786209106\tNó làm cuộc sống khó khăn cho chúng ta .\n",
            "D-7021\t-0.47155600786209106\tNó làm cuộc sống khó khăn cho chúng ta .\n",
            "P-7021\t-0.5090 -1.1331 -0.9929 -0.0927 -0.9589 -0.1846 -0.6720 -0.1227 -0.1893 -0.2293 -0.1027\n",
            "S-2714\tI &apos;m a lawyer brand .\n",
            "T-2714\tLuật sư : Tôi là người có phong cách luật sư .\n",
            "H-2714\t-0.3760035037994385\tTôi là một công ty luật sư .\n",
            "D-2714\t-0.3760035037994385\tTôi là một công ty luật sư .\n",
            "P-2714\t-0.1283 -0.2078 -0.5866 -2.1225 -0.0478 -0.0134 -0.0030 -0.1757 -0.0989\n",
            "S-2336\tYou can be logical and intuitive .\n",
            "T-2336\tCùng một lúc bạn có thể tuân theo vừa logic vừa trực giác\n",
            "H-2336\t-0.3153555393218994\tBạn có thể rất logic và trực quan .\n",
            "D-2336\t-0.3153555393218994\tBạn có thể rất logic và trực quan .\n",
            "P-2336\t-0.3134 -0.1733 -0.0882 -1.6910 -0.1355 -0.2129 -0.0187 -0.1655 -0.2552 -0.0998\n",
            "S-1703\tWe certainly need one to succeed .\n",
            "T-1703\tChúng ta chắc chắn cần một cái gì đó để thành công .\n",
            "H-1703\t-0.2978264391422272\tChúng ta chắc chắn cần một để thành công .\n",
            "D-1703\t-0.2978264391422272\tChúng ta chắc chắn cần một để thành công .\n",
            "P-1703\t-0.6120 -0.3282 -0.1587 -0.0676 -0.3813 -0.5306 -0.7979 -0.0437 -0.0416 -0.2075 -0.1069\n",
            "S-3611\tNo had never been an option .\n",
            "T-3611\tNói &apos; không &apos; chưa bao giờ là một lựa chọn .\n",
            "H-3611\t-0.3186574876308441\tKhông bao giờ là một lựa chọn .\n",
            "D-3611\t-0.3186574876308441\tKhông bao giờ là một lựa chọn .\n",
            "P-3611\t-0.4363 -0.2812 -0.0457 -0.4799 -0.4110 -0.4994 -0.0759 -0.5352 -0.1034\n",
            "S-6654\tBut my daughter never complained .\n",
            "T-6654\tNhưng con gái tôi không bao giờ phàn nàn .\n",
            "H-6654\t-0.21507970988750458\tNhưng con gái tôi không bao giờ than phiền .\n",
            "D-6654\t-0.21507970988750458\tNhưng con gái tôi không bao giờ than phiền .\n",
            "P-6654\t-0.1171 -0.0649 -0.0058 -0.2741 -1.2527 -0.0262 -0.0470 -0.0352 -0.0472 -0.3914 -0.1042\n",
            "S-5706\tNot everybody gets to do that .\n",
            "T-5706\tKhông phải ai cũng có cơ hội để làm điều này .\n",
            "H-5706\t-0.5706812739372253\tKhông phải ai cũng có thể làm điều đó .\n",
            "D-5706\t-0.5706812739372253\tKhông phải ai cũng có thể làm điều đó .\n",
            "P-5706\t-0.3414 -0.0352 -0.4992 -0.0247 -3.2451 -0.1684 -0.1796 -1.1035 -0.2669 -0.3065 -0.1069\n",
            "S-5031\tThis is happening to us today .\n",
            "T-5031\tĐiều này đang diễn ra với chúng ta ngày hôm nay .\n",
            "H-5031\t-0.31901612877845764\tĐiều này đang xảy ra với chúng ta ngày hôm nay .\n",
            "D-5031\t-0.31901612877845764\tĐiều này đang xảy ra với chúng ta ngày hôm nay .\n",
            "P-5031\t-0.4588 -0.2962 -0.6579 -0.4181 -0.5043 -0.1768 -0.1005 -0.2260 -0.2471 -0.6080 -0.0512 -0.3043 -0.0980\n",
            "S-4890\tWe asked around and nobody knew .\n",
            "T-4890\tChúng tôi đã hỏi xung quanh và không ai biết cả .\n",
            "H-4890\t-0.519586980342865\tChúng tôi hỏi và không ai biết .\n",
            "D-4890\t-0.519586980342865\tChúng tôi hỏi và không ai biết .\n",
            "P-4890\t-0.2658 -0.2044 -0.7861 -1.5793 -0.3151 -0.0760 -0.1036 -1.2438 -0.1023\n",
            "S-4010\tBut it &apos;s not documented .\n",
            "T-4010\tNhưng điều này không được ghi nhận lại bằng tài liệu .\n",
            "H-4010\t-0.4154142737388611\tNhưng nó không phải là tài liệu .\n",
            "D-4010\t-0.4154142737388611\tNhưng nó không phải là tài liệu .\n",
            "P-4010\t-0.2046 -0.8592 -0.2190 -1.0414 -0.3651 -0.6016 -0.0073 -0.3387 -0.1020\n",
            "S-3769\tI represent people on death row .\n",
            "T-3769\tTôi xin lên tiếng làm đại diện cho những người tử tù\n",
            "H-3769\t-0.22192765772342682\tTôi đại diện cho mọi người về cái chết .\n",
            "D-3769\t-0.22192765772342682\tTôi đại diện cho mọi người về cái chết .\n",
            "P-3769\t-0.1495 -0.0895 -0.0144 -0.0230 -0.4962 -0.0733 -0.2742 -0.6680 -0.2692 -0.2754 -0.1084\n",
            "S-3768\tThe only country in the world .\n",
            "T-3768\tvà là nước duy nhất trên thế giới làm điều này .\n",
            "H-3768\t-0.14414949715137482\tĐất nước duy nhất trên thế giới .\n",
            "D-3768\t-0.14414949715137482\tĐất nước duy nhất trên thế giới .\n",
            "P-3768\t-0.4892 -0.0108 -0.0257 -0.0292 -0.2125 -0.0438 -0.0466 -0.3294 -0.1101\n",
            "S-3635\tLife hadn &apos;t changed for centuries .\n",
            "T-3635\tCuộc sống đã là như vậy trong hàng thế kỷ rồi .\n",
            "H-3635\t-0.3667864203453064\tCuộc sống đã không thay đổi trong nhiều thế kỉ .\n",
            "D-3635\t-0.3667864203453064\tCuộc sống đã không thay đổi trong nhiều thế kỉ .\n",
            "P-3635\t-0.1392 -0.0793 -0.7106 -0.0807 -0.1949 -0.0382 -1.7563 -0.1397 -0.0366 -0.7932 -0.3324 -0.1005\n",
            " 10% 6/60 [00:11<01:50,  2.05s/it, wps=536]S-3096\tAnd then some very funny things happened .\n",
            "T-3096\tVà có vài chuyện rất thú vị đã xảy ra .\n",
            "H-3096\t-0.610900342464447\tVà một vài điều rất thú vị đã xảy ra .\n",
            "D-3096\t-0.610900342464447\tVà một vài điều rất thú vị đã xảy ra .\n",
            "P-3096\t-0.4970 -0.9836 -0.9033 -0.4390 -0.8699 -2.2876 -0.0324 -0.6588 -0.1865 -0.0835 -0.2909 -0.0984\n",
            "S-5561\tBut it is not only about me .\n",
            "T-5561\tNhưng những thông tin đó không chỉ nói về tôi .\n",
            "H-5561\t-0.5098928809165955\tNhưng nó không chỉ là về tôi .\n",
            "D-5561\t-0.5098928809165955\tNhưng nó không chỉ là về tôi .\n",
            "P-5561\t-0.2574 -1.5321 -0.1151 -0.1429 -1.3299 -0.7213 -0.1357 -0.2460 -0.1087\n",
            "S-5559\tAll this is possible with this information .\n",
            "T-5559\tTất cả đều có thể với những thông tin này .\n",
            "H-5559\t-0.46756497025489807\tTất cả điều này là khả thi với thông tin này .\n",
            "D-5559\t-0.46756497025489807\tTất cả điều này là khả thi với thông tin này .\n",
            "P-5559\t-0.8491 -0.0436 -1.2997 -0.2680 -1.0307 -1.2768 -0.0530 -0.2958 -0.1045 -0.0530 -0.4362 -0.2680 -0.1001\n",
            "S-5522\tWho sends whom a text message ?\n",
            "T-5522\tAi đã gửi cho ai những tin nhắn di động ?\n",
            "H-5522\t-0.46791303157806396\tAi gửi tin nhắn một tin nhắn ?\n",
            "D-5522\t-0.46791303157806396\tAi gửi tin nhắn một tin nhắn ?\n",
            "P-5522\t-0.0188 -0.0213 -0.7369 -0.0027 -2.9758 -0.0407 -0.0339 -0.2744 -0.1067\n",
            "S-5441\tA morning that I will never forget .\n",
            "T-5441\tMột buổi sáng mà tôi không thể nào quên được .\n",
            "H-5441\t-0.22942760586738586\tMột buổi sáng mà tôi sẽ không bao giờ quên .\n",
            "D-5441\t-0.22942760586738586\tMột buổi sáng mà tôi sẽ không bao giờ quên .\n",
            "P-5441\t-0.4478 -0.6460 -0.0110 -0.6901 -0.1588 -0.1716 -0.1190 -0.0204 -0.0572 -0.0135 -0.3107 -0.1069\n",
            "S-5375\tAbuse thrives only in silence .\n",
            "T-5375\tSự ngược đãi chỉ đáng sợ trong im lặng .\n",
            "H-5375\t-0.5834655165672302\tSử dụng sự phát triển duy nhất trong im lặng .\n",
            "D-5375\t-0.5834655165672302\tSử dụng sự phát triển duy nhất trong im lặng .\n",
            "P-5375\t-2.2783 -1.1641 -0.0032 -0.8232 -0.5502 -0.2002 -1.4423 -0.0382 -0.5340 -0.1720 -0.0044 -0.2699 -0.1050\n",
            "S-5188\tToday I have just one request .\n",
            "T-5188\tHôm nay tôi chỉ có một yêu cầu mà thôi .\n",
            "H-5188\t-0.39915019273757935\tHôm nay tôi chỉ có một yêu cầu .\n",
            "D-5188\t-0.39915019273757935\tHôm nay tôi chỉ có một yêu cầu .\n",
            "P-5188\t-0.3346 -0.0516 -0.2426 -0.8362 -1.0701 -0.2851 -0.2793 -0.0519 -0.7382 -0.1020\n",
            "S-4987\tLet me show you how they work .\n",
            "T-4987\tĐể tôi cho bạn thấy chúng hoạt động ra sao .\n",
            "H-4987\t-0.508812665939331\tĐể tôi cho các bạn thấy chúng hoạt động thế nào .\n",
            "D-4987\t-0.508812665939331\tĐể tôi cho các bạn thấy chúng hoạt động thế nào .\n",
            "P-4987\t-0.1629 -0.0954 -0.9616 -0.6591 -0.0713 -0.5640 -1.0658 -0.6498 -0.0353 -1.8363 -0.0579 -0.3563 -0.0986\n",
            "S-4917\tBut it has an unexpected twist .\n",
            "T-4917\tNhưng nó có một khúc ngoặt không mong muốn .\n",
            "H-4917\t-0.4822981357574463\tNhưng nó có một bước tiến bất ngờ .\n",
            "D-4917\t-0.4822981357574463\tNhưng nó có một bước tiến bất ngờ .\n",
            "P-4917\t-0.2060 -0.4080 -0.4270 -0.3564 -1.4736 -1.2961 -0.1978 -0.0075 -0.3409 -0.1097\n",
            "S-4896\tAnd we built an iPad application .\n",
            "T-4896\tVà chúng tôi xây dựng một ứng dụng trên iPad\n",
            "H-4896\t-0.3420390784740448\tVà chúng tôi xây dựng một ứng dụng iPad .\n",
            "D-4896\t-0.3420390784740448\tVà chúng tôi xây dựng một ứng dụng iPad .\n",
            "P-4896\t-0.6615 -0.1030 -0.1210 -2.1802 -0.2181 -0.3180 -0.0433 -0.0171 -0.0256 -0.0049 -0.3148 -0.0969\n",
            "S-4579\tThat &apos;s about all it can do .\n",
            "T-4579\tĐó là tất cả những gì có thể xảy ra .\n",
            "H-4579\t-0.49536871910095215\tĐó là về tất cả những gì nó có thể làm .\n",
            "D-4579\t-0.49536871910095215\tĐó là về tất cả những gì nó có thể làm .\n",
            "P-4579\t-0.3929 -0.2100 -1.3076 -0.7872 -0.0598 -0.3612 -1.1527 -1.4533 -0.1622 -0.0721 -0.1582 -0.2235 -0.0991\n",
            "S-4373\tI don &apos;t take the same history .\n",
            "T-4373\tTôi không áp dụng cùng một tiền sử bệnh nữa .\n",
            "H-4373\t-0.5684888362884521\tTôi không lấy cùng một lịch sử .\n",
            "D-4373\t-0.5684888362884521\tTôi không lấy cùng một lịch sử .\n",
            "P-4373\t-0.1683 -0.2196 -1.3232 -2.3866 -0.4071 -0.0768 -0.0631 -0.3619 -0.1098\n",
            "S-4370\tWe can &apos;t get rid of it .\n",
            "T-4370\tTa không thể tống khứ vấn đề này được .\n",
            "H-4370\t-0.42056146264076233\tChúng ta không thể loại bỏ nó .\n",
            "D-4370\t-0.42056146264076233\tChúng ta không thể loại bỏ nó .\n",
            "P-4370\t-0.3018 -0.3223 -0.1372 -0.0965 -1.9386 -0.0287 -0.4963 -0.3626 -0.1010\n",
            "S-4162\tNow it turns out you &apos;re right .\n",
            "T-4162\tBây giờ , nó chỉ ra rằng bạn đã đúng .\n",
            "H-4162\t-0.5143337845802307\tHoá ra bạn đúng .\n",
            "D-4162\t-0.5143337845802307\tHoá ra bạn đúng .\n",
            "P-4162\t-0.8252 -0.0969 -0.4304 -1.2560 -0.3741 -0.1034\n",
            "S-3518\tI &apos;m not sure where we go .\n",
            "T-3518\tTôi cũng không chắc chúng ta đang đi đến đâu .\n",
            "H-3518\t-0.41349270939826965\tTôi không chắc chúng ta sẽ đi đến đâu .\n",
            "D-3518\t-0.41349270939826965\tTôi không chắc chúng ta sẽ đi đến đâu .\n",
            "P-3518\t-0.1760 -0.1848 -0.1212 -0.6208 -0.3165 -0.8943 -0.3940 -1.3365 -0.0588 -0.3417 -0.1037\n",
            "S-3476\tAnd women successfully argued that .\n",
            "T-3476\tVà nữ giới đã thành công với lý lẽ đó .\n",
            "H-3476\t-0.404385507106781\tVà phụ nữ đã hoàn toàn tranh luận điều đó .\n",
            "D-3476\t-0.404385507106781\tVà phụ nữ đã hoàn toàn tranh luận điều đó .\n",
            "P-3476\t-0.4089 -0.3649 -0.0491 -0.3660 -1.5952 -0.2743 -0.2287 -0.3192 -0.6773 -0.2676 -0.1962 -0.1053\n",
            "S-6078\tThe first principle of aid is respect .\n",
            "T-6078\tNguyên tắc đầu tiên về viện trợ là tôn trọng .\n",
            "H-6078\t-0.2785404622554779\tNguyên tắc viện trợ đầu tiên là sự tôn trọng .\n",
            "D-6078\t-0.2785404622554779\tNguyên tắc viện trợ đầu tiên là sự tôn trọng .\n",
            "P-6078\t-0.0490 -0.5310 -0.9355 -0.0082 -0.0543 -0.0374 -0.2652 -1.1047 -0.0210 -0.0054 -0.2272 -0.1034\n",
            "S-3046\tSo let &apos;s start with Sunday .\n",
            "T-3046\tVậy thì chúng ta cùng bắt đầu với Chủ Nhật .\n",
            "H-3046\t-0.35853153467178345\tHãy bắt đầu với chủ nhật .\n",
            "D-3046\t-0.35853153467178345\tHãy bắt đầu với chủ nhật .\n",
            "P-3046\t-2.0039 -0.1033 -0.0875 -0.2044 -0.0618 -0.0498 -0.2487 -0.1088\n",
            "S-2433\tAnd you know what I &apos;ve learned ?\n",
            "T-2433\tVà các bạn có biết tôi học được gì không ?\n",
            "H-2433\t-0.5112069845199585\tVà bạn biết tôi đã học được gì không ?\n",
            "D-2433\t-0.5112069845199585\tVà bạn biết tôi đã học được gì không ?\n",
            "P-2433\t-0.6070 -0.7178 -0.6766 -0.5051 -0.5011 -0.0557 -0.3128 -0.7551 -1.2926 -0.0992 -0.1002\n",
            "S-2121\tThat &apos;s usually not the route .\n",
            "T-2121\tVà thường thì đó không phải là lộ trình đâu .\n",
            "H-2121\t-0.5537413954734802\tĐó thường không phải là con đường .\n",
            "D-2121\t-0.5537413954734802\tĐó thường không phải là con đường .\n",
            "P-2121\t-1.2625 -0.1900 -0.7161 -0.0643 -0.1584 -1.4204 -0.0196 -1.0421 -0.1103\n",
            "S-1777\tAnd let me begin with one example .\n",
            "T-1777\tVà hãy để tôi bắt đầu với một ví dụ .\n",
            "H-1777\t-0.35223421454429626\tĐể tôi bắt đầu với một ví dụ .\n",
            "D-1777\t-0.35223421454429626\tĐể tôi bắt đầu với một ví dụ .\n",
            "P-1777\t-2.0513 -0.1302 -0.0607 -0.0609 -0.2275 -0.5251 -0.0298 -0.0595 -0.2754 -0.1019\n",
            "S-1306\tNow , that blew my mind .\n",
            "T-1306\tĐiều đó đã làm tôi cực kỳ hưng phấn .\n",
            "H-1306\t-0.7617468237876892\tBây giờ , nó làm tôi bực mình .\n",
            "D-1306\t-0.7617468237876892\tBây giờ , nó làm tôi bực mình .\n",
            "P-1306\t-2.4596 -0.0593 -0.2793 -2.6137 -0.5474 -0.0879 -1.9002 -0.0401 -0.0109 -0.2758 -0.1051\n",
            "S-940\tSo with that , I thank you .\n",
            "T-940\tXin cảm ơn quý vị đã chú ý lắng nghe .\n",
            "H-940\t-0.5446038246154785\tVới điều đó , tôi xin cảm ơn .\n",
            "D-940\t-0.5446038246154785\tVới điều đó , tôi xin cảm ơn .\n",
            "P-940\t-1.8800 -0.3488 -0.3704 -0.1415 -0.5640 -0.9483 -0.1752 -0.1138 -0.8045 -0.0996\n",
            "S-880\tAnd that can make a big difference .\n",
            "T-880\tVà điều đó có thể tạo ra sự khác biệt .\n",
            "H-880\t-0.37194201350212097\tVà điều đó có thể tạo nên sự khác biệt lớn .\n",
            "D-880\t-0.37194201350212097\tVà điều đó có thể tạo nên sự khác biệt lớn .\n",
            "P-880\t-0.6779 -1.1390 -0.3750 -0.2016 -0.1081 -0.5571 -0.4845 -0.6943 -0.1254 -0.0130 -0.1690 -0.1869 -0.1034\n",
            "S-478\tThese are cell phones of the future .\n",
            "T-478\tĐây là những điện thoại di động của tương lai .\n",
            "H-478\t-0.2174873650074005\tĐây là điện thoại di động của tương lai .\n",
            "D-478\t-0.2174873650074005\tĐây là điện thoại di động của tương lai .\n",
            "P-478\t-0.3631 -0.1196 -0.6942 -0.0086 -0.0160 -0.0144 -0.6898 -0.0462 -0.0443 -0.2938 -0.1023\n",
            "S-202\tYou probably saw it on the news .\n",
            "T-202\tCó thể các bạn đã xem tin đó trên báo .\n",
            "H-202\t-0.6131079792976379\tBạn có thể thấy nó trên tin tức .\n",
            "D-202\t-0.6131079792976379\tBạn có thể thấy nó trên tin tức .\n",
            "P-202\t-1.5894 -0.2264 -0.3775 -0.4070 -1.5424 -0.0897 -1.2740 -0.1497 -0.3705 -0.1045\n",
            "S-172\tThese flows are increasing very rapidly .\n",
            "T-172\tNhững dòng chảy này đang ngày càng tăng nhanh hơn .\n",
            "H-172\t-0.2746813893318176\tNhững dòng này đang tăng lên rất nhanh .\n",
            "D-172\t-0.2746813893318176\tNhững dòng này đang tăng lên rất nhanh .\n",
            "P-172\t-0.4016 -0.1442 -0.5617 -0.1592 -0.2818 -0.5929 -0.1260 -0.0083 -0.3715 -0.0996\n",
            "S-149\tOur magazines are read by millions .\n",
            "T-149\tHàng triệu người đón đọc tạp chí của chúng tôi .\n",
            "H-149\t-0.38628333806991577\tCác tạp chí của chúng tôi được đọc bởi hàng triệu .\n",
            "D-149\t-0.38628333806991577\tCác tạp chí của chúng tôi được đọc bởi hàng triệu .\n",
            "P-149\t-1.0037 -0.0030 -0.0102 -0.7014 -0.0778 -0.7259 -0.8199 -0.2006 -0.1300 -0.0493 -0.0453 -1.1554 -0.0993\n",
            "S-7267\tThese are not trivial activities .\n",
            "T-7267\tĐó không phải là các hoạt động tầm thường .\n",
            "H-7267\t-0.5340707302093506\tĐây không phải là hoạt động bình thường .\n",
            "D-7267\t-0.5340707302093506\tĐây không phải là hoạt động bình thường .\n",
            "P-7267\t-0.3685 -0.1045 -0.0386 -0.3560 -1.0039 -0.0200 -3.0467 -0.0079 -0.2951 -0.0996\n",
            "S-6994\tBut what if you are that person ?\n",
            "T-6994\tNhưng nếu bạn là những người đó thì sao ?\n",
            "H-6994\t-0.3960191607475281\tNhưng nếu bạn là người đó ?\n",
            "D-6994\t-0.3960191607475281\tNhưng nếu bạn là người đó ?\n",
            "P-6994\t-0.1607 -1.0148 -0.2941 -0.1878 -0.5537 -0.1818 -0.6717 -0.1036\n",
            "S-6851\tThere is help . There is hope .\n",
            "T-6851\tCó sự nâng đỡ . Có niềm hy vọng .\n",
            "H-6851\t-0.4750961661338806\tCó sự giúp đỡ . Có hy vọng .\n",
            "D-6851\t-0.4750961661338806\tCó sự giúp đỡ . Có hy vọng .\n",
            "P-6851\t-1.7354 -0.2688 -0.1965 -0.1440 -0.1815 -1.6358 -0.2561 -0.0363 -0.2030 -0.0935\n",
            "S-6817\tHe said , &quot; You listened .\n",
            "T-6817\tKevin đáp : &quot; Vì chú chịu nghe cháu .\n",
            "H-6817\t-0.7958647608757019\tAnh ta nói , &quot; Các bạn nghe .\n",
            "D-6817\t-0.7958647608757019\tAnh ta nói , &quot; Các bạn nghe .\n",
            "P-6817\t-1.3958 -0.8892 -0.6932 -1.0958 -0.0951 -1.5707 -0.4691 -0.6274 -0.9391 -0.1834\n",
            "S-4294\tShe had irreversible brain damage .\n",
            "T-4294\tNão bà bị huỷ hoại không thể thay đổi được .\n",
            "H-4294\t-0.42424771189689636\tCô ấy bị tổn thương não .\n",
            "D-4294\t-0.42424771189689636\tCô ấy bị tổn thương não .\n",
            "P-4294\t-0.8805 -0.7592 -0.1651 -0.1703 -0.0221 -0.3436 -0.9543 -0.0989\n",
            "S-3936\tWell there are opportunities all around us .\n",
            "T-3936\tÀ , Luôn có nhiều cơ hội xung quanh chúng ta .\n",
            "H-3936\t-0.4247738718986511\tCó những cơ hội xung quanh chúng ta .\n",
            "D-3936\t-0.4247738718986511\tCó những cơ hội xung quanh chúng ta .\n",
            "P-3936\t-1.0413 -1.1561 -0.0061 -0.0345 -0.9083 -0.0113 -0.3640 -0.2536 -0.3746 -0.0980\n",
            "S-3517\tDo we really want to go there ?\n",
            "T-3517\tChúng ta có thực sự muốn đi xa đến mức đó không ?\n",
            "H-3517\t-0.37572765350341797\tLiệu chúng ta có thực sự muốn đến đó không ?\n",
            "D-3517\t-0.37572765350341797\tLiệu chúng ta có thực sự muốn đến đó không ?\n",
            "P-3517\t-0.4023 -0.2987 -0.1660 -0.1366 -0.6385 -0.0479 -0.0624 -1.6068 -0.5653 -0.4014 -0.0855 -0.0974\n",
            "S-3231\tIt &apos;s morning , before the match .\n",
            "T-3231\tĐó là vào buổi sáng , trước khi trận đấu bắt đầu .\n",
            "H-3231\t-0.6323803067207336\tVào buổi sáng , trước khi trùng khớp .\n",
            "D-3231\t-0.6323803067207336\tVào buổi sáng , trước khi trùng khớp .\n",
            "P-3231\t-1.9851 -0.2097 -0.0092 -0.5926 -0.1035 -0.4382 -2.6517 -0.0507 -0.1776 -0.1055\n",
            "S-2288\tYou see some fun stuff happening here .\n",
            "T-2288\tBạn có thể thấy một vài điều thú vị đang diễn ra .\n",
            "H-2288\t-0.5460598468780518\tBạn thấy một số thứ thú vị đang diễn ra ở đây .\n",
            "D-2288\t-0.5460598468780518\tBạn thấy một số thứ thú vị đang diễn ra ở đây .\n",
            "P-2288\t-0.6324 -0.4300 -1.2430 -1.0312 -0.3424 -1.6513 -0.0122 -0.5735 -0.7599 -0.0496 -0.3641 -0.1168 -0.3439 -0.0946\n",
            "S-1736\tThe disaster is for that two billion .\n",
            "T-1736\tThảm hoạ xảy đến cho 2 tỷ người nghèo đói kia .\n",
            "H-1736\t-0.9761290550231934\tThảm hoạ là hai tỉ .\n",
            "D-1736\t-0.9761290550231934\tThảm hoạ là hai tỉ .\n",
            "P-1736\t-1.6635 -1.1087 -0.0130 -1.3926 -2.2303 -0.8092 -0.4932 -0.0985\n",
            "S-1170\tPeople were suffering . People were fighting .\n",
            "T-1170\tMọi người đang vật lộn . Mọi người đang chống chọi .\n",
            "H-1170\t-0.5664204359054565\tMọi người phải chịu đựng . Mọi người đang chiến đấu .\n",
            "D-1170\t-0.5664204359054565\tMọi người phải chịu đựng . Mọi người đang chiến đấu .\n",
            "P-1170\t-0.8477 -0.0625 -3.5123 -0.0859 -0.2191 -0.3644 -0.3684 -0.0552 -1.0792 -0.4447 -0.0372 -0.1817 -0.1050\n",
            "S-219\tSo don &apos;t worry about climate change .\n",
            "T-219\tDo vậy bạn đừng lo lắng quá về biến đổi khí hậu .\n",
            "H-219\t-0.4371417164802551\tVì vậy đừng lo về biến đổi khí hậu .\n",
            "D-219\t-0.4371417164802551\tVì vậy đừng lo về biến đổi khí hậu .\n",
            "P-219\t-1.9170 -0.8121 -0.6797 -0.2089 -0.1934 -0.5367 -0.0277 -0.0036 -0.0265 -0.3034 -0.0995\n",
            "S-148\t156 nations carry our television channel .\n",
            "T-148\t156 quốc gia tiếp sóng kênh truyền hình của chúng tôi .\n",
            "H-148\t-0.33758822083473206\t15 quốc gia mang kênh truyền hình của chúng tôi .\n",
            "D-148\t-0.33758822083473206\t15 quốc gia mang kênh truyền hình của chúng tôi .\n",
            "P-148\t-1.1143 -0.0137 -0.0609 -0.0812 -0.7196 -0.0090 -0.0060 -0.9439 -0.3679 -0.2083 -0.4330 -0.0931\n",
            "S-7385\tIn 1997 , this building opened .\n",
            "T-7385\tVào năm 1997 , toà nhà này khai trương .\n",
            "H-7385\t-0.3660553991794586\tVào năm 1997 , toà nhà này được mở .\n",
            "D-7385\t-0.3660553991794586\tVào năm 1997 , toà nhà này được mở .\n",
            "P-7385\t-1.1285 -0.0352 -0.0094 -0.0078 -0.1403 -0.0676 -0.0501 -0.2128 -1.7168 -0.2052 -0.7181 -0.1008\n",
            "S-7202\tIt &apos;s there right at its heart .\n",
            "T-7202\tNo ́ thư ̣ c sư ̣ đang ơ <<unk>> đo ́\n",
            "H-7202\t-0.7066566944122314\tNó ở ngay đó .\n",
            "D-7202\t-0.7066566944122314\tNó ở ngay đó .\n",
            "P-7202\t-0.4276 -0.8287 -0.0722 -1.9627 -0.8400 -0.1087\n",
            "S-6824\tKevin is straight , as he says .\n",
            "T-6824\tKevin không phải là người đồng tính như nó đã nói .\n",
            "H-6824\t-0.6125162839889526\tKevin là thẳng , như anh ta đã nói .\n",
            "D-6824\t-0.6125162839889526\tKevin là thẳng , như anh ta đã nói .\n",
            "P-6824\t-0.0306 -1.7677 -0.1054 -0.6121 -0.3316 -0.8987 -1.1706 -1.3038 -0.1153 -0.3007 -0.1013\n",
            "S-6704\tThat was all I needed to hear .\n",
            "T-6704\tĐó là tất cả những gì mà tôi hằng mong ước .\n",
            "H-6704\t-0.22608202695846558\tĐó là tất cả những gì tôi cần nghe .\n",
            "D-6704\t-0.22608202695846558\tĐó là tất cả những gì tôi cần nghe .\n",
            "P-6704\t-0.1701 -0.2607 -0.3892 -0.0581 -0.1488 -0.1064 -0.2575 -0.2085 -0.4974 -0.2817 -0.1084\n",
            "S-6096\tThere is a problem with community meetings .\n",
            "T-6096\tCó một vần đề trong những cuộc họp cộng đồng .\n",
            "H-6096\t-0.4793473780155182\tCó một vấn đề với các cuộc gặp gỡ cộng đồng .\n",
            "D-6096\t-0.4793473780155182\tCó một vấn đề với các cuộc gặp gỡ cộng đồng .\n",
            "P-6096\t-0.6588 -0.4994 -0.0762 -0.0743 -0.7504 -0.8701 -0.0508 -1.7918 -0.5172 -0.3535 -0.0180 -0.4707 -0.1004\n",
            "S-5133\tShe &apos;s not North Korean . &quot;\n",
            "T-5133\tNó không phải là người Bắc Triều Tiên . &quot;\n",
            "H-5133\t-0.29939305782318115\tCô ấy không phải Bắc Triều Tiên . &quot;\n",
            "D-5133\t-0.29939305782318115\tCô ấy không phải Bắc Triều Tiên . &quot;\n",
            "P-5133\t-1.0346 -0.5706 -0.1526 -0.1476 -0.6502 -0.0150 -0.0099 -0.0887 -0.0207 -0.6192 -0.1912 -0.0924\n",
            "S-4706\tThey &apos;re obscure , weird programs .\n",
            "T-4706\tChúng là những chương trình rất mơ hồ và kì quặc .\n",
            "H-4706\t-0.5241031646728516\tChúng bị ám ảnh , các chương trình kì lạ .\n",
            "D-4706\t-0.5241031646728516\tChúng bị ám ảnh , các chương trình kì lạ .\n",
            "P-4706\t-0.6362 -1.9867 -0.3090 -0.0152 -0.4069 -1.4348 -0.0405 -0.0986 -0.7416 -0.1802 -0.3431 -0.0963\n",
            "S-6679\tI knew then how to self-identify .\n",
            "T-6679\tLúc ấy , tôi đã biết mình là ai .\n",
            "H-6679\t-0.6447221040725708\tTôi biết cách tự nhận diện .\n",
            "D-6679\t-0.6447221040725708\tTôi biết cách tự nhận diện .\n",
            "P-6679\t-1.1238 -0.3464 -1.9728 -0.3479 -0.0713 -0.6897 -0.5057 -0.1001\n",
            "S-3744\tToday , there are 2.3 million .\n",
            "T-3744\tNgày nay , con số đó đã lên đến 2,3 triệu\n",
            "H-3744\t-0.2380131334066391\tNgày nay , có 2.3 triệu .\n",
            "D-3744\t-0.2380131334066391\tNgày nay , có 2.3 triệu .\n",
            "P-3744\t-0.3498 -0.0690 -0.2861 -0.2995 -0.3887 -0.0039 -0.0668 -0.5790 -0.0992\n",
            "S-2012\tI &apos;m an expert in relationships . &quot;\n",
            "T-2012\tTôi là một chuyên gia về các mối quan hệ . &quot;\n",
            "H-2012\t-0.3399275541305542\tTôi là chuyên gia trong các mối quan hệ . &quot;\n",
            "D-2012\t-0.3399275541305542\tTôi là chuyên gia trong các mối quan hệ . &quot;\n",
            "P-2012\t-0.1711 -0.1897 -0.4656 -0.0027 -1.1605 -1.1555 -0.2239 -0.0150 -0.0173 -0.4196 -0.1594 -0.0990\n",
            "S-1644\tWhat should our report card look like ?\n",
            "T-1644\tBảng báo cáo chính mình sẽ nên ra làm sao ?\n",
            "H-1644\t-0.41495281457901\tBáo cáo của chúng ta nên trông như thế nào ?\n",
            "D-1644\t-0.41495281457901\tBáo cáo của chúng ta nên trông như thế nào ?\n",
            "P-1644\t-0.6944 -0.9164 -0.0340 -0.3172 -0.2819 -0.8905 -0.3240 -1.3334 -0.2341 -0.0498 -0.0691 -0.1459 -0.1036\n",
            "S-556\tEverybody in my Manhattan neighborhood is away .\n",
            "T-556\tLáng giềng ở khu Manhattan đã đi hết .\n",
            "H-556\t-0.670790433883667\tMọi người ở khu phố Manhattan đều xa .\n",
            "D-556\t-0.670790433883667\tMọi người ở khu phố Manhattan đều xa .\n",
            "P-556\t-1.0195 -0.0929 -0.8205 -0.5857 -0.3168 -0.0466 -0.8014 -2.4640 -0.4561 -0.1044\n",
            "S-510\tAll of these are consuming questions .\n",
            "T-510\tTất cả đều là câu hỏi hao mòn đầu óc .\n",
            "H-510\t-0.2623441815376282\tTất cả đều là những câu hỏi tiêu thụ .\n",
            "D-510\t-0.2623441815376282\tTất cả đều là những câu hỏi tiêu thụ .\n",
            "P-510\t-0.2602 -0.0587 -0.7956 -0.4261 -0.5657 -0.0777 -0.0314 -0.1116 -0.2240 -0.2362 -0.0988\n",
            "S-4\tWe go through initiation rites .\n",
            "T-4\tChúng ta cùng phải trải qua những nghi lễ đầu đời .\n",
            "H-4\t-0.7117007970809937\tChúng ta trải qua những nghi thức bắt đầu .\n",
            "D-4\t-0.7117007970809937\tChúng ta trải qua những nghi thức bắt đầu .\n",
            "P-4\t-0.3003 -0.3234 -2.9778 -0.1137 -0.8048 -0.0513 -0.4288 -2.2509 -0.1809 -0.2948 -0.1021\n",
            "S-7147\tSo I go in a different direction .\n",
            "T-7147\tVà tôi sẽ đi tiếp vào một luận điểm mới .\n",
            "H-7147\t-0.46662673354148865\tVì vậy tôi đi theo một hướng khác .\n",
            "D-7147\t-0.46662673354148865\tVì vậy tôi đi theo một hướng khác .\n",
            "P-7147\t-2.0559 -0.7894 -0.3903 -0.3136 -0.0738 -0.2313 -0.0959 -0.1780 -0.4338 -0.1042\n",
            "S-6924\tThat determines good teams from bad .\n",
            "T-6924\tĐó là khác biệt giữa đội tốt và không tốt .\n",
            "H-6924\t-0.6038798689842224\tĐiều đó xác định các nhóm tốt từ xấu .\n",
            "D-6924\t-0.6038798689842224\tĐiều đó xác định các nhóm tốt từ xấu .\n",
            "P-6924\t-1.2753 -0.5037 -0.5686 -0.0172 -1.1982 -0.6277 -0.1966 -1.1482 -0.7433 -0.2612 -0.1027\n",
            "S-6923\tThe bad ones have information overload .\n",
            "T-6923\tTruyền không tốt sẽ gây quá tải thông tin .\n",
            "H-6923\t-0.4002504050731659\tNhững người xấu có thông tin quá tải .\n",
            "D-6923\t-0.4002504050731659\tNhững người xấu có thông tin quá tải .\n",
            "P-6923\t-0.1675 -1.6780 -0.2672 -0.6536 -0.2489 -0.0303 -0.2970 -0.0830 -0.4831 -0.0938\n",
            "S-6816\tAnd you know what he told me ?\n",
            "T-6816\tCác bạn có biết cậu ấy nói gì với tôi ?\n",
            "H-6816\t-0.791395366191864\tVà bạn biết anh ta nói gì với tôi ?\n",
            "D-6816\t-0.791395366191864\tVà bạn biết anh ta nói gì với tôi ?\n",
            "P-6816\t-0.5181 -0.9094 -0.6962 -2.3577 -0.9507 -1.1781 -0.3254 -0.7938 -0.0822 -0.7895 -0.1043\n",
            "S-6630\tBut we came across a new phenomenon .\n",
            "T-6630\tNhưng chúng tôi đã gặp phải một hiện tượng mới .\n",
            "H-6630\t-0.3859940767288208\tNhưng chúng tôi đã trải qua một hiện tượng mới .\n",
            "D-6630\t-0.3859940767288208\tNhưng chúng tôi đã trải qua một hiện tượng mới .\n",
            "P-6630\t-0.2720 -0.1365 -0.1720 -0.6293 -2.4343 -0.1900 -0.3734 -0.0273 -0.0127 -0.0332 -0.2498 -0.1017\n",
            "S-6498\tNever apologize for that .\n",
            "T-6498\tĐừng bao giờ cảm thấy có lỗi vì điều đó .\n",
            "H-6498\t-0.31730183959007263\tĐừng bao giờ xin lỗi vì điều đó .\n",
            "D-6498\t-0.31730183959007263\tĐừng bao giờ xin lỗi vì điều đó .\n",
            "P-6498\t-0.5934 -0.0870 -0.0290 -0.0080 -0.0023 -1.5144 -0.1207 -0.3737 -0.3387 -0.1058\n",
            "S-6377\tWe &apos;re trying to prevent an impact .\n",
            "T-6377\tChúng ta đang cố gắng ngăn chặn cuộc va chạm .\n",
            "H-6377\t-0.484805166721344\tChúng tôi đang cố ngăn chặn một tác động .\n",
            "D-6377\t-0.484805166721344\tChúng tôi đang cố ngăn chặn một tác động .\n",
            "P-6377\t-0.1539 -0.9370 -0.8897 -0.0946 -0.0736 -0.5676 -0.9590 -1.1861 -0.0451 -0.3266 -0.0995\n",
            "S-6329\tin the cold , windy night .\n",
            "T-6329\ttrong đêm tối lạnh lẽo gió sương .\n",
            "H-6329\t-0.5495235919952393\tTrong đêm lạnh , chiến thắng .\n",
            "D-6329\t-0.5495235919952393\tTrong đêm lạnh , chiến thắng .\n",
            "P-6329\t-0.7727 -0.5038 -0.0968 -0.6069 -1.8893 -0.0403 -0.3783 -0.1080\n",
            "S-6193\tSo we started retouching photos .\n",
            "T-6193\tChúng tôi bắt đầu chỉnh sửa những tấm ảnh này .\n",
            "H-6193\t-0.8776868581771851\tVì vậy chúng tôi bắt đầu tái tạo những tấm ảnh .\n",
            "D-6193\t-0.8776868581771851\tVì vậy chúng tôi bắt đầu tái tạo những tấm ảnh .\n",
            "P-6193\t-2.2304 -0.8789 -0.5415 -0.1052 -0.1164 -0.0588 -2.5415 -1.1983 -1.7616 -0.8701 -0.4194 -0.5887 -0.0991\n",
            "S-7204\tSome of these may be counterintuitive .\n",
            "T-7204\tMột vài điều có thể đi ngược lại .\n",
            "H-7204\t-0.6614872217178345\tMột vài trong số đó có thể khác thường .\n",
            "D-7204\t-0.6614872217178345\tMột vài trong số đó có thể khác thường .\n",
            "P-7204\t-0.2441 -1.1778 -0.7557 -0.2090 -0.5476 -0.5074 -0.3608 -2.2039 -0.9218 -0.2483 -0.1000\n",
            "S-2341\tAnd really you do the same thing .\n",
            "T-2341\tVà thực sự bạn làm điều y hệt thế .\n",
            "H-2341\t-0.527387261390686\tVà bạn thực sự làm điều tương tự .\n",
            "D-2341\t-0.527387261390686\tVà bạn thực sự làm điều tương tự .\n",
            "P-2341\t-0.3119 -1.0386 -1.9351 -0.0886 -0.4930 -0.8614 -0.0887 -0.0407 -0.3131 -0.1028\n",
            "S-2326\tAnd that &apos;s it . Thank you .\n",
            "T-2326\tĐó là tất cả . Cảm ơn các bạn .\n",
            "H-2326\t-0.6243356466293335\tVà đó là nó . Xin cảm ơn .\n",
            "D-2326\t-0.6243356466293335\tVà đó là nó . Xin cảm ơn .\n",
            "P-2326\t-0.7330 -1.0201 -0.7368 -2.3628 -0.2784 -0.0750 -0.6135 -0.0777 -0.2491 -0.0971\n",
            "S-2270\tYou move around , you have fun .\n",
            "T-2270\tBạn có thể đi xung quanh và tận hưởng .\n",
            "H-2270\t-0.729272723197937\tBạn di chuyển xung quanh , bạn có niềm vui .\n",
            "D-2270\t-0.729272723197937\tBạn di chuyển xung quanh , bạn có niềm vui .\n",
            "P-2270\t-0.3180 -0.0990 -0.0350 -2.0934 -0.0255 -0.5530 -0.4526 -1.5234 -2.7049 -0.0430 -0.8099 -0.0935\n",
            "S-2219\tWe went and looked at a site .\n",
            "T-2219\tChúng tôi đã đến và quan sát tại chỗ .\n",
            "H-2219\t-0.6903101205825806\tChúng tôi đi xem xét một khu vực .\n",
            "D-2219\t-0.6903101205825806\tChúng tôi đi xem xét một khu vực .\n",
            "P-2219\t-0.1381 -0.1069 -2.1495 -1.1440 -0.5297 -0.8170 -1.6761 -0.0242 -0.2121 -0.1054\n",
            "S-2087\tOne billion people will go hungry today .\n",
            "T-2087\tMột tỷ người sẽ bị đói ngày hôm nay .\n",
            "H-2087\t-0.45822712779045105\tMột tỷ người sẽ đói ngày hôm nay .\n",
            "D-2087\t-0.45822712779045105\tMột tỷ người sẽ đói ngày hôm nay .\n",
            "P-2087\t-0.5994 -0.7835 -0.0607 -0.2454 -0.8736 -0.4235 -1.2419 -0.0527 -0.1967 -0.1049\n",
            "S-2032\tThey &apos;re feasting . &quot;\n",
            "T-2032\tChúng đang tiệc tùng say sưa . &quot;\n",
            "H-2032\t-0.9908729791641235\tChúng đang làm chậm lại . &quot;\n",
            "D-2032\t-0.9908729791641235\tChúng đang làm chậm lại . &quot;\n",
            "P-2032\t-1.1708 -0.6826 -2.5479 -1.6413 -1.3963 -0.2420 -0.1502 -0.0958\n",
            "S-1673\tWe need to get the message out .\n",
            "T-1673\tChúng ta cần lấy cái thông điệp ra ngoài .\n",
            "H-1673\t-0.4986197352409363\tChúng ta cần đưa thông điệp ra .\n",
            "D-1673\t-0.4986197352409363\tChúng ta cần đưa thông điệp ra .\n",
            "P-1673\t-0.2101 -0.1838 -0.1301 -1.2854 -1.4771 -0.0270 -0.4268 -0.6387 -0.1087\n",
            "S-1250\tI could draw . I could paint .\n",
            "T-1250\tTôi có thể vẽ . Tôi có thể tô màu\n",
            "H-1250\t-0.18589025735855103\tTôi có thể vẽ . Tôi có thể vẽ .\n",
            "D-1250\t-0.18589025735855103\tTôi có thể vẽ . Tôi có thể vẽ .\n",
            "P-1250\t-0.1624 -0.2442 -0.1022 -0.0062 -0.2958 -0.2800 -0.2232 -0.0776 -0.0652 -0.4861 -0.1019\n",
            "S-1185\tNow , this sounds crazy , right ?\n",
            "T-1185\tĐiều này nghe thật điên rồ , phải không ?\n",
            "H-1185\t-0.3436746597290039\tNghe thật điên rồ phải không ?\n",
            "D-1185\t-0.3436746597290039\tNghe thật điên rồ phải không ?\n",
            "P-1185\t-0.3059 -0.9402 -0.0311 -0.4348 -0.3443 -0.0388 -0.5634 -0.0909\n",
            "S-544\tAnd there are several reasons for this .\n",
            "T-544\tVà có một vài lý do cho việc này .\n",
            "H-544\t-0.542138397693634\tVà có rất nhiều lý do cho việc này .\n",
            "D-544\t-0.542138397693634\tVà có rất nhiều lý do cho việc này .\n",
            "P-544\t-0.6711 -0.2194 -2.3262 -0.0579 -0.6314 -0.0317 -0.3672 -1.1738 -0.1126 -0.2732 -0.0993\n",
            "S-330\tWhy not think about it this way ?\n",
            "T-330\tTại sao lại không nghĩ về nó như vậy ?\n",
            "H-330\t-0.3173536956310272\tTại sao không nghĩ theo cách này ?\n",
            "D-330\t-0.3173536956310272\tTại sao không nghĩ theo cách này ?\n",
            "P-330\t-0.1047 -0.0562 -0.1822 -0.1880 -1.6688 -0.1186 -0.2993 -0.1429 -0.0955\n",
            "S-283\tI think it &apos;s odious .\n",
            "T-283\tTôi nghĩ nó thật ghê tởm .\n",
            "H-283\t-0.9059228301048279\tTôi nghĩ nó khá là oai .\n",
            "D-283\t-0.9059228301048279\tTôi nghĩ nó khá là oai .\n",
            "P-283\t-0.2003 -0.1833 -1.4923 -2.5516 -0.3468 -1.0529 -1.9807 -0.2359 -0.1095\n",
            "S-243\tWe need to go far , quickly .\n",
            "T-243\tChúng ta cần phải đi xa , nhanh chóng .\n",
            "H-243\t-0.5409701466560364\tChúng ta cần đi xa , nhanh thôi .\n",
            "D-243\t-0.5409701466560364\tChúng ta cần đi xa , nhanh thôi .\n",
            "P-243\t-0.2158 -0.1218 -0.1610 -1.0470 -0.6956 -0.6749 -1.1672 -0.9769 -0.2443 -0.1053\n",
            "S-200\tThat image reminded me of something .\n",
            "T-200\tHình ảnh này khiến tôi nghĩ tới một thứ .\n",
            "H-200\t-0.5128648281097412\tHình ảnh đó làm tôi nhớ đến một cái gì đó .\n",
            "D-200\t-0.5128648281097412\tHình ảnh đó làm tôi nhớ đến một cái gì đó .\n",
            "P-200\t-0.9857 -0.0136 -0.3463 -1.7117 -0.0985 -0.2100 -0.6409 -0.6805 -1.4030 -0.0422 -0.1133 -0.3198 -0.1017\n",
            "S-188\tThis is a completely unsustainable pattern .\n",
            "T-188\tĐây là mô hình hoàn toàn không bền vững .\n",
            "H-188\t-0.3948543071746826\tĐây là một mô hình hoàn toàn không bền vững .\n",
            "D-188\t-0.3948543071746826\tĐây là một mô hình hoàn toàn không bền vững .\n",
            "P-188\t-0.6583 -0.9305 -0.3205 -1.7377 -0.0395 -0.0959 -0.0602 -0.3167 -0.1794 -0.0130 -0.2864 -0.1002\n",
            "S-2367\tThis is a photograph of the object .\n",
            "T-2367\tĐây là một bức ảnh của vật thể này .\n",
            "H-2367\t-0.3945801258087158\tĐây là một bức ảnh của vật thể .\n",
            "D-2367\t-0.3945801258087158\tĐây là một bức ảnh của vật thể .\n",
            "P-2367\t-0.0829 -0.1149 -1.2075 -0.5563 -0.2261 -1.0712 -0.1566 -0.0721 -0.3524 -0.1057\n",
            "S-7077\tIt &apos;s an amazing multi-track movie .\n",
            "T-7077\tĐó là một bộ phim nhiều phần tuyệt vời\n",
            "H-7077\t-0.6705084443092346\tNó là một bộ phim đa dạng .\n",
            "D-7077\t-0.6705084443092346\tNó là một bộ phim đa dạng .\n",
            "P-7077\t-1.7156 -0.2432 -0.2838 -0.2578 -0.0214 -1.0322 -2.0290 -0.3475 -0.1041\n",
            "S-6944\tThey want to be their favorite player .\n",
            "T-6944\tmuốn là cầu thủ yêu thích của họ .\n",
            "H-6944\t-0.24391041696071625\tHọ muốn trở thành cầu thủ yêu thích của họ .\n",
            "D-6944\t-0.24391041696071625\tHọ muốn trở thành cầu thủ yêu thích của họ .\n",
            "P-6944\t-0.1962 -0.0781 -0.6608 -0.0627 -0.4279 -0.0206 -0.1410 -0.0254 -0.3106 -0.6613 -0.2406 -0.1018\n",
            "S-6912\tYou just go out and react .\n",
            "T-6912\tBạn chỉ cần ra đó và phản công .\n",
            "H-6912\t-0.33149755001068115\tBạn chỉ cần ra ngoài và phản ứng lại .\n",
            "D-6912\t-0.33149755001068115\tBạn chỉ cần ra ngoài và phản ứng lại .\n",
            "P-6912\t-0.6054 -0.1177 -0.2283 -0.4766 -1.0730 -0.1248 -0.1972 -0.0328 -0.4323 -0.2579 -0.1003\n",
            "S-6639\tIt &apos;s really the most scary thing .\n",
            "T-6639\tNó thực sự là điều đáng sợ nhất .\n",
            "H-6639\t-0.30795183777809143\tĐó thực sự là điều đáng sợ nhất .\n",
            "D-6639\t-0.30795183777809143\tĐó thực sự là điều đáng sợ nhất .\n",
            "P-6639\t-1.1105 -0.7442 -0.1167 -0.1102 -0.5574 -0.0610 -0.0247 -0.0700 -0.1773 -0.1074\n",
            "S-6566\tWhat would we be capable of then ?\n",
            "T-6566\tKhi đó ta sẽ có thể làm gì ?\n",
            "H-6566\t-0.47393521666526794\tChúng ta sẽ có khả năng gì ?\n",
            "D-6566\t-0.47393521666526794\tChúng ta sẽ có khả năng gì ?\n",
            "P-6566\t-1.1054 -0.0942 -1.1019 -0.6031 -0.2445 -0.0531 -0.3699 -0.5859 -0.1073\n",
            "S-6417\tThe machines would rise up against us .\n",
            "T-6417\tMáy sẽ nổi lên chống lại con người .\n",
            "H-6417\t-0.9209662079811096\tCác máy móc sẽ nổi lên với chúng ta .\n",
            "D-6417\t-0.9209662079811096\tCác máy móc sẽ nổi lên với chúng ta .\n",
            "P-6417\t-2.2429 -1.0560 -0.0692 -0.4739 -1.8199 -1.0639 -2.1364 -0.1401 -0.8003 -0.2265 -0.1014\n",
            "S-6041\tThank you so much . Thank you .\n",
            "T-6041\tCảm ơn cháu rất nhiều . Cảm ơn .\n",
            "H-6041\t-0.393729031085968\tXin cảm ơn . Xin cảm ơn .\n",
            "D-6041\t-0.393729031085968\tXin cảm ơn . Xin cảm ơn .\n",
            "P-6041\t-0.1138 -0.6167 -0.0923 -0.7224 -0.7949 -0.7544 -0.0848 -0.2652 -0.0990\n",
            "S-5751\tMy friend got to come with me .\n",
            "T-5751\tCô bạn của tôi đã đi cùng tôi .\n",
            "H-5751\t-0.6923880577087402\tBạn tôi đến với tôi .\n",
            "D-5751\t-0.6923880577087402\tBạn tôi đến với tôi .\n",
            "P-5751\t-0.1294 -0.6283 -2.6206 -0.6804 -0.2966 -0.3887 -0.1027\n",
            "S-5422\tThey are bird-blending machines .\n",
            "T-5422\tChúng là máy nghiền những chú chim .\n",
            "H-5422\t-0.501788854598999\tChúng là những cỗ máy kết thúc .\n",
            "D-5422\t-0.501788854598999\tChúng là những cỗ máy kết thúc .\n",
            "P-5422\t-1.3002 -0.1964 -0.5770 -0.8501 -0.0565 -0.7927 -0.1474 -0.4896 -0.1062\n",
            "S-5334\tAnd he was very , very sorry .\n",
            "T-5334\tvà anh ta đã vô cùng hối lỗi .\n",
            "H-5334\t-0.5752670764923096\tVà ông ấy rất xin lỗi .\n",
            "D-5334\t-0.5752670764923096\tVà ông ấy rất xin lỗi .\n",
            "P-5334\t-0.7288 -1.0061 -1.3340 -0.2346 -0.7673 -0.0244 -0.4147 -0.0922\n",
            "S-5084\tBut today , it goes beyond that .\n",
            "T-5084\tNhưng mọi chuyện không chỉ dừng ở đó .\n",
            "H-5084\t-0.6867198348045349\tNhưng hôm nay , nó vượt xa điều đó .\n",
            "D-5084\t-0.6867198348045349\tNhưng hôm nay , nó vượt xa điều đó .\n",
            "P-5084\t-0.1496 -1.2833 -0.0770 -0.1530 -0.4266 -1.3333 -1.0915 -2.4064 -0.3101 -0.2183 -0.1048\n",
            "S-5022\tSo go ahead and start inventing .\n",
            "T-5022\tHãy tiến lên và bắt đầu phát minh .\n",
            "H-5022\t-0.8498782515525818\tVậy hãy bắt đầu phát minh .\n",
            "D-5022\t-0.8498782515525818\tVậy hãy bắt đầu phát minh .\n",
            "P-5022\t-2.0040 -1.2620 -1.0728 -0.0707 -1.1226 -0.0238 -1.1440 -0.0992\n",
            "S-5007\tAnd it &apos;s been an incredible experience .\n",
            "T-5007\tVà đó là một trải nghiệm tuyệt vời .\n",
            "H-5007\t-0.4918610155582428\tĐó là một trải nghiệm đáng kinh ngạc .\n",
            "D-5007\t-0.4918610155582428\tĐó là một trải nghiệm đáng kinh ngạc .\n",
            "P-5007\t-2.2925 -0.2758 -0.2152 -0.1301 -0.0526 -1.4982 -0.0119 -0.1411 -0.1983 -0.1030\n",
            "S-4867\tAnd every morning I hop on it .\n",
            "T-4867\tVào mỗi buổi sáng tôi đứng lên cân .\n",
            "H-4867\t-0.678398847579956\tVà mỗi sáng tôi nhảy lên nó .\n",
            "D-4867\t-0.678398847579956\tVà mỗi sáng tôi nhảy lên nó .\n",
            "P-4867\t-1.3575 -0.1022 -0.1773 -0.4498 -1.5882 -0.9255 -1.0755 -0.3172 -0.1125\n",
            "S-4802\tHow do I get this removed ? &quot;\n",
            "T-4802\tLàm thế nào để xử lý nó ? &quot;\n",
            "H-4802\t-0.7207504510879517\tLàm thế nào để tôi bỏ nó đi ? &quot;\n",
            "D-4802\t-0.7207504510879517\tLàm thế nào để tôi bỏ nó đi ? &quot;\n",
            "P-4802\t-0.4794 -1.1692 -0.0802 -0.6194 -2.1200 -1.4070 -1.3291 -0.3632 -0.0965 -0.1678 -0.0965\n",
            "S-4260\tActually , I made two more mistakes .\n",
            "T-4260\tThực ra , tôi phạm 2 sai lầm nữa .\n",
            "H-4260\t-0.5960938334465027\tThực ra , tôi đã phạm phải 2 lỗi nữa .\n",
            "D-4260\t-0.5960938334465027\tThực ra , tôi đã phạm phải 2 lỗi nữa .\n",
            "P-4260\t-0.7731 -0.7608 -0.7146 -0.1650 -0.3047 -0.5137 -0.4075 -1.1524 -0.1636 -1.8620 -0.2378 -0.0979\n",
            "S-6591\tShe is no more a free individual .\n",
            "T-6591\tkhông còn có sự tự do cá nhân nữa .\n",
            "H-6591\t-0.42471376061439514\tCô ấy không còn là một cá nhân tự do nữa .\n",
            "D-6591\t-0.42471376061439514\tCô ấy không còn là một cá nhân tự do nữa .\n",
            "P-6591\t-0.9848 -0.5718 -0.1832 -0.4005 -0.4119 -0.6600 -0.0984 -0.0325 -0.7800 -0.0175 -0.9241 -0.3644 -0.0922\n",
            "S-6382\tIs there a single equation for intelligence ?\n",
            "T-6382\tCó chăng một phương trình cho trí thông minh ?\n",
            "H-6382\t-0.4355117976665497\tCó phương trình nào cho trí thông minh ?\n",
            "D-6382\t-0.4355117976665497\tCó phương trình nào cho trí thông minh ?\n",
            "P-6382\t-0.8729 -1.5517 -0.0733 -0.4876 -0.1485 -0.0432 -0.2806 -0.0285 -0.7650 -0.1038\n",
            "S-6313\tMy interpreter told me their stories .\n",
            "T-6313\tNgười phiên dịch của tôi kể chuyện của họ .\n",
            "H-6313\t-0.5708569884300232\tPhóng viên của tôi đã nói với tôi những câu chuyện của họ .\n",
            "D-6313\t-0.5708569884300232\tPhóng viên của tôi đã nói với tôi những câu chuyện của họ .\n",
            "P-6313\t-2.7354 -1.0227 -0.0650 -0.4961 -0.1102 -0.7055 -1.6850 -0.4449 -0.0970 -0.9819 -0.0426 -0.0405 -0.1860 -0.1034 -0.3141 -0.1035\n",
            "S-6216\tShe also had duplicates .\n",
            "T-6216\tCô cũng đã có bản sao của bức ảnh .\n",
            "H-6216\t-0.6521191596984863\tCô ấy cũng có những bản sao .\n",
            "D-6216\t-0.6521191596984863\tCô ấy cũng có những bản sao .\n",
            "P-6216\t-0.7958 -0.8465 -0.2734 -0.4123 -1.0429 -1.4768 -0.3167 -0.6029 -0.1019\n",
            "S-6166\tWe &apos;re pale , gray creatures .\n",
            "T-6166\tChúng tôi là những sinh vật xanh xao ,\n",
            "H-6166\t-0.20625920593738556\tChúng ta là những sinh vật màu xám .\n",
            "D-6166\t-0.20625920593738556\tChúng ta là những sinh vật màu xám .\n",
            "P-6166\t-0.1410 -0.2472 -0.0733 -0.3438 -0.1311 -0.0072 -0.7720 -0.0022 -0.2513 -0.0935\n",
            "S-6083\tWe don &apos;t work from offices .\n",
            "T-6083\tChúng tôi không làm việc từ những văn phòng .\n",
            "H-6083\t-0.33642706274986267\tChúng tôi không làm việc từ văn phòng .\n",
            "D-6083\t-0.33642706274986267\tChúng tôi không làm việc từ văn phòng .\n",
            "P-6083\t-0.2450 -1.0341 -0.1416 -0.2408 -0.0948 -0.8793 -0.2384 -0.0049 -0.3849 -0.1005\n",
            "S-5898\tIt &apos;s 150 feet by 10 feet .\n",
            "T-5898\tNó rộng hơn 3m , dài 50m .\n",
            "H-5898\t-0.6745812296867371\tĐây là 150 feet .\n",
            "D-5898\t-0.6745812296867371\tĐây là 150 feet .\n",
            "P-5898\t-2.6967 -0.1123 -0.6220 -0.1850 -0.3210 -0.1106\n",
            "S-5557\tYou can see every step I take .\n",
            "T-5557\tBạn có thể thấy từng bước đi của tôi .\n",
            "H-5557\t-0.5367493629455566\tBạn có thể thấy từng bước tôi lấy .\n",
            "D-5557\t-0.5367493629455566\tBạn có thể thấy từng bước tôi lấy .\n",
            "P-5557\t-0.3458 -0.1358 -0.0998 -0.3727 -0.3679 -0.0141 -0.4025 -3.2129 -0.3186 -0.0975\n",
            "S-5372\tI &apos;m still breaking the silence today .\n",
            "T-5372\tTôi đang đập tan sự im lặng hôm nay .\n",
            "H-5372\t-0.30786243081092834\tHôm nay tôi vẫn đang phá vỡ sự im lặng .\n",
            "D-5372\t-0.30786243081092834\tHôm nay tôi vẫn đang phá vỡ sự im lặng .\n",
            "P-5372\t-1.6253 -0.0876 -0.2634 -0.0236 -0.4421 -0.2921 -0.0336 -0.1702 -0.0313 -0.0013 -0.6192 -0.1048\n",
            "S-5085\tThey will tap your Internet connection .\n",
            "T-5085\tHọ nghe lén đường truyền Internet của bạn .\n",
            "H-5085\t-0.4335511326789856\tHọ sẽ tận dụng kết nối Internet của bạn .\n",
            "D-5085\t-0.4335511326789856\tHọ sẽ tận dụng kết nối Internet của bạn .\n",
            "P-5085\t-0.7921 -0.1348 -1.6374 -0.1469 -0.2785 -0.0205 -0.3294 -0.2994 -0.8042 -0.2235 -0.1024\n",
            "S-4698\tIntroduce some mutations perhaps .\n",
            "T-4698\tCó thể đưa ra vài sự hoán đổi .\n",
            "H-4698\t-1.0464122295379639\tTính toán có lẽ sẽ biến mất .\n",
            "D-4698\t-1.0464122295379639\tTính toán có lẽ sẽ biến mất .\n",
            "P-4698\t-3.3943 -1.9149 -0.4315 -0.2766 -0.3374 -0.5855 -1.7202 -1.4277 -0.2757 -0.1005\n",
            "S-4569\tAnd they don &apos;t tell us much .\n",
            "T-4569\tvà chúng không cho chúng ta biết nhiều lắm .\n",
            "H-4569\t-0.5518205761909485\tVà họ không nói cho chúng ta biết nhiều .\n",
            "D-4569\t-0.5518205761909485\tVà họ không nói cho chúng ta biết nhiều .\n",
            "P-4569\t-0.5360 -0.7147 -0.2441 -0.7965 -0.8788 -0.1622 -1.0075 -0.6464 -0.5727 -0.4059 -0.1054\n",
            "S-4477\tIt might take a moment to load .\n",
            "T-4477\tCó lẽ cần giây lát để chạy đoạn video .\n",
            "H-4477\t-0.7764158248901367\tCó thể cần một chút thời gian để tải .\n",
            "D-4477\t-0.7764158248901367\tCó thể cần một chút thời gian để tải .\n",
            "P-4477\t-2.1318 -0.3951 -0.9858 -1.4408 -0.7083 -0.3962 -0.2237 -0.2592 -0.7217 -1.1769 -0.1009\n",
            "S-4394\tI &apos;m human . I make mistakes .\n",
            "T-4394\tTôi là con người . Tôi phạm sai lầm .\n",
            "H-4394\t-0.17970627546310425\tTôi là con người . Tôi mắc sai lầm .\n",
            "D-4394\t-0.17970627546310425\tTôi là con người . Tôi mắc sai lầm .\n",
            "P-4394\t-0.1632 -0.1510 -0.2383 -0.0944 -0.2723 -0.0602 -0.1963 -0.3452 -0.0042 -0.3498 -0.1019\n",
            "S-4393\tI am a redefined physician .\n",
            "T-4393\tTôi là một y sĩ theo khái niệm mới .\n",
            "H-4393\t-0.36871519684791565\tTôi là một bác sĩ định nghĩa lại một bác sĩ .\n",
            "D-4393\t-0.36871519684791565\tTôi là một bác sĩ định nghĩa lại một bác sĩ .\n",
            "P-4393\t-0.0965 -0.2161 -0.4679 -0.4280 -0.1086 -0.3325 -0.0197 -0.0474 -0.6756 -1.6468 -0.1229 -0.5328 -0.0983\n",
            "S-4640\tAnd those are the neural structures .\n",
            "T-4640\tVà đó là những cấu trúc thần kinh .\n",
            "H-4640\t-0.288936585187912\tVà đó là những cấu trúc thần kinh .\n",
            "D-4640\t-0.288936585187912\tVà đó là những cấu trúc thần kinh .\n",
            "P-4640\t-0.5228 -0.3406 -0.2504 -1.3675 -0.0441 -0.0291 -0.0910 -0.0059 -0.1319 -0.1060\n",
            "S-3957\tYou &apos;re an inspiring person .\n",
            "T-3957\tAnh thực sự là một người truyền cảm hứng .\n",
            "H-3957\t-0.38444632291793823\tBạn là một người truyền cảm hứng .\n",
            "D-3957\t-0.38444632291793823\tBạn là một người truyền cảm hứng .\n",
            "P-3957\t-0.6150 -0.4495 -0.6205 -0.2434 -0.9443 -0.0156 -0.0066 -0.4611 -0.1038\n",
            "S-3850\tAnd I began giving her my rap .\n",
            "T-3850\tThế là tôi bắt đầu nói huyên thuyên\n",
            "H-3850\t-0.5554398894309998\tVà tôi bắt đầu cho cô ấy cái rap của tôi .\n",
            "D-3850\t-0.5554398894309998\tVà tôi bắt đầu cho cô ấy cái rap của tôi .\n",
            "P-3850\t-1.0353 -0.1679 -0.1688 -0.0507 -0.3899 -0.3043 -0.4384 -2.5604 -0.9358 -0.3462 -0.3632 -0.3647 -0.0953\n",
            "S-3459\tThey had a concept of blue blood .\n",
            "T-3459\tHọ có khái niệm về dòng giống hoàng tộc .\n",
            "H-3459\t-0.302897185087204\tHọ có khái niệm về máu xanh .\n",
            "D-3459\t-0.302897185087204\tHọ có khái niệm về máu xanh .\n",
            "P-3459\t-0.3072 -0.3790 -0.7345 -0.0234 -0.0195 -0.2979 -0.0533 -0.8077 -0.1037\n",
            "S-3316\tYou can go all the way through .\n",
            "T-3316\tBạn có thể làm tất cả những thứ này .\n",
            "H-3316\t-0.5836586952209473\tBạn có thể đi xuyên qua .\n",
            "D-3316\t-0.5836586952209473\tBạn có thể đi xuyên qua .\n",
            "P-3316\t-0.3248 -0.1551 -0.0920 -0.5624 -2.8007 -0.0927 -0.5319 -0.1097\n",
            "S-3303\tYou can play with a different type .\n",
            "T-3303\tBạn có thể bày trò với một loại khác .\n",
            "H-3303\t-0.3360225260257721\tBạn có thể chơi với một loại khác .\n",
            "D-3303\t-0.3360225260257721\tBạn có thể chơi với một loại khác .\n",
            "P-3303\t-0.3505 -0.1744 -0.0908 -0.1715 -0.2526 -0.4662 -1.0601 -0.1134 -0.5754 -0.1053\n",
            "S-3277\tThe whole building is made of water .\n",
            "T-3277\tToàn bộ kiến trúc này được làm bằng nước .\n",
            "H-3277\t-0.22550088167190552\tToàn bộ toà nhà được làm từ nước .\n",
            "D-3277\t-0.22550088167190552\tToàn bộ toà nhà được làm từ nước .\n",
            "P-3277\t-0.2445 -0.3233 -0.0200 -0.0163 -0.2083 -0.7074 -0.3719 -0.1391 -0.1163 -0.1079\n",
            "S-3173\tJust spread it as wide as possible .\n",
            "T-3173\tChỉ cần lây nhiễm nó càng rộng càng tốt .\n",
            "H-3173\t-0.7159332036972046\tChỉ rộng ra càng nhiều càng tốt .\n",
            "D-3173\t-0.7159332036972046\tChỉ rộng ra càng nhiều càng tốt .\n",
            "P-3173\t-1.7005 -0.1091 -1.4866 -1.5492 -1.0000 -0.1323 -0.0057 -0.3515 -0.1086\n",
            "S-3051\tMonday : Color is powerful .\n",
            "T-3051\tThứ Hai : Màu sắc là chủ đạo .\n",
            "H-3051\t-0.8408045768737793\tThứ hai : Tô hình là quyền lực .\n",
            "D-3051\t-0.8408045768737793\tThứ hai : Tô hình là quyền lực .\n",
            "P-3051\t-1.1998 -0.4147 -0.0474 -1.8143 -0.8657 -2.2668 -1.6271 -0.5886 -0.0819 -0.2355 -0.1071\n",
            "S-2997\tThat &apos;s a painting of a circle .\n",
            "T-2997\tĐây là một bức vẽ về một vòng tròn .\n",
            "H-2997\t-0.30929940938949585\tĐó là một bức tranh của một vòng tròn .\n",
            "D-2997\t-0.30929940938949585\tĐó là một bức tranh của một vòng tròn .\n",
            "P-2997\t-0.5559 -0.1726 -0.7563 -0.1039 -0.1207 -0.9793 -0.1079 -0.3229 -0.0028 -0.1728 -0.1071\n",
            "S-2918\tImagine then just two other little changes .\n",
            "T-2918\tTưởng tượng khi đó chỉ với hai thay đổi nhỏ\n",
            "H-2918\t-0.4511054456233978\tHãy tưởng tượng chỉ hai thay đổi nhỏ khác .\n",
            "D-2918\t-0.4511054456233978\tHãy tưởng tượng chỉ hai thay đổi nhỏ khác .\n",
            "P-2918\t-1.1627 -0.1357 -0.0314 -1.4109 -0.7683 -0.5076 -0.0201 -0.0413 -0.3922 -0.3866 -0.1054\n",
            "S-2709\tSo I guess that &apos;s my brand .\n",
            "T-2709\tMình nghĩ đó là cái riêng biệt của mình .\n",
            "H-2709\t-0.5532156229019165\tTôi đoán đó là nhãn hiệu của tôi .\n",
            "D-2709\t-0.5532156229019165\tTôi đoán đó là nhãn hiệu của tôi .\n",
            "P-2709\t-1.7604 -0.5531 -1.1308 -0.3044 -1.0856 -0.0072 -0.1550 -0.2054 -0.2273 -0.1030\n",
            "S-2694\tHow would you guys describe your brand ?\n",
            "T-2694\tAnh coi mình thuộc trường phái phong cách nào ?\n",
            "H-2694\t-0.4430195093154907\tBạn sẽ mô tả công ty của mình như thế nào ?\n",
            "D-2694\t-0.4430195093154907\tBạn sẽ mô tả công ty của mình như thế nào ?\n",
            "P-2694\t-1.9416 -0.2618 -0.3194 -0.1049 -0.8132 -0.3161 -1.0359 -0.1154 -0.5150 -0.0670 -0.0660 -0.1070 -0.0958\n",
            "S-2493\tHe only has use of his eyes .\n",
            "T-2493\tAnh ấy chỉ còn điều khiển được đôi mắt .\n",
            "H-2493\t-0.5166029334068298\tAnh ta chỉ sử dụng đôi mắt của mình .\n",
            "D-2493\t-0.5166029334068298\tAnh ta chỉ sử dụng đôi mắt của mình .\n",
            "P-2493\t-1.6005 -0.6076 -0.1076 -1.9681 -0.0619 -0.2238 -0.0054 -0.4251 -0.3614 -0.2133 -0.1080\n",
            "S-2422\tThe captain waved me over .\n",
            "T-2422\tĐội trưởng vẫy tay gọi tôi lại .\n",
            "H-2422\t-1.0333504676818848\tNgười nắm lấy tôi rồi .\n",
            "D-2422\t-1.0333504676818848\tNgười nắm lấy tôi rồi .\n",
            "P-2422\t-2.2980 -1.0883 -0.4625 -0.1140 -2.0918 -1.0790 -0.0999\n",
            "S-2390\tSo let &apos;s think about the atoms .\n",
            "T-2390\tVậy hãy suy nghĩ về các hạt nguyên tử .\n",
            "H-2390\t-0.488435834646225\tHãy nghĩ về nguyên tử .\n",
            "D-2390\t-0.488435834646225\tHãy nghĩ về nguyên tử .\n",
            "P-2390\t-1.3646 -0.3971 -0.7285 -0.5213 -0.0827 -0.2210 -0.1039\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/fairseq-generate\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-generate')())\n",
            "  File \"/content/fairseq/fairseq_cli/generate.py\", line 413, in cli_main\n",
            "    main(args)\n",
            "  File \"/content/fairseq/fairseq_cli/generate.py\", line 50, in main\n",
            "    return _main(cfg, sys.stdout)\n",
            "  File \"/content/fairseq/fairseq_cli/generate.py\", line 206, in _main\n",
            "    constraints=constraints,\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 538, in inference_step\n",
            "    models, sample, prefix_tokens=prefix_tokens, constraints=constraints\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 191, in generate\n",
            "    return self._generate(sample, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 345, in _generate\n",
            "    self.temperature,\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 809, in forward_decoder\n",
            "    decoder_out = model.decoder.forward(tokens, encoder_out=encoder_out)\n",
            "  File \"/content/mymodel/models/nnFairseqTransformer.py\", line 134, in forward\n",
            "    memory_key_padding_mask=memory_key_padding_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\", line 255, in forward\n",
            "    memory_key_padding_mask=memory_key_padding_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\", line 459, in forward\n",
            "    x = self.norm3(x + self._ff_block(x))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\", line 483, in _ff_block\n",
            "    x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Evaluate our model, change the path\n",
        "!fairseq-generate /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset \\\n",
        "    --path /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint_best.pt \\\n",
        "    --batch-size 128 --beam 5 --remove-bpe \\\n",
        "    --user-dir /content/mymodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Wbr-bJW4-r"
      },
      "source": [
        "## Try to add FuzzyLayer to Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iagQ0QWRb4n7",
        "outputId": "70eb4f54-b48b-4bce-fdc5-a7a77ae583fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 35])\n",
            "tensor([[6.7112e-06, 6.8293e-04, 1.1360e-05, 1.4338e-05, 3.1253e-06, 4.4289e-04,\n",
            "         1.2499e-04, 2.6953e-04, 5.7319e-06, 3.1216e-05, 5.5655e-05, 3.2802e-04,\n",
            "         3.7528e-02, 1.1846e-05, 7.1205e-07, 2.0275e-06, 7.1357e-07, 4.7466e-04,\n",
            "         1.9231e-06, 2.3387e-03, 8.4445e-06, 1.2212e-04, 1.2321e-04, 4.9719e-04,\n",
            "         9.7817e-03, 7.2931e-03, 2.3511e-06, 5.0083e-02, 1.0146e-05, 1.0202e-06,\n",
            "         5.4978e-04, 8.7630e-04, 9.0879e-02, 2.8873e-08, 5.0999e-03],\n",
            "        [6.7112e-06, 6.8293e-04, 1.1360e-05, 1.4338e-05, 3.1253e-06, 4.4289e-04,\n",
            "         1.2499e-04, 2.6953e-04, 5.7319e-06, 3.1216e-05, 5.5655e-05, 3.2802e-04,\n",
            "         3.7528e-02, 1.1846e-05, 7.1205e-07, 2.0275e-06, 7.1357e-07, 4.7466e-04,\n",
            "         1.9231e-06, 2.3387e-03, 8.4445e-06, 1.2212e-04, 1.2321e-04, 4.9719e-04,\n",
            "         9.7817e-03, 7.2931e-03, 2.3511e-06, 5.0083e-02, 1.0146e-05, 1.0202e-06,\n",
            "         5.4978e-04, 8.7630e-04, 9.0879e-02, 2.8873e-08, 5.0999e-03],\n",
            "        [6.7112e-06, 6.8293e-04, 1.1360e-05, 1.4338e-05, 3.1253e-06, 4.4289e-04,\n",
            "         1.2499e-04, 2.6953e-04, 5.7319e-06, 3.1216e-05, 5.5655e-05, 3.2802e-04,\n",
            "         3.7528e-02, 1.1846e-05, 7.1205e-07, 2.0275e-06, 7.1357e-07, 4.7466e-04,\n",
            "         1.9231e-06, 2.3387e-03, 8.4445e-06, 1.2212e-04, 1.2321e-04, 4.9719e-04,\n",
            "         9.7817e-03, 7.2931e-03, 2.3511e-06, 5.0083e-02, 1.0146e-05, 1.0202e-06,\n",
            "         5.4978e-04, 8.7630e-04, 9.0879e-02, 2.8873e-08, 5.0999e-03]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# FuzzyLayer\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "\n",
        "class FuzzyLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, output_dim: int, **kwargs):\n",
        "        super(FuzzyLayer, self).__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.fuzzy_degree = nn.Parameter(torch.empty(output_dim))\n",
        "        self.sigma = nn.Parameter(torch.ones(output_dim))\n",
        "        self.reset_parameters()\n",
        "        \n",
        "    def reset_parameters(self) -> None:\n",
        "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
        "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
        "        # https://github.com/pytorch/pytorch/issues/57109\n",
        "        nn.init.uniform_(self.fuzzy_degree)\n",
        "\n",
        "    def forward(self, input, **kwargs):\n",
        "        x = torch.repeat_interleave(torch.unsqueeze(input,-1), self.output_dim, dim=-1)\n",
        "        fuzzy_out = torch.exp(\n",
        "                      -torch.sum(\n",
        "                          torch.square((x-self.fuzzy_degree)/(self.sigma**2))            \n",
        "                          ,dim=-2, keepdims=False)\n",
        "              )\n",
        "        return fuzzy_out\n",
        "\n",
        "\n",
        "class FuzzyRuleLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim: int, output_dim,**kwargs):\n",
        "        super(FuzzyRuleLayer, self).__init__(**kwargs)\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.layers = nn.ModuleList([\n",
        "            FuzzyLayer(output_dim) for _ in range(input_dim)\n",
        "        ])\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size, input_dim = input.size()\n",
        "        an=torch.ones(batch_size, self.output_dim)\n",
        "        for layer in self.layers:\n",
        "            an=an*layer(input)\n",
        "        return an\n",
        "\n",
        "z=FuzzyRuleLayer(5,35)\n",
        "y=torch.ones(3,5)\n",
        "print(z(y).shape)\n",
        "print(z(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "227Lz-QqbOQK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icDOr3H9HlHY"
      },
      "source": [
        "## Try to add MyLSTM to fairseq (CPU only)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnFBO2ZoZoWu"
      },
      "source": [
        "### Some notes\n",
        "+ Follow the tutorial at https://fairseq.readthedocs.io/en/latest/tutorial_simple_lstm.html, add `@register_model` and `@register_model_architecture` to appropriate class.\n",
        "\n",
        "+ That's not all, you must either:\n",
        "\n",
        "1. Move your `model_name.py` to `fairseq/models`\n",
        "\n",
        "2. Inside your directory (supposed `user_dir`), create a new folder named `models` and move your file there. In the command line (such as `fairseq-train`), specify `--user-dir /path/to/user_dir`\n",
        "\n",
        "Because each time the command line tool runs, it must run some bootstrap code to get the current model list, parse your arguments, etc. Therefore you must follow some of their rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85WWH0DhawMB",
        "outputId": "4da5f279-965c-41fd-bbc1-a1b8ac8e02a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'my_transformer' already exists and is not an empty directory.\n",
            "mkdir: cannot create directory ‘mymodel’: File exists\n",
            "/content/mymodel\n",
            "mkdir: cannot create directory ‘models’: File exists\n",
            "/content/mymodel/models\n"
          ]
        }
      ],
      "source": [
        "# Make mymodel path and prepare my_model (in this case `MyLSTM.py`) in user_dir (in this case `mymodel`)\n",
        "%cd /content\n",
        "!rm -rf my_transformer\n",
        "!git clone https://github.com/gigajet/transformer my_transformer\n",
        "!mkdir mymodel\n",
        "%cd mymodel\n",
        "!mkdir models\n",
        "%cd models \n",
        "!cp /content/my_transformer/MyFairseqLSTM.py .\n",
        "!cp -r /content/my_transformer/layer .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbnkII_hHqIj",
        "outputId": "b383bf6e-a5b0-413a-9b45-510b0367167c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "2022-04-22 10:02:58 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2022-04-22 10:02:59 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/content/mymodel', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 12000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='mylstm_default', adam_betas=(0.9, 0.999), adam_eps=1e-08, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='mylstm_default', azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/content/drive/MyDrive/translation/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_dropout=0.2, decoder_embed_dim=256, decoder_hidden_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_dropout=0.2, encoder_embed_dim=256, encoder_hidden_dim=256, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.005], lr_scheduler='fixed', lr_shrink=0.5, max_epoch=1, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='/content/mymodel', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=0, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/translation/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.005]}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.5, 'warmup_updates': 0, 'lr': [0.005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-04-22 10:03:01 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types\n",
            "2022-04-22 10:03:01 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types\n",
            "MyLSTM(\n",
            "  (encoder): SimpleLSTMEncoder(\n",
            "    (embed_tokens): Embedding(8848, 256, padding_idx=1)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (lstm): LSTM(256, 256, batch_first=True)\n",
            "  )\n",
            "  (decoder): SimpleLSTMDecoder(\n",
            "    (embed_tokens): Embedding(6632, 256, padding_idx=1)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (lstm): LSTM(512, 256)\n",
            "    (output_projection): Linear(in_features=256, out_features=6632, bias=True)\n",
            "  )\n",
            ")\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | MyLSTM(\n",
            "  (encoder): SimpleLSTMEncoder(\n",
            "    (embed_tokens): Embedding(8848, 256, padding_idx=1)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (lstm): LSTM(256, 256, batch_first=True)\n",
            "  )\n",
            "  (decoder): SimpleLSTMDecoder(\n",
            "    (embed_tokens): Embedding(6632, 256, padding_idx=1)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (lstm): LSTM(512, 256)\n",
            "    (output_projection): Linear(in_features=256, out_features=6632, bias=True)\n",
            "  )\n",
            ")\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | model: MyLSTM\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | num. shared model params: 6,982,120 (num. trained: 6,982,120)\n",
            "2022-04-22 10:03:01 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-04-22 10:03:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: /content/drive/MyDrive/translation/iwslt14.tokenized.de-en/valid.de-en.de\n",
            "2022-04-22 10:03:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: /content/drive/MyDrive/translation/iwslt14.tokenized.de-en/valid.de-en.en\n",
            "2022-04-22 10:03:01 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt14.tokenized.de-en valid de-en 7283 examples\n",
            "2022-04-22 10:03:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-04-22 10:03:04 | INFO | fairseq.utils | rank   0: capabilities =  3.7  ; total memory = 11.173 GB ; name = Tesla K80                               \n",
            "2022-04-22 10:03:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-04-22 10:03:04 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-04-22 10:03:04 | INFO | fairseq_cli.train | max tokens per device = 12000 and max sentences per device = None\n",
            "2022-04-22 10:03:04 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt\n",
            "2022-04-22 10:03:04 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2022-04-22 10:03:04 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2022-04-22 10:03:04 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: /content/drive/MyDrive/translation/iwslt14.tokenized.de-en/train.de-en.de\n",
            "2022-04-22 10:03:04 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: /content/drive/MyDrive/translation/iwslt14.tokenized.de-en/train.de-en.en\n",
            "2022-04-22 10:03:04 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt14.tokenized.de-en train de-en 160239 examples\n",
            "2022-04-22 10:03:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 388\n",
            "epoch 001:   0% 0/388 [00:00<?, ?it/s]2022-04-22 10:03:04 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2022-04-22 10:03:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 557, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 190, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 316, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 856, in train_step\n",
            "    raise e\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 830, in train_step\n",
            "    **extra_kwargs,\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 512, in train_step\n",
            "    loss, sample_size, logging_output = criterion(model, sample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/criterions/cross_entropy.py\", line 35, in forward\n",
            "    net_output = model(**sample[\"net_input\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 322, in forward\n",
            "    encoder_out = self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/mymodel/models/MyFairseqLSTM.py\", line 60, in forward\n",
            "    x = nn.utils.rnn.pack_padded_sequence(x, src_lengths, batch_first=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/rnn.py\", line 249, in pack_padded_sequence\n",
            "    _VF._pack_padded_sequence(input, lengths, batch_first)\n",
            "RuntimeError: 'lengths' argument should be a 1D CPU int64 tensor, but got 1D cuda:0 Long tensor\n"
          ]
        }
      ],
      "source": [
        "# Train the model, please change --max-epoch depends whether you use gpu/cpu\n",
        "%env CUDA_VISIBLE_DEVICES=0 \n",
        "!fairseq-train \\\n",
        "    /content/drive/MyDrive/translation/iwslt14.tokenized.de-en \\\n",
        "    --encoder-dropout 0.2 --decoder-dropout 0.2 \\\n",
        "    --optimizer adam --lr 0.005 --lr-shrink 0.5 \\\n",
        "    --max-epoch 1 \\\n",
        "    --max-tokens 12000 \\\n",
        "    --save-dir checkpoints \\\n",
        "    --user-dir /content/mymodel \\\n",
        "    --arch mylstm_default \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wp9VGKqQVPb"
      },
      "source": [
        "## Get mymodel from github and prepare directory structure that satisfies fairseq requirement. Adding custom model to fairseq in `/content/mymodel`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfQorQ23Qf24",
        "outputId": "c6ce5196-d0c8-44b5-bcb7-4882a544fe18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'my_transformer'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 267 (delta 13), reused 14 (delta 6), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (267/267), 28.30 MiB | 7.17 MiB/s, done.\n",
            "Resolving deltas: 100% (148/148), done.\n",
            "/content/mymodel\n",
            "/content/mymodel/models\n",
            "/content/fairseq\n"
          ]
        }
      ],
      "source": [
        "# Make mymodel path and prepare my_model (in this case `MyLSTM.py`) in user_dir (in this case `mymodel`)\n",
        "%cd /content\n",
        "!rm -rf my_transformer\n",
        "!git clone https://github.com/gigajet/transformer my_transformer\n",
        "!rm -rf mymodel\n",
        "!mkdir mymodel\n",
        "%cd mymodel\n",
        "!cp -r /content/my_transformer models\n",
        "\n",
        "# Xóa thể loại không liên quan\n",
        "%cd models\n",
        "!rm -f string_reverser_*.py\n",
        "\n",
        "# Finalize\n",
        "%cd /content/fairseq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hv4UomOGyJqX"
      },
      "outputs": [],
      "source": [
        "# fix the import layer to mymodel.layer\n",
        "# F*** PYTHON3 IMPORT\n",
        "!find /content/mymodel -type f -exec sed -i \"s/from layer\\./from mymodel.models.layer./g\" {} \\;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training nntransformer_default"
      ],
      "metadata": {
        "id": "7DGeQy3fetQB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w81ozS3NQf3F",
        "outputId": "535eef74-9720-4d2d-b2e6-f3d54b98b4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "2022-05-06 15:16:16 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-05-06 15:16:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/content/mymodel', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='nntransformer_default', adam_betas='(0.9, 0.98)', adam_eps=1e-08, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='nntransformer_default', azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', device_id=0, dim_feedforward=2048, dim_model=512, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=100, max_source_positions=1024, max_src_len=16378, max_target_positions=1024, max_tgt_len=16378, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_head=8, num_layer=6, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='/content/mymodel', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-05-06 15:16:18 | INFO | fairseq.tasks.translation | [en] dictionary: 7656 types\n",
            "2022-05-06 15:16:18 | INFO | fairseq.tasks.translation | [vi] dictionary: 6656 types\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | NNTransformer(\n",
            "  (encoder): NNTransformerEncoder(\n",
            "    (embedding): PositionalEncodedEmbedding(\n",
            "      (input_embedding): Embedding(7656, 512, padding_idx=1)\n",
            "    )\n",
            "    (nn_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (1): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (2): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (3): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (4): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (5): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): NNTransformerDecoder(\n",
            "    (embedding): PositionalEncodedEmbedding(\n",
            "      (input_embedding): Embedding(6656, 512, padding_idx=1)\n",
            "    )\n",
            "    (nn_decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (1): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (2): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (3): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (4): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (5): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=6656, bias=True)\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            ")\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | model: NNTransformer\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | num. shared model params: 54,880,768 (num. trained: 54,880,768)\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-05-06 15:16:22 | INFO | fairseq.data.data_utils | loaded 5,089 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/valid.en-vi.en\n",
            "2022-05-06 15:16:22 | INFO | fairseq.data.data_utils | loaded 5,089 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/valid.en-vi.vi\n",
            "2022-05-06 15:16:22 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset valid en-vi 5089 examples\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.0.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.0.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.1.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.1.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.1.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.2.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.2.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.2.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.3.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.3.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.3.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.4.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.4.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.4.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.5.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.5.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.5.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.multihead_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.multihead_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.multihead_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.multihead_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.multihead_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.multihead_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.multihead_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.multihead_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.multihead_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.multihead_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.multihead_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.multihead_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.multihead_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.multihead_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.multihead_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.self_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.self_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.self_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.multihead_attn.q_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.multihead_attn.k_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.multihead_attn.v_proj_weight\n",
            "2022-05-06 15:16:22 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-05-06 15:16:22 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2022-05-06 15:16:22 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint_last.pt\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint_last.pt\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2022-05-06 15:16:22 | INFO | fairseq.data.data_utils | loaded 111,966 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.en-vi.en\n",
            "2022-05-06 15:16:22 | INFO | fairseq.data.data_utils | loaded 111,966 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.en-vi.vi\n",
            "2022-05-06 15:16:22 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset train en-vi 111966 examples\n",
            "2022-05-06 15:16:22 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n",
            "2022-05-06 15:16:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 816\n",
            "epoch 001:   0% 0/816 [00:00<?, ?it/s]2022-05-06 15:16:22 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2022-05-06 15:16:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:375: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001: 100% 815/816 [05:13<00:00,  2.51it/s, loss=8.455, nll_loss=7.754, ppl=215.8, wps=9375, ups=2.57, wpb=3647.4, bsz=139.4, num_updates=800, lr=0.0001, gnorm=1.591, train_wall=39, gb_free=11.7, wall=307]2022-05-06 15:21:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/47 [00:00<?, ?it/s]\u001b[A2022-05-06 15:21:38 | INFO | fairseq.tasks.translation | example hypothesis: Đây là một cách khác.\n",
            "2022-05-06 15:21:38 | INFO | fairseq.tasks.translation | example reference: Đây là một mẩu than đá.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   2% 1/47 [00:03<02:22,  3.10s/it]\u001b[A2022-05-06 15:21:42 | INFO | fairseq.tasks.translation | example hypothesis: Và đây là điều đó.\n",
            "2022-05-06 15:21:42 | INFO | fairseq.tasks.translation | example reference: Và vẫn chưa ai làm điều đó cả.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   4% 2/47 [00:06<02:17,  3.05s/it]\u001b[A2022-05-06 15:21:45 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:21:45 | INFO | fairseq.tasks.translation | example reference: Họ chỉ chờ đến ngày ra toà.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   6% 3/47 [00:09<02:17,  3.12s/it]\u001b[A2022-05-06 15:21:48 | INFO | fairseq.tasks.translation | example hypothesis: Và tôi nghĩ rằng tôi đã làm việc này.\n",
            "2022-05-06 15:21:48 | INFO | fairseq.tasks.translation | example reference: Tôi nghĩ đó một thử nghiệm thú vị.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   9% 4/47 [00:12<02:16,  3.18s/it]\u001b[A2022-05-06 15:21:51 | INFO | fairseq.tasks.translation | example hypothesis: Đây là một người khác.\n",
            "2022-05-06 15:21:51 | INFO | fairseq.tasks.translation | example reference: Một năm sau, anh ta vẫn bốc mùi.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  11% 5/47 [00:15<02:12,  3.15s/it]\u001b[A2022-05-06 15:21:54 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta không phải là một người khác.\n",
            "2022-05-06 15:21:54 | INFO | fairseq.tasks.translation | example reference: Đó là một trật tự lớn nhỏ, lên xuống.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  13% 6/47 [00:18<02:09,  3.16s/it]\u001b[A2022-05-06 15:21:58 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng tôi nói, \"Và bạn nói,\"\n",
            "2022-05-06 15:21:58 | INFO | fairseq.tasks.translation | example reference: rồi nói, \"Đi đi! Người tiếp theo!\"\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  15% 7/47 [00:22<02:07,  3.19s/it]\u001b[A2022-05-06 15:22:01 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng ta có thể làm việc đó.\n",
            "2022-05-06 15:22:01 | INFO | fairseq.tasks.translation | example reference: Và hoạt động của họ cần chú ý cao độ.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  17% 8/47 [00:25<02:02,  3.15s/it]\u001b[A2022-05-06 15:22:04 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể làm thế nào đó.\n",
            "2022-05-06 15:22:04 | INFO | fairseq.tasks.translation | example reference: Họ quay lại kiện thêm nhiều vụ vi phạm bản quyền hơn nữa.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  19% 9/47 [00:28<01:59,  3.16s/it]\u001b[A2022-05-06 15:22:07 | INFO | fairseq.tasks.translation | example hypothesis: Và tôi nghĩ rằng bạn có thể làm việc này.\n",
            "2022-05-06 15:22:07 | INFO | fairseq.tasks.translation | example reference: Tôi sẽ chỉ bạn một mánh khoé này, nếu bạn muốn chơi lại một lần nữa.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  21% 10/47 [00:31<01:57,  3.19s/it]\u001b[A2022-05-06 15:22:11 | INFO | fairseq.tasks.translation | example hypothesis: Và tôi muốn nói rằng bạn có thể thấy rằng bạn có thể làm việc này.\n",
            "2022-05-06 15:22:11 | INFO | fairseq.tasks.translation | example reference: Bây giờ tôi sẽ chia sẻ với các bạn quy trình bốn bước để tạo ra những vật liệu này.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  23% 11/47 [00:35<01:58,  3.28s/it]\u001b[A2022-05-06 15:22:14 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể làm việc làm việc này.\n",
            "2022-05-06 15:22:14 | INFO | fairseq.tasks.translation | example reference: Sức mạnh của đất mẹ là một phần quan trọng giúp nỗi đau của họ dường như được giảm nhẹ.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  26% 12/47 [00:38<01:55,  3.31s/it]\u001b[A2022-05-06 15:22:17 | INFO | fairseq.tasks.translation | example hypothesis: Đây là một cách mà chúng ta có thể làm việc này.\n",
            "2022-05-06 15:22:17 | INFO | fairseq.tasks.translation | example reference: Công việc của tôi xoay quanh những hành vi mà chúng ta thực hiện vô thức ở mức độ tập thể.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  28% 13/47 [00:41<01:53,  3.35s/it]\u001b[A2022-05-06 15:22:21 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể làm gì? Chúng ta có thể làm gì?\n",
            "2022-05-06 15:22:21 | INFO | fairseq.tasks.translation | example reference: Chúng ta thật sự nên hỏi rằng: Liệu thế giới có thể chịu đựng được số lượng xe hơi đó không?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  30% 14/47 [00:45<01:52,  3.42s/it]\u001b[A2022-05-06 15:22:25 | INFO | fairseq.tasks.translation | example hypothesis: Tôi muốn nói rằng tôi có thể làm việc này.\n",
            "2022-05-06 15:22:25 | INFO | fairseq.tasks.translation | example reference: Tôi có thể làm ví dụ bằng giọng mình và chơi lại chúng chỉ bằng cách chạm vào mấy cái bảng này đây\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  32% 15/47 [00:49<01:55,  3.61s/it]\u001b[A2022-05-06 15:22:29 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể làm điều đó là điều đó.\n",
            "2022-05-06 15:22:29 | INFO | fairseq.tasks.translation | example reference: Các phần tử khí bị đẩy ra khỏi mặt ấm đẩy ra xa với vận tốc tăng thêm bởi vì nó ấm.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  34% 16/47 [00:53<01:57,  3.80s/it]\u001b[A2022-05-06 15:22:33 | INFO | fairseq.tasks.translation | example hypothesis: Và đây là một người khác, chúng ta có thể làm việc này.\n",
            "2022-05-06 15:22:33 | INFO | fairseq.tasks.translation | example reference: Và truyền thuyết thứ tư là, ngủ sớm sẽ dậy sớm giúp ta khoẻ mạnh, giàu có và khôn ngoan.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  36% 17/47 [00:57<01:57,  3.92s/it]\u001b[A2022-05-06 15:22:38 | INFO | fairseq.tasks.translation | example hypothesis: Tôi muốn nói: Tôi muốn nói rằng: Tôi không phải không phải là một người.\n",
            "2022-05-06 15:22:38 | INFO | fairseq.tasks.translation | example reference: Shaffi Mather: Tôi chỉ cố gắng vượt qua những ngày đầu tiên khi tôi còn chưa bị loại bỏ.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  38% 18/47 [01:02<01:57,  4.05s/it]\u001b[A2022-05-06 15:22:42 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng tôi nghĩ rằng chúng ta có thể làm việc này, và chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:22:42 | INFO | fairseq.tasks.translation | example reference: Tiếp theo, tôi sẽ lướt nhanh hơn qua vài phần não chuyên biệt khác mà chúng tôi và những người khác đã tìm ra.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  40% 19/47 [01:06<01:57,  4.21s/it]\u001b[A2022-05-06 15:22:47 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể làm việc này, và chúng ta có thể thấy rằng chúng ta có thể làm việc này.\n",
            "2022-05-06 15:22:47 | INFO | fairseq.tasks.translation | example reference: Giờ nếu chúng ta tháo chuỗi xoắn kép và mở tách hai chuỗi ra, chúng ta sẽ nhìn thấy chúng giống như hàm răng.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  43% 20/47 [01:11<01:54,  4.25s/it]\u001b[A2022-05-06 15:22:51 | INFO | fairseq.tasks.translation | example hypothesis: Và tôi muốn nói rằng, tôi muốn nói rằng tôi muốn nói rằng, nhưng tôi muốn nói rằng tôi muốn nói với những người khác.\n",
            "2022-05-06 15:22:51 | INFO | fairseq.tasks.translation | example reference: Và tôi đã nghĩ rằng khi tôi lại gần tôi sẽ nhìn thấy được chi tiết của từng người nhìn thấy được quần áo họ và vân vân.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  45% 21/47 [01:15<01:51,  4.28s/it]\u001b[A2022-05-06 15:22:56 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng ta có thể làm việc này, và chúng ta có thể làm thế giới, nhưng chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:22:56 | INFO | fairseq.tasks.translation | example reference: Bạn có thể thấy, đây là Sao Thổ, đây là Sao Mộc và trong lúc chúng ta dừng ở đây, tôi muốn chỉ ra một điều\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  47% 22/47 [01:20<01:50,  4.40s/it]\u001b[A2022-05-06 15:23:01 | INFO | fairseq.tasks.translation | example hypothesis: Và đây là điều này, tôi không phải là điều này.\n",
            "2022-05-06 15:23:01 | INFO | fairseq.tasks.translation | example reference: Và nó có hình dáng chiếc sừng trông rất buồn cười, mà cho tới nay tôi được biết đây là cuốn sách dạy nấu đầu tiên làm điều này.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  49% 23/47 [01:25<01:51,  4.66s/it]\u001b[A2022-05-06 15:23:06 | INFO | fairseq.tasks.translation | example hypothesis: Và đây là một người khác biệt là một người khác.\n",
            "2022-05-06 15:23:06 | INFO | fairseq.tasks.translation | example reference: Và nó là sản phẩm của một quá trình lịch sử phức tạp đã phát triển cùng với sự nổi lên của Hồi giáo bảo thủ kể từ cuối thập niên 1970.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  51% 24/47 [01:30<01:51,  4.85s/it]\u001b[A2022-05-06 15:23:11 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể làm việc này, chúng ta có thể làm thế giới, nhưng chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:23:11 | INFO | fairseq.tasks.translation | example reference: Con quạ đó tạm thời được độc quyền ăn lạc cho tới khi bạn nó tìm ra làm thế như thế nào, và thế là xong.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  53% 25/47 [01:35<01:47,  4.90s/it]\u001b[A2022-05-06 15:23:17 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể làm việc này, nhưng nó không phải là một người, nhưng nó không phải là một cái gì đó.\n",
            "2022-05-06 15:23:17 | INFO | fairseq.tasks.translation | example reference: Ông viết rằng, khi đang ở trong trại, ông có thể đoán trước người nào sẽ được thả, người nào sẽ ổn và người nào không.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  55% 26/47 [01:41<01:44,  4.99s/it]\u001b[A2022-05-06 15:23:22 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể nói rằng những người trong những người khác.\n",
            "2022-05-06 15:23:22 | INFO | fairseq.tasks.translation | example reference: Tổ Chức Y Tế Thế Giới ước tính -- họ đưa ra rất nhiều ước tính về số người cần đeo kính -- ước đoán thấp nhất là 150 triệu người.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  57% 27/47 [01:46<01:42,  5.11s/it]\u001b[A2022-05-06 15:23:27 | INFO | fairseq.tasks.translation | example hypothesis: Nếu bạn có thể thấy rằng, và tôi có thể làm việc này, và tôi có thể làm việc đó là điều đó là một cái gì đó.\n",
            "2022-05-06 15:23:27 | INFO | fairseq.tasks.translation | example reference: Giờ tôi hiểu rằng, biệt giam là một trong những nơi bất nhân và dã man nhất bạn có thể rơi vào, nhưng ở đó tôi đã tìm thấy chính mình.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  60% 28/47 [01:51<01:35,  5.05s/it]\u001b[A2022-05-06 15:23:32 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể tìm thấy những người khác nhau, và những người khác nhau.\n",
            "2022-05-06 15:23:32 | INFO | fairseq.tasks.translation | example reference: Như bồi thẩm đoàn những người đã tuyên án những người vô tội đó và bồi thẩm đoàn đã kết án Titus, nhiều người tin rằng trí nhớ làm việc như một chiếc máy ghi hình.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  62% 29/47 [01:57<01:34,  5.24s/it]\u001b[A2022-05-06 15:23:38 | INFO | fairseq.tasks.translation | example hypothesis: Nếu bạn có thể nói rằng bạn có thể thấy rằng bạn có thể thấy rằng bạn có thể thấy rằng bạn có thể thấy rằng bạn có thể thấy rằng nó.\n",
            "2022-05-06 15:23:38 | INFO | fairseq.tasks.translation | example reference: Nếu tôi nói với bạn có 1 đợt dịch hạch sẽ giết 15,000 người Mỹ năm tới, bạn sẽ hốt hoảng nếu bạn không phát hiện ra đó là bệnh cúm.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  64% 30/47 [02:02<01:31,  5.41s/it]\u001b[A2022-05-06 15:23:45 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng tôi có thể làm việc này, nhưng không phải là những người khác nhau, nhưng tôi có thể làm thế giới.\n",
            "2022-05-06 15:23:45 | INFO | fairseq.tasks.translation | example reference: Những nhà hoạt động mà tôi phỏng vấn không có điểm chung nào trừ một điều họ luôn nhắc tới mẹ họ như hình bóng to lớn ảnh hưởng sâu sắc đến họ.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  66% 31/47 [02:09<01:30,  5.67s/it]\u001b[A2022-05-06 15:23:50 | INFO | fairseq.tasks.translation | example hypothesis: Đây là một người khác, những người khác nhau, một người khác, nhưng nó là một người khác nhau.\n",
            "2022-05-06 15:23:50 | INFO | fairseq.tasks.translation | example reference: Như chính phủ I-ran phát hiện ra thông qua một chuỗi các công ty bình phong, công ty nặc danh sở hữu một toà nhà ngay trung tâm của Manhattan trên Đại lộ 5, bất chấp các cuộc trừng phạt của Mỹ.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  68% 32/47 [02:15<01:25,  5.73s/it]\u001b[A2022-05-06 15:23:57 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng ta có thể làm việc này, nhưng chúng ta có thể làm việc này, nhưng chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:23:57 | INFO | fairseq.tasks.translation | example reference: Và vào ngày 21 tháng 9 năm nay, chúng tôi sẽ khởi động chiến dịch tại O2 Arena tiến lên vì hoạt động đó, để cố gắng tạo ra kỉ lục lớn nhất về sự loại bỏ thù địch.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  70% 33/47 [02:21<01:21,  5.84s/it]\u001b[A2022-05-06 15:24:03 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng ta có thể làm việc đó là một cái mà chúng ta có thể làm việc này.\n",
            "2022-05-06 15:24:03 | INFO | fairseq.tasks.translation | example reference: Chúng tôi muốn tìm ra liệu có sự khác biệt nhỏ nào trong các cộng đồng về lượng tương tác mỗi con kiến cần để sẵn sàng ra ngoài kiếm ăn, khi cộng đồng ấy ít đi kiếm ăn.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  72% 34/47 [02:27<01:17,  5.93s/it]\u001b[A2022-05-06 15:24:10 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể thấy những người khác nhau, và những người khác nhau, và những người khác nhau, và những người khác nhau.\n",
            "2022-05-06 15:24:10 | INFO | fairseq.tasks.translation | example reference: Loài tanager ở bờ Đông nước Mỹ, khi rừng có phần rậm rạp hơn, có tiếng hót khác so với loài tanUNKNOWNTOKENINREF ở phía bên kia, phía tây vậy là chúng rất khác nhau.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  74% 35/47 [02:34<01:16,  6.35s/it]\u001b[A2022-05-06 15:24:16 | INFO | fairseq.tasks.translation | example hypothesis: Chúng tôi muốn nói rằng những người khác, nhưng tôi không phải là một cái gì đó là một người khác nhau, nhưng tôi đã nói về những người khác.\n",
            "2022-05-06 15:24:16 | INFO | fairseq.tasks.translation | example reference: Do đó khi Sở công viên liên hệ với tôi về chương trình cấp hạt giống trị giá $10: 00, một chương trình nhằm giúp phát triển những dự án đê điều, tôi nghĩ ngay rằng ý đồ đó tốt, nhưng có chút ngây thơ.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  77% 36/47 [02:41<01:10,  6.39s/it]\u001b[A2022-05-06 15:24:24 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể làm việc làm thế giới, chúng ta có thể làm việc làm thế giới, chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:24:24 | INFO | fairseq.tasks.translation | example reference: ngay bây giờ, thế giới có thể sản xuất khoảng 350 triệu liều vắc xin cúm cho 3 biến thể và chúng ta có thể có tới 1.2 tỷ liều nếu chúng ta muốn đặt mục tiêu cho một biến thể đơn như cúm lợn\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  79% 37/47 [02:48<01:07,  6.74s/it]\u001b[A2022-05-06 15:24:32 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể thấy những người khác nhau, nhưng chúng ta có thể thấy rằng những người khác nhau, nhưng chúng ta có thể thấy rằng những người khác nhau, nhưng chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:24:32 | INFO | fairseq.tasks.translation | example reference: Như vậy, tuổi thọ trung bình ở Mỹ và Anh là 78.1 tuổi, nhưng chúng ta biết được từ hơn 1000 cuộc nghiên cứu khoa học được kiểm tra kỹ càng rằng bạn có thể sống thêm 10 năm bằng cách nâng cao bốn loại sức bật này.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  81% 38/47 [02:56<01:03,  7.06s/it]\u001b[A2022-05-06 15:24:39 | INFO | fairseq.tasks.translation | example hypothesis: Và chúng ta có thể thấy rằng chúng ta có thể làm việc này, nhưng chúng ta có thể thấy rằng chúng ta có thể làm thế giới.\n",
            "2022-05-06 15:24:39 | INFO | fairseq.tasks.translation | example reference: Sẽ không thể nhìn hay cảm nhận bất cứ thứ gì giống như chúng ta thấy khi chúng ta nhìn một bông hoa. Vậy nếu bạn nhìn bông hoa ở đây, và bạn là một con côn trùng bé xíu, bạn ở trên bề mặt của bông hoa đó, địa hình cũng giống như vậy,\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  83% 39/47 [03:03<00:56,  7.05s/it]\u001b[A2022-05-06 15:24:47 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể làm việc này, và tôi đã nói rằng những người khác nhau, và nó là một người khác nhau, và những người khác, nhưng tôi đã làm việc đó là một người khác.\n",
            "2022-05-06 15:24:47 | INFO | fairseq.tasks.translation | example reference: Vậy mà, nếu tôi đã học được điều gì trong gần 12 năm nay kéo những vật nặng quanh những nơi lạnh giá, đó là cảm hứng thực sự, và sự trưởng thành chỉ đến từ khó khăn và thử thách, từ việc rời khỏi những cái tiện nghi và thân thuộc và bước chân vào những nơi chưa biết đến.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  85% 40/47 [03:11<00:51,  7.42s/it]\u001b[A2022-05-06 15:24:56 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể tìm thấy những người khác nhau, nhưng chúng ta có thể làm việc làm thế giới.\n",
            "2022-05-06 15:24:56 | INFO | fairseq.tasks.translation | example reference: Những người máy sẽ không thế hết công việc của chúng ta trong một vài năm tới vậy nên cuốn sách chiến lược kinh tế 101 sẽ vẫn có hiệu lực: Khuyến khích kinh doanh, giàm gấp đôi về cơ sở hạ tầng và đảm bảo tạo ra những người lao động bước ra từ hệ thống giáo dục với những kỹ năng phù hợp.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  87% 41/47 [03:20<00:47,  7.89s/it]\u001b[A2022-05-06 15:25:06 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể tìm thấy những người khác nhau, nhưng nó có thể tìm thấy những người khác nhau, nhưng bạn có thể tìm thấy những người khác nhau.\n",
            "2022-05-06 15:25:06 | INFO | fairseq.tasks.translation | example reference: Chúng ta đều được đặt trong những mạng xã hội gồn bạn bè, gia đình, đồng nghiệp và hơn thế nữa. Nicholas Christakis theo dõi cách những đặc tính đa dạng -- từ hạnh phúc cho đến nạn béo phì -- có thể lan truyền từ người này sang người khác, cho thấy vị trí của bạn trong mạng lưới có thể ảnh hưởng tới cuộc sống của chính bạn theo những cách mà bạn thậm chí không biết.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  89% 42/47 [03:30<00:42,  8.59s/it]\u001b[A2022-05-06 15:25:19 | INFO | fairseq.tasks.translation | example hypothesis: Chúng ta có thể nói rằng những người khác, nhưng không phải là một người khác nhau, nhưng không phải là một người khác nhau, nhưng không phải là một người khác nhau.\n",
            "2022-05-06 15:25:19 | INFO | fairseq.tasks.translation | example reference: Ngày nay, khi bạn suy nghĩ một sự thật rằng, về mặt lịch sử trung tâm R & amp; D của các công ty đa quốc gia luôn luôn đặt ở văn phòng đầu não, hoặc tại các quốc gia gốc của công ty đa quốc gia đó, việc có được 750 trung tâm R & amp; D của các tập đoàn đa quốc gia tại Ấn Độ đó thực sự là một con số ấn tượng.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  91% 43/47 [03:43<00:39,  9.76s/it]\u001b[A2022-05-06 15:25:35 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng ta có thể tìm thấy những người khác, nhưng chúng ta có thể thấy những người khác nhau, nhưng họ có thể thấy những người khác nhau, nhưng họ có thể làm việc này, và họ có thể thấy những người khác nhau.\n",
            "2022-05-06 15:25:35 | INFO | fairseq.tasks.translation | example reference: Ngày nay, thuốc kháng sinh được sử dụng cho những bệnh nhân như thế này, nhưng cũng được sử dụng phí phạm cho những trường hợp rất nhẹ, như chữa cho người bị cảm, cúm, những bệnh không có phản hồi với thuốc kháng sinh. Và thuốc kháng sinh cũng được sử dụng với lượng lớn, không mang tính trị liệu, với nồng độ thấp, để kích thích sinh trưởng ở gà và lợn.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  94% 44/47 [03:59<00:35, 11.78s/it]\u001b[A2022-05-06 15:25:51 | INFO | fairseq.tasks.translation | example hypothesis: Và đây là một người, tôi muốn nói về những người khác, nhưng tôi đã nói rằng, nhưng tôi muốn nói về những người khác, và những người khác, nhưng tôi đã nói về những người khác, nhưng không phải là một cái gì đó.\n",
            "2022-05-06 15:25:51 | INFO | fairseq.tasks.translation | example reference: Và để nhấn mạnh điểm này, tôi đã bơi phía dưới con tầu đánh bắt tôm và chụp bức ảnh này của một gã đang xúc những sinh vật bị bắt nhầm này đổ ra biển như là rác và chụp được dòng thác của cái chết, Bạn biết đấy, các sinh vật thuộc họ cá đuối, cá bơn, cá nóc, mà chỉ một giờ trước đây, còn đang ở dưới đáy của đại dương, còn sống, nhưng giờ đây bị ném trở lại như là rác\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  96% 45/47 [04:16<00:26, 13.08s/it]\u001b[A2022-05-06 15:26:22 | INFO | fairseq.tasks.translation | example hypothesis: Tôi muốn nói rằng, \"Tôi muốn nói rằng,\" Tôi muốn nói rằng, \"Tôi muốn nói rằng,\" Tôi muốn nói, \"Tôi muốn nói,\" Tôi muốn nói rằng \"Tôi muốn nói rằng,\"\n",
            "2022-05-06 15:26:22 | INFO | fairseq.tasks.translation | example reference: Nhưng cũng để lại trong tôi tình thế lưỡng nan. Tiếp tục theo nghiệp viết lách, cố gắng tìm ra cách viết lại một quyển sách mà mọi người đều hài lòng, vì tôi biết rằng những người say mê \"Ăn, Cầu nguyện, Yêu\" sẽ vô cùng thất vọng với bất kỳ tác phẩm nào của tôi sau đó không phải là \"Ăn, Cầu nguyện, Yêu\". và những người ghét \"Ăn, Cầu nguyện, Yêu\" cũng sẽ rất thất vọng về những tác phẩm sau đó bởi chúng là bằng chứng rằng tôi vẫn tồn tại.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  98% 46/47 [04:46<00:18, 18.24s/it]\u001b[A2022-05-06 15:26:24 | INFO | fairseq.tasks.translation | example hypothesis: Vì vậy, chúng tôi đã nói rằng những người, nhưng không phải là một người khác, nhưng không phải là một người khác, nhưng nó, nhưng không phải là một con người, và những người, nhưng tôi đã nói về những người khác, và những người khác.\n",
            "2022-05-06 15:26:24 | INFO | fairseq.tasks.translation | example reference: Và sự nổi dậy của hàng loạt phong trào như Chúng tôi là một phần trăm Thế hệ tài nguyên (Resource Generation hay Sự giàu có cho lợi ích chung trong đó những thành viên có đặc quyền nhất trong dân số thành viên của một phần trăm những người giàu có đang dùng tài sản kinh tế của mình, dù trưởng thành hay còn trẻ, đó là điều làm tôi bất ngờ nhất, dùng những đặc quyền của họ những tài sản kinh tế của họ để chống lại sự bất bình đẳng bằng cách ủng hộ những chính sách xã hội những thay đổi về giá trị xã hội và thay đổi trong hành vi con người cho dù chúng chống lại lợi ích kinh tế của chính họ nhưng trên hết sẽ khôi phục Giấc mơ Mỹ\n",
            "\n",
            "epoch 001 | valid on 'valid' subset: 100% 47/47 [04:48<00:00, 13.46s/it]\u001b[A\n",
            "                                                                        \u001b[A2022-05-06 15:26:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.174 | nll_loss 7.395 | ppl 168.29 | bleu 1.82 | wps 470.3 | wpb 2916.9 | bsz 108.3 | num_updates 816\n",
            "2022-05-06 15:26:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 816 updates\n",
            "2022-05-06 15:26:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint1.pt\n",
            "2022-05-06 15:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint1.pt\n",
            "2022-05-06 15:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer/checkpoint1.pt (epoch 1 @ 816 updates, score 1.82) (writing took 9.942253876999985 seconds)\n",
            "2022-05-06 15:26:34 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2022-05-06 15:26:34 | INFO | train | epoch 001 | loss 9.714 | nll_loss 9.235 | ppl 602.44 | wps 4850.9 | ups 1.33 | wpb 3641.2 | bsz 137.2 | num_updates 816 | lr 0.000102 | gnorm 1.487 | train_wall 311 | gb_free 11.6 | wall 612\n",
            "2022-05-06 15:26:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 816\n",
            "epoch 002:   0% 0/816 [00:00<?, ?it/s]2022-05-06 15:26:34 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2022-05-06 15:26:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 557, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 190, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 316, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 1058, in train_step\n",
            "    gb_used = torch.cuda.max_memory_allocated() / 1024 / 1024 / 1024\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\", line 341, in max_memory_allocated\n",
            "    return memory_stats(device=device).get(\"allocated_bytes.all.peak\", 0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\", line 198, in memory_stats\n",
            "    stats = memory_stats_as_nested_dict(device=device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\", line 210, in memory_stats_as_nested_dict\n",
            "    return torch._C._cuda_memoryStats(device)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Use MyTransformer to train en-vi data\n",
        "# Train the model, please change --max-epoch depends whether you use gpu/cpu\n",
        "# see stop-time-hours\n",
        "%env CUDA_VISIBLE_DEVICES=0 \n",
        "!fairseq-train \\\n",
        "    /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset \\\n",
        "    --arch nntransformer_default \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-epoch 100 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    --save-dir /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-nntransformer \\\n",
        "    --user-dir /content/mymodel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training custom proposal transformer\n",
        "Arch is `proposalX_default`"
      ],
      "metadata": {
        "id": "FPIFPwDde0Xk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b051b6-f90c-4ef2-b0ce-a0a411f2eaa4",
        "id": "fEFW9OOkfLiT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "2022-05-07 15:07:26 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-05-07 15:07:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/content/mymodel', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-proposal-3', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='proposal3_default', adam_betas='(0.9, 0.98)', adam_eps=1e-08, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='proposal3_default', azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', device_id=0, dim_feedforward=2048, dim_fuzzy=128, dim_model=128, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, eos=2, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=100, max_source_positions=1024, max_src_len=4096, max_target_positions=1024, max_tgt_len=4096, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_head=8, num_layer=6, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-proposal-3', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='/content/mymodel', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-05-07 15:07:29 | INFO | fairseq.tasks.translation | [en] dictionary: 7656 types\n",
            "2022-05-07 15:07:29 | INFO | fairseq.tasks.translation | [vi] dictionary: 6656 types\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | Proposal3Transformer(\n",
            "  (encoder): Proposal3Encoder(\n",
            "    (embedding): PositionalEncodedEmbedding(\n",
            "      (input_embedding): Embedding(7656, 128, padding_idx=1)\n",
            "    )\n",
            "    (nn_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): Proposal3EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (fuzzy_membership): MembershipFunctionLayer()\n",
            "          (fuzzy_rule): FuzzyRuleLayer()\n",
            "        )\n",
            "        (1): Proposal3EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (fuzzy_membership): MembershipFunctionLayer()\n",
            "          (fuzzy_rule): FuzzyRuleLayer()\n",
            "        )\n",
            "        (2): Proposal3EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (fuzzy_membership): MembershipFunctionLayer()\n",
            "          (fuzzy_rule): FuzzyRuleLayer()\n",
            "        )\n",
            "        (3): Proposal3EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (fuzzy_membership): MembershipFunctionLayer()\n",
            "          (fuzzy_rule): FuzzyRuleLayer()\n",
            "        )\n",
            "        (4): Proposal3EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (fuzzy_membership): MembershipFunctionLayer()\n",
            "          (fuzzy_rule): FuzzyRuleLayer()\n",
            "        )\n",
            "        (5): Proposal3EncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (fuzzy_membership): MembershipFunctionLayer()\n",
            "          (fuzzy_rule): FuzzyRuleLayer()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): NNTransformerDecoder(\n",
            "    (embedding): PositionalEncodedEmbedding(\n",
            "      (input_embedding): Embedding(6656, 128, padding_idx=1)\n",
            "    )\n",
            "    (nn_decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (1): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (2): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (3): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (4): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "        (5): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "          (dropout3): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=128, out_features=6656, bias=True)\n",
            "    (dropout): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            ")\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | model: Proposal3Transformer\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | num. shared model params: 10,401,280 (num. trained: 10,401,280)\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-05-07 15:07:31 | INFO | fairseq.data.data_utils | loaded 5,089 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/valid.en-vi.en\n",
            "2022-05-07 15:07:31 | INFO | fairseq.data.data_utils | loaded 5,089 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/valid.en-vi.vi\n",
            "2022-05-07 15:07:31 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset valid en-vi 5089 examples\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.0.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.0.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.1.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.1.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.1.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.2.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.2.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.2.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.3.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.3.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.3.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.4.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.4.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.4.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.5.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.5.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- encoder.nn_encoder.layers.5.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.multihead_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.multihead_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.0.multihead_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.multihead_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.multihead_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.1.multihead_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.multihead_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.multihead_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.2.multihead_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.multihead_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.multihead_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.3.multihead_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.multihead_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.multihead_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.4.multihead_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.self_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.self_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.self_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.multihead_attn.q_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.multihead_attn.k_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | detected shared parameter: encoder.nn_encoder.layers.0.self_attn.q_proj_weight <- decoder.nn_decoder.layers.5.multihead_attn.v_proj_weight\n",
            "2022-05-07 15:07:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-05-07 15:07:31 | INFO | fairseq.utils | rank   0: capabilities =  3.7  ; total memory = 11.173 GB ; name = Tesla K80                               \n",
            "2022-05-07 15:07:31 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-05-07 15:07:31 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-proposal-3/checkpoint_last.pt\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-proposal-3/checkpoint_last.pt\n",
            "2022-05-07 15:07:31 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2022-05-07 15:07:31 | INFO | fairseq.data.data_utils | loaded 111,966 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.en-vi.en\n",
            "2022-05-07 15:07:31 | INFO | fairseq.data.data_utils | loaded 111,966 examples from: /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset/train.en-vi.vi\n",
            "2022-05-07 15:07:31 | INFO | fairseq.tasks.translation | /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset train en-vi 111966 examples\n",
            "2022-05-07 15:07:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 816\n",
            "epoch 001:   0% 0/816 [00:00<?, ?it/s]2022-05-07 15:07:32 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2022-05-07 15:07:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/fairseq/fairseq/utils.py:375: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 557, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 190, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 316, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 830, in train_step\n",
            "    **extra_kwargs,\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 516, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/content/fairseq/fairseq/optim/fairseq_optimizer.py\", line 95, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Train the model, please change --max-epoch depends whether you use gpu/cpu\n",
        "# see stop-time-hours\n",
        "%env CUDA_VISIBLE_DEVICES=0 \n",
        "!fairseq-train \\\n",
        "    /content/drive/MyDrive/translation/iwslt15.tokenized.en-vi/dataset \\\n",
        "    --arch proposal3_default \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "    --dropout 0.3 --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --max-epoch 100 \\\n",
        "    --max-tokens 4096 \\\n",
        "    --eval-bleu \\\n",
        "    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "    --eval-bleu-detok moses \\\n",
        "    --eval-bleu-remove-bpe \\\n",
        "    --eval-bleu-print-samples \\\n",
        "    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "    --save-dir /content/drive/MyDrive/iwslt15.tokenized.en-vi/checkpoints-proposal-3 \\\n",
        "    --user-dir /content/mymodel\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_OBkDDiNQPuD",
        "CBYOOYRFbojI",
        "uuVoveca1ATX",
        "YYLNU2e0Ow0d",
        "N0Wbr-bJW4-r",
        "icDOr3H9HlHY",
        "4Wp9VGKqQVPb",
        "7DGeQy3fetQB",
        "FPIFPwDde0Xk"
      ],
      "name": "running fairseq",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}